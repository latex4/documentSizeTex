\relax 
\bibstyle{aaai24}
\citation{tsai2017deep,cong2020dovenet,ling2021region}
\citation{luan2018deep}
\citation{luan2018deep,zhang2020deep}
\citation{peng2019element,cao2022painterly,yan2022style}
\citation{peng2019element}
\citation{huang2017arbitrary}
\citation{cao2022painterly}
\citation{sdedit,cdc}
\citation{VGG19}
\citation{VGG19}
\citation{luan2018deep,peng2019element,cao2022painterly,yan2022style}
\citation{peng2019element,cao2022painterly}
\citation{huang2017arbitrary}
\citation{VGG19}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:illustration}{{1}{1}{(a) The background image with two marked query patches (red and blue). We show the similarity maps of two query patches based on VGG-19 \citep  {VGG19} features. (b) The composite image with two inserted foreground objects. (c) The ideal harmonized image.}{}{}}
\citation{goodfellow2020generative}
\citation{lin2014microsoft}
\citation{nichol2016painter}
\citation{tsai2017deep,Jiang_2021_ICCV,xing2022composite,peng2022frih,zhu2022image,valanarasu2022interactive,LEMaRT}
\citation{xiaodong2019improving,Hao2020bmcv,sofiiuk2021foreground}
\citation{cong2020dovenet,cong2021bargainnet,ling2021region,hang2022scs}
\citation{guo2021image,guo2021intrinsic,guo2022transformer}
\citation{cong2022high,ke2022harmonizer,liang2021spatial,xue2022dccf,PCTNet,WangCVPR2023}
\citation{luan2018deep,zhang2020deep,peng2019element}
\citation{luan2018deep,zhang2020deep}
\citation{peng2019element}
\citation{luan2018deep,zhang2020deep}
\citation{peng2019element,yan2022style,cao2022painterly}
\citation{sdedit,cdc}
\citation{peng2019element,yan2022style,cao2022painterly}
\citation{kolkin2019style,jing2020dynamic,chen2021dualast,chen2017stylebank,sanakoyeu2018style,wang2020collaborative,li2018learning,chen2016fast,sheng2018avatar,gu2018arbitrary,zhang2019multimodal,chen2022toward,huo2021manifold}
\citation{huang2017arbitrary,li2017universal}
\citation{park2019arbitrary,liu2021adaattn,deng2022stytr2}
\citation{park2019arbitrary}
\citation{liu2021adaattn}
\citation{huang2017arbitrary}
\citation{park2019arbitrary}
\citation{deng2022stytr2}
\citation{elad2017style,li2016combining,park2019arbitrary,huo2021manifold}
\citation{VGG19}
\citation{VGG19}
\citation{ronneberger2015u}
\newlabel{sec:image_harmonization}{{2.1}{2}{}{}{}}
\citation{nichol2016painter}
\citation{wu2019detectron2}
\citation{lin2014microsoft}
\citation{huang2017arbitrary}
\citation{VGG19}
\citation{peng2019element,cao2022painterly}
\citation{huang2017arbitrary}
\newlabel{fig:network}{{2}{3}{The illustration of our network structure. Given a pair of composite image $\bm  {I}^c$ and painterly image $\bm  {I}^p$, we pass them through pretrained VGG-19\nobreakspace  {}\citep  {VGG19} encoder and projection module $P$ to get object features $\hat  {\bm  {f}}^{c,o}$ and $\hat  {\bm  {f}}^{p,o}$ respectively. We insert our designed ObAdaIN modules into skip connections and bottleneck, which harmonize the encoder feature maps of $\bm  {I}^c$. The harmonized encoder feature maps are delivered to the decoder to produce the harmonized image $\tilde  {\bm  {I}}^h$. In the ObAdaIN module in the $l$-th layer, the mapping module $M_l$ learns a mapping from background style $\bm  {s}_l^{p,b}$ (\emph  {resp.}, $\bm  {s}_l^{c,b}$) and object feature $\hat  {\bm  {f}}^{p,o}$ (\emph  {resp.}, $\hat  {\bm  {f}}^{c,o}$) to object style $\tilde  {\bm  {s}}_l^{p,o}$ (\emph  {resp.}, $\tilde  {\bm  {s}}_l^{c,o}$) for painterly (\emph  {resp.}, composite) object. }{}{}}
\newlabel{sec:train_data_preparation}{{3.1}{3}{}{}{}}
\newlabel{sec:network_structure}{{3.2}{3}{}{}{}}
\citation{cao2022painterly}
\newlabel{fig:pair_construction}{{3}{4}{The illustration of constructing training image pairs $\{\bm  {I}^p, \bm  {I}^c\}$. Given a photographic object (outlined in yellow), we have a reference object (outlined in yellow) with similar color and semantics in the reference image $\bm  {I}^p$. We put the photographic object within the bounding box of reference object, resulting in a composite image $\bm  {I}^c$. }{}{}}
\newlabel{eqn:loss_obj}{{1}{4}{}{}{}}
\newlabel{eqn:adain}{{4}{4}{}{}{}}
\citation{VGG19}
\citation{gatys2016image}
\citation{park2019arbitrary}
\citation{liu2021adaattn}
\citation{deng2022stytr2}
\citation{quantart}
\citation{inst}
\citation{sdedit}
\citation{cdc}
\citation{peng2019element}
\citation{luan2018deep}
\citation{cao2022painterly}
\citation{park2019arbitrary}
\citation{liu2021adaattn}
\citation{deng2022stytr2}
\citation{quantart}
\citation{inst}
\citation{sdedit}
\citation{cdc}
\citation{peng2019element}
\citation{luan2018deep}
\citation{cao2022painterly}
\citation{lin2014microsoft}
\citation{nichol2016painter}
\citation{cao2022painterly}
\citation{he2016deep}
\citation{TouvronBCCEGIJSVJ23}
\citation{park2019arbitrary}
\citation{liu2021adaattn}
\citation{deng2022stytr2}
\citation{quantart}
\citation{inst}
\citation{sdedit}
\citation{cdc}
\citation{peng2019element}
\citation{luan2018deep}
\citation{cao2022painterly}
\citation{cao2022painterly}
\citation{bradley1952rank,lai2016comparative}
\citation{cao2022painterly,luan2018deep}
\newlabel{eqn:style_loss}{{5}{5}{}{}{}}
\newlabel{eqn:content_loss}{{6}{5}{}{}{}}
\newlabel{eqn:total_loss}{{7}{5}{}{}{}}
\newlabel{sec:imp_detail}{{4.1}{5}{}{}{}}
\newlabel{sec:cmp_with_baseline}{{4.2}{5}{}{}{}}
\newlabel{tab:results}{{1}{5}{The comparison between different methods. }{}{}}
\citation{lin2014microsoft}
\newlabel{fig:baseline_main}{{4}{6}{In the upper part, we compare with style transfer baselines SANet\nobreakspace  {}\citep  {park2019arbitrary}, AdaAttN\nobreakspace  {}\citep  {liu2021adaattn}, StyTr2\nobreakspace  {}\citep  {deng2022stytr2}, QuantArt\nobreakspace  {}\citep  {quantart}, INST\nobreakspace  {}\citep  {inst}. In the lower part, we compare with painterly image harmonization baselines SDEdit\nobreakspace  {}\citep  {sdedit}, CDC\nobreakspace  {}\citep  {cdc}, E2STN\nobreakspace  {}\citep  {peng2019element}, DPH\nobreakspace  {}\citep  {luan2018deep}, PHDNet\nobreakspace  {}\citep  {cao2022painterly}. }{}{}}
\newlabel{fig:reference_results}{{5}{7}{From left to right, we show the reference image, the mask of reference object, the composite image, the mask of composite object, and the harmonized results obtained using different style vectors. ``BG" uses background style vector, ``RO" uses reference object style vector, and ``Ours" uses our hallucinated style vector.}{}{}}
\bibdata{main.bbl}
\gdef \@abspage@last{8}
