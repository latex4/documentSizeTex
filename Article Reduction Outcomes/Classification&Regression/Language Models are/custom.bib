@article{roads1985research,
  title={Research in music and artificial intelligence},
  author={Roads, Curtis},
  journal={ACM Computing Surveys (CSUR)},
  volume={17},
  number={2},
  pages={163--190},
  year={1985},
  publisher={ACM New York, NY, USA}
}

@article{kaliakatsos2020artificial,
  title={Artificial intelligence methods for music generation: a review and future perspectives},
  author={Kaliakatsos-Papakostas, Maximos and Floros, Andreas and Vrahatis, Michael N},
  journal={Nature-Inspired Computation and Swarm Intelligence},
  pages={217--245},
  year={2020},
  publisher={Elsevier}
}

@article{ji2020comprehensive,
  title={A comprehensive survey on deep music generation: Multi-level representations, algorithms, evaluations, and future directions},
  author={Ji, Shulei and Luo, Jing and Yang, Xinyu},
  journal={arXiv preprint arXiv:2011.06801},
  year={2020}
}

@inproceedings{huang2020pop,
  title={Pop music transformer: Beat-based modeling and generation of expressive pop piano compositions},
  author={Huang, Yu-Siang and Yang, Yi-Hsuan},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={1180--1188},
  year={2020}
}

@inproceedings{ren2020popmag,
  title={Popmag: Pop music accompaniment generation},
  author={Ren, Yi and He, Jinzheng and Tan, Xu and Qin, Tao and Zhao, Zhou and Liu, Tie-Yan},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={1198--1206},
  year={2020}
}

@article{10.1525/mp.2004.21.3.289,
 ISSN = {07307829, 15338312},
 URL = {http://www.jstor.org/stable/10.1525/mp.2004.21.3.289},
 abstract = {The possible links between music and language continue to intrigue scientists interested in the nature of these two types of knowledge, their evolution, and their instantiation in the brain. Here we consider music and language from a developmental perspective, focusing on the degree to which similar mechanisms of learning and memory might subserve the acquisition of knowledge in these two domains. In particular, it seems possible that while adult musical and linguistic processes are modularized to some extent as separate entities, there may be similar developmental underpinnings in both domains, suggesting that modularity is emergent rather than present at the beginning of life. Directions for future research are considered.},
 author = {Erin McMullen and Jenny R. Saffran},
 journal = {Music Perception: An Interdisciplinary Journal},
 number = {3},
 pages = {289--311},
 publisher = {University of California Press},
 title = {Music and Language: A Developmental Comparison},
 urldate = {2022-10-19},
 volume = {21},
 year = {2004}
}

@article{10.1525/mp.2009.26.3.195,
 ISSN = {07307829, 15338312},
 URL = {http://www.jstor.org/stable/10.1525/mp.2009.26.3.195},
 abstract = {THE PARALLELS BETWEEN LANGUAGE AND MUSIC CAN BE explored only in the context of (a) the differences between them, and (b) those parallels that are also shared with other cognitive capacities. The two differ in many aspects of structure and function, and, with the exception of the metrical grid, all aspects they share appear to be instances of more general capacities.},
 author = {Ray Jackendoff},
 journal = {Music Perception: An Interdisciplinary Journal},
 number = {3},
 pages = {195--204},
 publisher = {University of California Press},
 title = {Parallels and Nonparallels between Language and Music},
 urldate = {2022-10-19},
 volume = {26},
 year = {2009}
}

@inproceedings{liang2020pirhdy,
  title={Pirhdy: Learning pitch-, rhythm-, and dynamics-aware embeddings for symbolic music},
  author={Liang, Hongru and Lei, Wenqiang and Chan, Paul Yaozhu and Yang, Zhenglu and Sun, Maosong and Chua, Tat-Seng},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={574--582},
  year={2020}
}

@article{chuan2020context,
  title={From context to concept: exploring semantic relationships in music with word2vec},
  author={Chuan, Ching-Hua and Agres, Kat and Herremans, Dorien},
  journal={Neural Computing and Applications},
  volume={32},
  number={4},
  pages={1023--1036},
  year={2020},
  publisher={Springer}
}

@inproceedings{NIPS2013_9aa42b31,
 author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Distributed Representations of Words and Phrases and their Compositionality},
 url = {https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf},
 volume = {26},
 year = {2013}
}

@article{zeng2021musicbert,
  title={Musicbert: Symbolic music understanding with large-scale pre-training},
  author={Zeng, Mingliang and Tan, Xu and Wang, Rui and Ju, Zeqian and Qin, Tao and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2106.05630},
  year={2021}
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{10.1145/3474085.3478875,
author = {Tan, Xu and Li, Xiaobing},
title = {A Tutorial on AI Music Composition},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3478875},
doi = {10.1145/3474085.3478875},
abstract = {AI music composition is one of the most attractive and important topics in artificial intelligence, music, and multimedia. The typical tasks in AI music composition include melody generation, song writing, accompaniment generation, arrangement, performance generation, timbre rendering, sound generation, and singing voice synthesis, which cover different modalities (e.g., symbolic music score, sound) and well match to the theme of ACM Multimedia. As the rapid development of artificial intelligence techniques such as content creation and deep learning, AI based music composition has achieved rapid progress, but still encountered a lot of challenges. A thorough introduction and review on the basics, the research progress, as well as how to address the challenges in AI music composition are timely and necessary for a broad audience working on artificial intelligence, music, and multimedia. In this tutorial, we will first introduce the background of AI music composition, including music basics and deep learning techniques for music composition. Then we will introduce AI music composition from two perspectives: 1) key components, which include music score generation, music performance generation, and music sound generation; 2) advanced topics, which include music structure/form/style/emotion modeling, timbre synthesis/transfer/mixing, etc. At last, we will point out some research challenges and future directions in AI music composition. This tutorial can serve both academic researchers and industry practitioners working on AI music composition.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {5678–5680},
numpages = {3},
keywords = {music arrangement, ai music, melody generation, singing voice synthesis, music composition, song writing, accompaniment generation},
location = {Virtual Event, China},
series = {MM '21}
}

@conference{complexis21,
author={Alexey Tikhonov. and Ivan Yamshchikov.},
title={Artificial Neural Networks Jamming on the Beat},
booktitle={Proceedings of the 6th International Conference on Complexity, Future Information Systems and Risk - COMPLEXIS,},
year={2021},
pages={37-44},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0010461200370044},
isbn={978-989-758-505-0},
issn={2184-5034},
}

@inproceedings{gillick2019learning,
  title={Learning to groove with inverse sequence transformations},
  author={Gillick, Jon and Roberts, Adam and Engel, Jesse and Eck, Douglas and Bamman, David},
  booktitle={International Conference on Machine Learning},
  pages={2269--2279},
  year={2019},
  organization={PMLR}
}

@inproceedings{burloiu2020adaptive,
  title={Adaptive Drum Machine Microtiming with Transfer Learning and RNNs},
  author={Burloiu, Grigore and Unatc, Cinetic},
  booktitle={Extended Abstracts for the Late-Breaking Demo Session of the International Society for Music Information Retrieval Conference (ISMIR)},
  year={2020}
}

@inproceedings{vogl2017intelligent,
  title={An intelligent drum machine for electronic dance music production and performance.},
  author={Vogl, Richard and Knees, Peter},
  booktitle={NIME},
  pages={251--256},
  year={2017}
}

@inproceedings{makris2017combining,
  title={Combining LSTM and feed forward neural networks for conditional rhythm composition},
  author={Makris, Dimos and Kaliakatsos-Papakostas, Maximos and Karydis, Ioannis and Kermanidis, Katia Lida},
  booktitle={International conference on engineering applications of neural networks},
  pages={570--582},
  year={2017},
  organization={Springer}
}

@article{makris2019conditional,
  title={Conditional neural sequence learners for generating drums’ rhythms},
  author={Makris, Dimos and Kaliakatsos-Papakostas, Maximos and Karydis, Ioannis and Kermanidis, Katia Lida},
  journal={Neural Computing and Applications},
  volume={31},
  number={6},
  pages={1793--1804},
  year={2019},
  publisher={Springer}
}

@inproceedings{lyu2015modelling,
  title={Modelling high-dimensional sequences with lstm-rtrbm: Application to polyphonic music generation},
  author={Lyu, Qi and Wu, Zhiyong and Zhu, Jun and Meng, Helen},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{lattner2019high,
  title={High-level control of drum track generation using learned patterns of rhythmic interaction},
  author={Lattner, Stefan and Grachten, Maarten},
  booktitle={2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
  pages={35--39},
  year={2019},
  organization={IEEE}
}

@inproceedings{burloiu2020interactive,
  title={Interactive Learning of Microtiming in an Expressive Drum Machine},
  author={Burloiu, Grigore},
  booktitle={The 2020 Joint Conference on AI Music Creativity},
  year={2020}
}

@inproceedings{bruford2020jaki,
  title={jaki: user-controllable generation of drum patterns using an LSTM encoder-decoder and deep reinforcement learning},
  author={Bruford, Fred and McDonald, S and Sandler, Mark},
  booktitle={The 2020 Joint Conference on AI Music Creativity},
  year={2020}
}

@inproceedings{brunner2018symbolic,
  title={Symbolic music genre transfer with cyclegan},
  author={Brunner, Gino and Wang, Yuyi and Wattenhofer, Roger and Zhao, Sumu},
  booktitle={2018 ieee 30th international conference on tools with artificial intelligence (ictai)},
  pages={786--793},
  year={2018},
  organization={IEEE}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{huang2018music,
  title={Music transformer},
  author={Huang, Cheng-Zhi Anna and Vaswani, Ashish and Uszkoreit, Jakob and Shazeer, Noam and Simon, Ian and Hawthorne, Curtis and Dai, Andrew M and Hoffman, Matthew D and Dinculescu, Monica and Eck, Douglas},
  journal={arXiv preprint arXiv:1809.04281},
  year={2018}
}

@misc{https://doi.org/10.48550/arxiv.2210.10349,
  doi = {10.48550/ARXIV.2210.10349},
  
  url = {https://arxiv.org/abs/2210.10349},
  
  author = {Yu, Botao and Lu, Peiling and Wang, Rui and Hu, Wei and Tan, Xu and Ye, Wei and Zhang, Shikun and Qin, Tao and Liu, Tie-Yan},
  
  keywords = {Sound (cs.SD), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), Multimedia (cs.MM), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {Museformer: Transformer with Fine- and Coarse-Grained Attention for Music Generation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{donahue2017dance,
  title={Dance dance convolution},
  author={Donahue, Chris and Lipton, Zachary C and McAuley, Julian},
  booktitle={International conference on machine learning},
  pages={1039--1048},
  year={2017},
  organization={PMLR}
}

@inproceedings{liang2019procedural,
  title={Procedural content generation of rhythm games using deep learning methods},
  author={Liang, Yubin and Li, Wanxiang and Ikeda, Kokolo},
  booktitle={Joint International Conference on Entertainment Computing and Serious Games},
  pages={134--145},
  year={2019},
  organization={Springer}
}

@article{senn2018groove,
  title={Groove in drum patterns as a function of both rhythmic properties and listeners’ attitudes},
  author={Senn, Olivier and Kilchenmann, Lorenz and Bechtold, Toni and Hoesl, Florian},
  journal={PloS one},
  volume={13},
  number={6},
  pages={e0199604},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}