%File: formatting-instructions-latex-2023.tex
%release 2023.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai23}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2023.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai23.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Pre-Training With Scientific Text Improves Educational Question Generation (Student Abstract)}
% \author{
%     %Authors
%     % All authors must be in the same font size and format.
%     Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
%     AAAI Style Contributions by Pater Patel Schneider,
%     Sunil Issar,\\
%     J. Scott Penberthy,
%     George Ferguson,
%     Hans Guesgen,
%     Francisco Cruz\equalcontrib,
%     Marc Pujol-Gonzalez\equalcontrib
% }
\author{
Hamze Muse\equalcontrib, 
Sahan Bulathwela\equalcontrib 
and Emine Yilmaz
}
% \affiliations{
%     %Afiliations
%     \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
%     % If you have multiple authors and multiple affiliations
%     % use superscripts in text and roman font to identify them.
%     % For example,

%     % Sunil Issar, \textsuperscript{\rm 2}
%     % J. Scott Penberthy, \textsuperscript{\rm 3}
%     % George Ferguson,\textsuperscript{\rm 4}
%     % Hans Guesgen, \textsuperscript{\rm 5}.
%     % Note that the comma should be placed BEFORE the superscript for optimum readability

%     1900 Embarcadero Road, Suite 101\\
%     Palo Alto, California 94303-3310 USA\\
%     % email address must be in roman text type, not monospace or sans serif
%     publications23@aaai.org
% %
% % See more examples next
% }

\affiliations{
Centre for Artificial Intelligence, University College London \\
    Gower Street, London WC1E 6BT, UK \\
    \{hamze.muse.20, m.bulathwela, emine.yilmaz\}@ucl.ac.uk
}

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name,\textsuperscript{\rm 1,\rm 2}
    Second Author Name, \textsuperscript{\rm 2}
    Third Author Name \textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1} Affiliation 1\\
    \textsuperscript{\rm 2} Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
% \usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
With the boom of digital educational materials and scalable e-learning systems, the potential for realising AI-assisted personalised learning has skyrocketed. In this landscape, the automatic generation of educational questions will play a key role, enabling scalable self-assessment when a global population is manoeuvring their personalised learning journeys. We develop \textit{EduQG}, a novel educational question generation model built by adapting a large language model. Our initial experiments demonstrate that \textit{EduQG} can produce superior educational questions by pre-training on scientific text. 
\end{abstract}

\section{Introduction}
While digital learning resources are created in abundance 
% in the form of  Massively Online Open Courses and Open Educational Resources 
\cite{truelearn}, providing related questions 
to these resources 
% is critical for 
facilitates self-testing, a critical element of self-regulated learning.
% \cite{chi1994eliciting}.
%  learners with self-testing opportunities that will allow them to gain self-awareness within their personalised journey. 
Also, question-answering enables an intelligent tutor to reliably verify learner skill mastery,
% is the most reliable tool an intelligent tutor has to verify the skill mastery of learners, 
making scalable educational question generation essential for democratising education \cite{ai_ed_demo,zhang2021review}. 
While existing language models are being used for question generation,
% While significant breakthroughs have been made on question generation using large language models, 
their utility 
% of these advancements 
to education is only being explored very recently \cite{wang2022towards}. In particular, pre-training large language models with educational text to improve question generation is an unexplored area. 
This work validates if additional training with educational text can improve questions generated in the educational context. We develop an experiment to adapt a large language model to test this and propose \emph{EduQG}, a novel model for educational question generation. Our initial comparisons with a baseline question generation model indicate that this additional training can improve performance.  

\begin{table*}[t!] \centering \small
\begin{tabular}{c|ccccc|ccc}
\hline
                & \multicolumn{5}{c}{Predictive Performance}                          & \multicolumn{3}{c}{Linguistic Quality}       \\
Model           & BLEU-1 $\uparrow$     & BLEU-2 $\uparrow$     & BLEU-3 $\uparrow$     & BLEU-4   $\uparrow$   & F1-Score  $\uparrow$        & Perplexity $\downarrow$       & Diversity $\uparrow$         & Grammar Errors $\downarrow$        \\
% &&&&&&&&\\

\hline
Leaf (Baseline) & 27.07          & 20.22          & 17.17          & {16.46} & 30.90          & \textbf{30.82} & 0.735          & \textbf{0.102} \\
EduQG (Ours)        & \textbf{29.19} & \textbf{21.69} & \textbf{18.03} & \textbf{16.76} & \textbf{33.18} & 34.36          & \textbf{0.749} & 0.122  \\       
\hline
\end{tabular}
\caption{Comparison of predictive performance and linguistic quality between Leaf (baseline) and EduQG (our proposal). The superior performance is indicated in \textbf{bold} face.}
\label{results}
\end{table*}
\section{Related Work}

Prior work mainly utilises i) rule-based and ii) neural-based models for question generation (QG), while neural approaches have dominated the state of the art on QG in different applications including intelligent tutoring \cite{zhang2021review}. 
When it comes to leveraging QG for education, Leaf system \cite{vachev2022leaf} is one of the latest proposed methods.
% To leverage QG for education, Leaf system \cite{vachev2022leaf} is one of the most recent methods. 
Leaf is a cutting-edge question generation system that fine-tunes a large language model for question generation and multiple-choice distracter generation. Due to the recency and relevance of the Leaf system, we use the QG model of Leaf as the baseline model of this study.
% Due to the recency and relevance to education of Leaf system, we use the QG model of Leaf as the baseline model of this study.  
Like many cutting-edge models, Leaf uses the \emph{SQuAD 1.1} \cite{DBLP:rajpurkar2016squad}, a reading comprehension dataset containing more than 100,000 questions crowd-sourced on a number of Wikipedia articles, to train the QG component of the system. It does so by fine-tuning a pre-trained T5 language model \cite{raffel2020exploring}. 
 
Although Leaf has been built for educational use cases using the SQuAD dataset, the SQuAD dataset itself contains questions that are aimed at English reading comprehension. Thus, it is not a strong candidate for testing the question generation capability for more rigorous subject domains such as the sciences. 
On the contrary, SciQ \cite{welbl-etal-2017-crowdsourcing} is a collection of 13,679 crowdsourced scientific exam questions that includes questions regarding physics, chemistry and other sciences. Although small in comparison to SQuAD, the SciQ dataset is a more relevant dataset that can be used to evaluate the educational QG capabilities of a model. Therefore, we use the SciQ dataset to evaluate the question generation models we build in this work. 

While large language models capture a lot of information about the world \cite{raffel2020exploring}, these models need to be pre-trained further in domain-specific datasets to improve their knowledge and fluency in specific domains (e.g. medicine \cite{https://doi.org/10.48550/arxiv.2109.04588}). In the realm of scientific information, \emph{S2ORC} is a corpus that consists of 81.1 million scholarly publications in English from various academic fields bringing together the largest publicly accessible collection of machine-readable academic literature to date \cite{lo-etal-2020-s2orc}. To test our hypothesis that pretraining the model with scientific/academic text would improve its educational QG capability, we use the S2ORC dataset.

\section{Our Approach}

The primary objective of our study is to validate if further fine-tuning a system on educational data can improve educational QG. The experiment we set up is illustrated in figure \ref{fig:method}. The foundational language model to both our training settings is the T5 language model \cite{raffel2020exploring}. We first replicate the QG component of the Leaf system \cite{vachev2022leaf} by taking the T5 model and fine-tuning it on the SQuAD 1.1 dataset as our baseline QG system (Blue flow in figure \ref{fig:method}). As the enhanced proposal, we use the same procedure, except, we fine-tune the T5 model with a down-sampled version of the S2ORC dataset  that contains approx. {23.2M} scientific abstracts related to Chemistry, Biology and Physics research papers (green dashed box in figure \ref{fig:method}). 

\paragraph{Evaluation} 
The two settings lead to the baseline (Leaf) and the proposed model (EduQG) that we compare using the SciQ dataset, as it contains exclusively educational questions.
To measure the predictive power of the human-generated questions, we use the BLUE score and the F1 score \cite{DBLP:rajpurkar2016squad}. To measure how human-like the generated questions are, we use perplexity, diversity and grammatical error rates. A lower perplexity score indicates better coherence \cite{wang2022towards}.
\begin{figure}[]
    \centering
    % \includegraphics[width=70mm,height=39mm]{Distribution_Train Data LR.png}
    % \includegraphics[width=95mm, height=65mm]{LaTeX/methodology_new.png}
    \includegraphics[width=\columnwidth]{methodology_new_v2.png}
    \caption{Baseline (blue arrows) and EduQG (green arrows).}
    \label{fig:method}
\end{figure}

\section{Preliminary Results and Discussion}

The results of the model comparison are presented in table \ref{results}. 
The predictive performance results in Table \ref{results} clearly indicate that the \textit{EduQG} model is better at predicting scientific questions based on the context compared to Leaf. This is a strong indication that the additional scientific knowledge the EduGQ model is pre-trained on has an effect on educational QG capability. However, the linguistic quality metrics (shown on the right of the table) do not yield a favourable result although diversity has been improved by our model. We hypothesise that this may be due to the mismatch of language style and vocabulary of a scientific language that is advanced and complex. Therefore, scientific language might not align seamlessly with the reference models used for linguistic quality assessment. 

\section{Conclusion}
This work introduces EduQG, a foundational step toward further pre-training to improve educational QG. Our initial experiments prove the utility of pre-training an existing language model to improve its performance. The linguistic quality metrics are not as favourable as expected. Deeper analyses are warranted to understand whether the outcomes portray a limitation or a mismatch between the language models which will be addressed in future work using both offline and human studies. 

\subsection{Acknowledgments}
This work is funded by the European Commission project "Humane AI" (grant 820437).

\bibliography{aaai23}

\end{document}
