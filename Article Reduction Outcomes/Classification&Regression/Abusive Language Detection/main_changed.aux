\relax 
\bibstyle{aaai21}
\citation{waseem2017understanding}
\citation{price2010cyberbullying}
\citation{nobata2016abusive}
\citation{vidgen2019challenges}
\citation{kowalski2007electronic,james2011friend}
\citation{choi2018effects}
\citation{chakrabarty2019pay}
\citation{wang2018disconnected}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:examples}{{1}{1}{Examples of YouTube comments with heterogeneous abusive language. Abusive parts are underlined in bold text.}{}{}}
\citation{vidgen2019challenges}
\citation{waseem2016hateful,davidson2017automated,golbeck2017large}
\citation{qian2019benchmark,ribeiroevolution}
\citation{de2018hate}
\citation{schmidt2017survey}
\citation{chung2019conan}
\citation{fortuna2018survey}
\citation{wulczyn2017ex}
\citation{nobata2016abusive}
\citation{yin2009detection,joksimovic2019automated}
\citation{park2017one,maity2018opinion}
\citation{pavlopoulos2017deeper,chakrabarty2019pay}
\citation{nobata2016abusive,schmidt2017survey}
\citation{vidgen2019challenges}
\citation{park2017one,badjatiya2017deep,fortuna2018survey}
\citation{hoff2009cyberbullying}
\citation{van2015detection,dinakar2011modeling}
\citation{luong2015effective}
\citation{liu2016neural}
\citation{liu2017exploiting}
\citation{bao2018deriving}
\citation{vidgen2019challenges}
\citation{alakrot2018dataset}
\citation{ribeiroevolution}
\newlabel{sec:related}{{}{2}{}{}{}}
\newlabel{sec:dataset}{{}{2}{}{}{}}
\citation{waseem2016you}
\citation{vidgen2019challenges}
\citation{vidgen2019challenges}
\citation{fortuna2018survey,peter2018cyberbullying}
\citation{nobata2016abusive}
\citation{nockleby2000hate}
\citation{patchin2015measuring}
\citation{vidgen2019challenges}
\citation{founta2018large}
\citation{hube2019understanding}
\citation{vidgen2019challenges}
\citation{miceli2020between}
\citation{low2007experiences,ferguson2011know}
\newlabel{sec:detection}{{}{3}{}{}{}}
\citation{chakrabarty2019pay}
\citation{sennrich2016linguistic}
\citation{mikolov2013distributed}
\citation{yang2016hierarchical}
\citation{chakrabarty2019pay}
\citation{liu2016neural,liu2017exploiting}
\newlabel{rnn_supervised_attetnion}{{1}{4}{RNN with supervised attention. Each input word is a concatenation of its word- and POS embeddings. The input is a sequence of embeddings, and the recurrent layer generates hidden state vectors. The attention module determines the attention distribution over these hidden vectors, which are linearly weighted with the attention weights to input to the feedforward network (FFN). The FFN predicts the scores of each class, which are transformed to a probability distribution over the classes in the output. The AttEncoder maps the ground truth (G) and model (M) attention to the same vector space in order to measure the encoded attention loss.}{}{}}
\citation{van2015detection,nobata2016abusive}
\citation{van2015detection}
\citation{opinionlexicon}
\citation{chakrabarty2019pay}
\citation{tweet_preprocessor}
\citation{owoputi2013improved}
\citation{davis2006relationship}
\newlabel{fig:att_example}{{2}{5}{Attention visualization of RNN trained with and without attention supervision for an abusive sentence in grey-scale image. The lighter the word, the higher its attention weight.}{}{}}
\newlabel{tab:detection_performance}{{2}{5}{Abusive language detection performance. C: using only comment labels, and C+S: using comment and sentence labels. }{}{}}
\newlabel{eq:proj_ground_attention}{{3}{5}{}{}{}}
\newlabel{eq:proj_model_attention}{{4}{5}{}{}{}}
\citation{van2015detection,dinakar2011modeling}
\citation{standley2020tasks}
\newlabel{fig:attn_eval_plot}{{3}{6}{Attention evaluation on test comments.}{}{}}
\newlabel{sec:categorization}{{}{6}{}{}{}}
\bibdata{aaai.bib}
\newlabel{tab:categorization}{{3}{7}{PR AUC of abuse categorization with and without attention supervision in single- and multi-task settings.}{}{}}
\newlabel{sec:conclusion}{{}{7}{}{}{}}
\gdef \@abspage@last{8}
