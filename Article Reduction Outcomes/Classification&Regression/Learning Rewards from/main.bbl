\begin{thebibliography}{71}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi:\discretionary{}{}{}#1}\else
  \providecommand{\doi}{doi:\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi

\bibitem[{Abbeel and Ng(2004)}]{abbeel2004apprenticeship}
Abbeel, P.; and Ng, A.~Y. 2004.
\newblock Apprenticeship Learning via Inverse Reinforcement Learning.
\newblock ICML, 1. New York, NY, USA.

\bibitem[{Allison, Luger, and
  Hofmann(2018)}]{fraser2018_natural_language_agent}
Allison, F.; Luger, E.; and Hofmann, K. 2018.
\newblock How Players Speak to an Intelligent Game Character Using Natural
  Language Messages.
\newblock \emph{Transactions of the Digital Games Research Association} 4.

\bibitem[{Argall et~al.(2009)Argall, Chernova, Veloso, and
  Browning}]{argall2009survey}
Argall, B.~D.; Chernova, S.; Veloso, M.; and Browning, B. 2009.
\newblock A survey of robot learning from demonstration.
\newblock \emph{Robotics and autonomous systems} 57(5): 469--483.

\bibitem[{Artzi and Zettlemoyer(2011)}]{artzi_2011_bootstrapping}
Artzi, Y.; and Zettlemoyer, L. 2011.
\newblock Bootstrapping {S}emantic {P}arsers from {C}onversations.
\newblock In \emph{EMNLP 2011}, 421--432. ACL.

\bibitem[{Bahdanau et~al.(2019)Bahdanau, Hill, Leike, Hughes, Hosseini, Kohli,
  and Grefenstette}]{Bahdanau_2019}
Bahdanau, D.; Hill, F.; Leike, J.; Hughes, E.; Hosseini, S.~A.; Kohli, P.; and
  Grefenstette, E. 2019.
\newblock Learning to Understand Goal Specifications by Modelling Reward.
\newblock In \emph{{ICLR} 2019}.

\bibitem[{Chen et~al.(2017)Chen, Yang, Chang, Ye, Zhou, and
  Yu}]{chen-etal-2017-line}
Chen, L.; Yang, R.; Chang, C.; Ye, Z.; Zhou, X.; and Yu, K. 2017.
\newblock On-line Dialogue Policy Learning with Companion Teaching.
\newblock In \emph{Proceedings of the 15th Conference of the {E}uropean Chapter
  of the Association for Computational Linguistics}, 198--204. Valencia, Spain:
  Association for Computational Linguistics.

\bibitem[{Chevalier{-}Boisvert et~al.(2018)Chevalier{-}Boisvert, Bahdanau,
  Lahlou, Willems, Saharia, Nguyen, and Bengio}]{chevalier_boisvert_2018}
Chevalier{-}Boisvert, M.; Bahdanau, D.; Lahlou, S.; Willems, L.; Saharia, C.;
  Nguyen, T.~H.; and Bengio, Y. 2018.
\newblock BabyAI: First Steps Towards Grounded Language Learning With a Human
  In the Loop.
\newblock \emph{arXiv} abs/1810.08272.

\bibitem[{Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and
  Amodei}]{christiano2017deep}
Christiano, P.~F.; Leike, J.; Brown, T.; Martic, M.; Legg, S.; and Amodei, D.
  2017.
\newblock Deep {R}einforcement {L}earning from {H}uman {P}references.
\newblock In \emph{NeurIPS}, 4299--4307.

\bibitem[{Cideron et~al.(2019)Cideron, Seurin, Strub, and
  Pietquin}]{cideron2019selfeducated}
Cideron, G.; Seurin, M.; Strub, F.; and Pietquin, O. 2019.
\newblock Self-Educated Language Agent With Hindsight Experience Replay For
  Instruction Following.
\newblock \emph{arXiv} abs/1910.09451.

\bibitem[{Clark(1996)}]{clark1996using}
Clark, H.~H. 1996.
\newblock \emph{Using {L}anguage}.
\newblock Cambridge {U}niversity {P}ress.

\bibitem[{Djalali et~al.(2011)Djalali, Clausen, Lauer, Schultz, and
  Potts}]{Djalali2011}
Djalali, A.; Clausen, D.; Lauer, S.; Schultz, K.; and Potts, C. 2011.
\newblock Modeling Expert Effects and Common Ground Using {Q}uestions {U}nder
  {D}iscussion.
\newblock In \emph{Proceedings of the {AAAI} Workshop on Building
  Representations of Common Ground with Intelligent Agents}. Washington, DC:
  AAAI Press.

\bibitem[{Djalali, Lauer, and Potts(2012)}]{Djalali_2012}
Djalali, A.; Lauer, S.; and Potts, C. 2012.
\newblock Corpus Evidence for Preference-Driven Interpretation.
\newblock In Aloni, M.; Kimmelman, V.; Roelofsen, F.; Sassoon, G.~W.; Schulz,
  K.; and Westera, M., eds., \emph{Proceedings of the 18th {A}msterdam
  Colloquium: Revised Selected Papers}, 150--159. Berlin: Springer.

\bibitem[{Dragan, Lee, and Srinivasa(2013)}]{Dragan2013Legibility}
Dragan, A.~D.; Lee, K.~C.; and Srinivasa, S.~S. 2013.
\newblock Legibility and Predictability of Robot Motion.
\newblock In \emph{ACM/IEEE International Conference on Human-Robot
  Interaction}.

\bibitem[{Fu et~al.(2019)Fu, Korattikara, Levine, and
  Guadarrama}]{fu_2019_goals}
Fu, J.; Korattikara, A.; Levine, S.; and Guadarrama, S. 2019.
\newblock From Language to Goals: Inverse Reinforcement Learning for
  Vision-Based Instruction Following.
\newblock \emph{arXiv} abs/1902.07742.

\bibitem[{Goodman and Frank(2016)}]{goodman_2016}
Goodman, N.~D.; and Frank, M.~C. 2016.
\newblock Pragmatic Language Interpretation as Probabilistic Inference.
\newblock \emph{Trends in Cognitive Sciences} 20(11): 818 -- 829.

\bibitem[{Goyal, Niekum, and Mooney(2019)}]{goyal2019using}
Goyal, P.; Niekum, S.; and Mooney, R.~J. 2019.
\newblock Using natural language for reward shaping in reinforcement learning.
\newblock In \emph{IJCAI}, 2385--2391. AAAI Press.

\bibitem[{Goyal, Niekum, and Mooney(2020)}]{goyal2020pixl2r}
Goyal, P.; Niekum, S.; and Mooney, R.~J. 2020.
\newblock PixL2R: Guiding Reinforcement Learning Using Natural Language by
  Mapping Pixels to Rewards.
\newblock \emph{arXiv} abs/2002.04833.

\bibitem[{Grice(1975)}]{grice1975logic}
Grice, H.~P. 1975.
\newblock Logic and Conversation.
\newblock In \emph{Syntax and {S}emantics: {V}ol. 3: {S}peech {A}cts}, 41--58.
  New York: Academic Press.

\bibitem[{Gureckis et~al.(2016)Gureckis, Martin, McDonnell, Rich, Markant,
  Coenen, Halpern, Hamrick, and Chan}]{gureckis_2016}
Gureckis, T.~M.; Martin, J.; McDonnell, J.; Rich, A.~S.; Markant, D.; Coenen,
  A.; Halpern, D.; Hamrick, J.~B.; and Chan, P. 2016.
\newblock psi{T}urk: An open-source framework for conducting replicable
  behavioral experiments online.
\newblock \emph{Behavior Research Methods} 48(3).

\bibitem[{Hadfield-Menell et~al.(2016)Hadfield-Menell, Russell, Abbeel, and
  Dragan}]{HadfieldMenell2016cooperative}
Hadfield-Menell, D.; Russell, S.~J.; Abbeel, P.; and Dragan, A. 2016.
\newblock Cooperative Inverse Reinforcement Learning.
\newblock In Lee, D.~D.; Sugiyama, M.; Luxburg, U.~V.; Guyon, I.; and Garnett,
  R., eds., \emph{NeurIPS}, 3909--3917. Curran Associates, Inc.

\bibitem[{Hancock et~al.(2018)Hancock, Varma, Wang, Bringmann, Liang, and
  Ré}]{Hancock_2018_explanation}
Hancock, B.; Varma, P.; Wang, S.; Bringmann, M.; Liang, P.; and Ré, C. 2018.
\newblock Training Classifiers with Natural Language Explanations.
\newblock \emph{ACL} .

\bibitem[{Harnad(1990)}]{harnad1990symbol}
Harnad, S. 1990.
\newblock The symbol grounding problem.
\newblock \emph{Physica D: Nonlinear Phenomena} 42(1-3): 335--346.

\bibitem[{Hattie and Timperley(2007)}]{Hattie_2007}
Hattie, J.; and Timperley, H. 2007.
\newblock The Power of Feedback.
\newblock \emph{Review of Educational Research} 77(1): 81--112.

\bibitem[{He et~al.(2017)He, Balakrishnan, Eric, and Liang}]{He_2017}
He, H.; Balakrishnan, A.; Eric, M.; and Liang, P. 2017.
\newblock Learning Symmetric Collaborative Dialogue Agents with Dynamic
  Knowledge Graph Embeddings.
\newblock \emph{ACL} .

\bibitem[{Ho et~al.(2016)Ho, Littman, MacGlashan, Cushman, and
  Austerweil}]{ho2016showing}
Ho, M.~K.; Littman, M.; MacGlashan, J.; Cushman, F.; and Austerweil, J.~L.
  2016.
\newblock Showing versus {D}oing: Teaching by {D}emonstration.
\newblock In \emph{NeurIPS}, 3027--3035.

\bibitem[{Hu and Liu(2004)}]{hu2004mining}
Hu, M.; and Liu, B. 2004.
\newblock Mining and summarizing customer reviews.
\newblock In \emph{SIGKDD}, 168--177.

\bibitem[{Hutto and Gilbert(2014)}]{HuttoG14}
Hutto, C.~J.; and Gilbert, E. 2014.
\newblock VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of
  Social Media Text.
\newblock In \emph{ICWSM}. The AAAI Press.

\bibitem[{Ilinykh, Zarrieß, and Schlangen(2019)}]{ilinykh2019meetup}
Ilinykh, N.; Zarrieß, S.; and Schlangen, D. 2019.
\newblock MeetUp! A Corpus of Joint Activity Dialogues in a Visual Environment.
\newblock \emph{arXiv} abs/1907.05084.

\bibitem[{Jeon, Milli, and Dragan(2020)}]{jeon2020rewardrational}
Jeon, H.~J.; Milli, S.; and Dragan, A.~D. 2020.
\newblock Reward-rational (implicit) choice: A unifying formalism for reward
  learning.
\newblock \emph{arXiv} abs/2002.04833.

\bibitem[{Jiang et~al.(2011)Jiang, Yu, Zhou, Liu, and Zhao}]{jiang2011target}
Jiang, L.; Yu, M.; Zhou, M.; Liu, X.; and Zhao, T. 2011.
\newblock Target-dependent twitter sentiment classification.
\newblock In \emph{AACL}, 151--160.

\bibitem[{Judah et~al.(2010)Judah, Roy, Fern, and
  Dietterich}]{judah2010_critique}
Judah, K.; Roy, S.; Fern, A.; and Dietterich, T.~G. 2010.
\newblock Reinforcement Learning via Practice and Critique Advice.
\newblock In \emph{AAAI}.

\bibitem[{Kaplan, Sauer, and Sosa(2017)}]{kaplan_atari}
Kaplan, R.; Sauer, C.; and Sosa, A. 2017.
\newblock Beating Atari with Natural Language Guided Reinforcement Learning.
\newblock \emph{arXiv} abs/1704.05539.

\bibitem[{Kim et~al.(2009)Kim, Leyzberg, Tsui, and Scassellati}]{kim2009people}
Kim, E.~S.; Leyzberg, D.; Tsui, K.~M.; and Scassellati, B. 2009.
\newblock How people talk when teaching a robot.
\newblock In \emph{ACM/IEEE {I}nternational {C}onference on Human-{R}obot
  {I}nteraction}, 23--30.

\bibitem[{Kim(2014)}]{Kim_2014}
Kim, Y. 2014.
\newblock Convolutional Neural Networks for Sentence Classification.
\newblock \emph{EMNLP 2014} .

\bibitem[{Knox and Stone(2009)}]{Knox2009Interactively}
Knox, W.~B.; and Stone, P. 2009.
\newblock Interactively Shaping Agents via Human Reinforcement: The TAMER
  Framework.
\newblock In \emph{Proceedings of the Fifth International Conference on
  Knowledge Capture}, 9–16. New York, NY, USA: Association for Computing
  Machinery.

\bibitem[{Kuhlmann et~al.(2004)Kuhlmann, Stone, Mooney, and
  Shavlik}]{kuhlman_2004}
Kuhlmann, G.; Stone, P.; Mooney, R.; and Shavlik, J. 2004.
\newblock Guiding a reinforcement learner with natural language advice: Initial
  results in RoboCup soccer.
\newblock \emph{AAAI Workshop - Technical Report} .

\bibitem[{Kuznetsova, Brockhoff, and
  Christensen(2017)}]{kuznetsova2017lmertest}
Kuznetsova, A.; Brockhoff, P.~B.; and Christensen, R. 2017.
\newblock lmerTest package: tests in linear mixed effects models.
\newblock \emph{Journal of statistical software} 82(13): 1--26.

\bibitem[{Li et~al.(2016)Li, Miller, Chopra, Ranzato, and
  Weston}]{li2016dialogue}
Li, J.; Miller, A.~H.; Chopra, S.; Ranzato, M.; and Weston, J. 2016.
\newblock Dialogue Learning With Human-In-The-Loop.
\newblock \emph{arXiv} abs/1611.09823.

\bibitem[{Ling and Fidler(2017)}]{Ling2017_captions}
Ling, H.; and Fidler, S. 2017.
\newblock Teaching Machines to Describe Images with Natural Language Feedback.
\newblock In \emph{NIPS}.

\bibitem[{Lipnevich and Smith(2009)}]{Lipnevich_education}
Lipnevich, A.; and Smith, J. 2009.
\newblock Effects of differential feedback on students' examination
  performance.
\newblock \emph{Journal of Experimental Psychology: Applied} 15(4): 319--333.

\bibitem[{Liu(2020)}]{liu2020sentiment}
Liu, B. 2020.
\newblock \emph{Sentiment {A}nalysis: {M}ining {O}pinions, {S}entiments, and
  {E}motions}.
\newblock Cambridge {U}niversity {P}ress.

\bibitem[{Luketina et~al.(2019)Luketina, Nardelli, Farquhar, Foerster, Andreas,
  Grefenstette, Whiteson, and Rockt{\"a}schel}]{luketina2019survey}
Luketina, J.; Nardelli, N.; Farquhar, G.; Foerster, J.; Andreas, J.;
  Grefenstette, E.; Whiteson, S.; and Rockt{\"a}schel, T. 2019.
\newblock A Survey of Reinforcement Learning Informed by Natural Language.
\newblock In \emph{IJCAI 2019}, volume~57. AAAI Press.

\bibitem[{MacGlashan et~al.(2015)MacGlashan, Babes-Vroman, desJardins, Littman,
  Muresan, Squire, Tellex, Arumugam, and Yang}]{macglashan2015grounding}
MacGlashan, J.; Babes-Vroman, M.; desJardins, M.; Littman, M.~L.; Muresan, S.;
  Squire, S.; Tellex, S.; Arumugam, D.; and Yang, L. 2015.
\newblock Grounding English Commands to Reward Functions.
\newblock In \emph{Robotics: Science and Systems}.

\bibitem[{MacGlashan et~al.(2017)MacGlashan, Ho, Loftin, Peng, Wang, Roberts,
  Taylor, and Littman}]{macglashan2017interactive}
MacGlashan, J.; Ho, M.~K.; Loftin, R.; Peng, B.; Wang, G.; Roberts, D.~L.;
  Taylor, M.~E.; and Littman, M.~L. 2017.
\newblock Interactive Learning from Policy-Dependent Human Feedback.
\newblock JMLR.

\bibitem[{Maclin and Shavlik(1994)}]{maclin_1994}
Maclin, R.; and Shavlik, J.~W. 1994.
\newblock Incorporating advice into agents that learn from reinforcements.
\newblock AAAI.

\bibitem[{McFadden(1974)}]{mcfadden1974conditional}
McFadden, D. 1974.
\newblock Conditional logit analysis of qualitative choice behavior.
\newblock \emph{Frontiers in {E}conometrics} 105--142.

\bibitem[{Mooney(2008)}]{mooney2008learning}
Mooney, R.~J. 2008.
\newblock Learning to Connect Language and Perception.
\newblock In \emph{AAAI}, 1598--1601.

\bibitem[{Murphy(2007)}]{murphy_2007}
Murphy, K. 2007.
\newblock Conjugate Bayesian analysis of the Gaussian distribution.
\newblock \urlprefix\url{https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf}.
\newblock Accessed 9/15/2020.

\bibitem[{Narasimhan, Barzilay, and Jaakkola(2018)}]{narasimhan2018grounding}
Narasimhan, K.; Barzilay, R.; and Jaakkola, T. 2018.
\newblock Grounding language for transfer in deep reinforcement learning.
\newblock \emph{Journal of Artificial Intelligence Research} 63: 849--874.

\bibitem[{Potts(2012)}]{potts_2012}
Potts, C. 2012.
\newblock Goal-Driven Answers in the {C}ards Dialogue Corpus.
\newblock In Arnett, N.; and Bennett, R., eds., \emph{Proceedings of the 30th
  {W}est {C}oast {C}onference on {F}ormal {L}inguistics}, 1--20.

\bibitem[{Puterman(1994)}]{puterman1994markov}
Puterman, M.~L. 1994.
\newblock \emph{Markov Decision Processes: Discrete Stochastic Dynamic
  Programming}.
\newblock John Wiley \& Sons, Inc.

\bibitem[{Ramachandran and Amir(2007)}]{ramachandran2007bayesian}
Ramachandran, D.; and Amir, E. 2007.
\newblock Bayesian Inverse Reinforcement Learning.
\newblock In \emph{IJCAI}, volume~7, 2586--2591.

\bibitem[{Ross and Bagnell(2010)}]{ross2010efficient}
Ross, S.; and Bagnell, D. 2010.
\newblock Efficient reductions for imitation learning.
\newblock In \emph{AISTATS}, 661--668.

\bibitem[{Shute(2008)}]{shute_2008}
Shute, V.~J. 2008.
\newblock Focus on Formative Feedback.
\newblock \emph{Review of Educational Research} 78(1): 153--189.

\bibitem[{Srivastava, Labutov, and Mitchell(2017)}]{srivastava2017_explanation}
Srivastava, S.; Labutov, I.; and Mitchell, T. 2017.
\newblock Joint Concept Learning and Semantic Parsing from Natural Language
  Explanations.
\newblock In \emph{EMNLP 2017}, 1527--1536. ACL.

\bibitem[{Suhr et~al.(2019)Suhr, Yan, Schluger, Yu, Khader, Mouallem, Zhang,
  and Artzi}]{Suhr_2019}
Suhr, A.; Yan, C.; Schluger, J.; Yu, S.; Khader, H.; Mouallem, M.; Zhang, I.;
  and Artzi, Y. 2019.
\newblock Executing Instructions in Situated Collaborative Interactions.
\newblock \emph{EMNLP 2019} .

\bibitem[{Szlam et~al.(2019)Szlam, Gray, Srinet, Jernite, Joulin, Synnaeve,
  Kiela, Yu, Chen, Goyal, Guo, Rothermel, Zitnick, and Weston}]{szlam2019build}
Szlam, A.; Gray, J.; Srinet, K.; Jernite, Y.; Joulin, A.; Synnaeve, G.; Kiela,
  D.; Yu, H.; Chen, Z.; Goyal, S.; Guo, D.; Rothermel, D.; Zitnick, C.~L.; and
  Weston, J. 2019.
\newblock Why Build an Assistant in Minecraft?
\newblock \emph{arXiv} abs/1907.09273.

\bibitem[{Tellex et~al.(2020)Tellex, Gopalan, Kress-Gazit, and
  Matuszek}]{Tellex2020}
Tellex, S.; Gopalan, N.; Kress-Gazit, H.; and Matuszek, C. 2020.
\newblock Robots That Use Language.
\newblock \emph{Annual Review of Control, Robotics, and Autonomous Systems}
  3(1): 25--55.

\bibitem[{Tellex et~al.(2011)Tellex, Kollar, Dickerson, Walter, Banerjee,
  Teller, and Roy}]{Tellex2011}
Tellex, S.; Kollar, T.; Dickerson, S.; Walter, M.~R.; Banerjee, A.~G.; Teller,
  S.; and Roy, N. 2011.
\newblock Understanding Natural Language Commands for Robotic Navigation and
  Mobile Manipulation.
\newblock In \emph{AAAI}.

\bibitem[{Thomason et~al.(2019)Thomason, Murray, Cakmak, and
  Zettlemoyer}]{thomason2019visionanddialog}
Thomason, J.; Murray, M.; Cakmak, M.; and Zettlemoyer, L. 2019.
\newblock Vision-and-Dialog Navigation.
\newblock \emph{arXiv} abs/1907.04957.

\bibitem[{Thomason et~al.(2020)Thomason, Padmakumar, Sinapov, Walker, Jiang,
  Yedidsion, Hart, Stone, and Mooney}]{thomason_2020}
Thomason, J.; Padmakumar, A.; Sinapov, J.; Walker, N.; Jiang, Y.; Yedidsion,
  H.; Hart, J.; Stone, P.; and Mooney, R.~J. 2020.
\newblock Jointly Improving Parsing and Perception for Natural Language
  Commands through Human-Robot Dialog.
\newblock \emph{The Journal of Artificial Intelligence Research (JAIR)} 67:
  327--374.

\bibitem[{Thomason et~al.(2015)Thomason, Zhang, Mooney, and
  Stone}]{thomason_2015}
Thomason, J.; Zhang, S.; Mooney, R.; and Stone, P. 2015.
\newblock Learning to Interpret Natural Language Commands through Human-Robot
  Dialog.
\newblock In \emph{Proceedings of the 24th International Conference on
  Artificial Intelligence}, IJCAI'15, 1923–1929. AAAI Press.

\bibitem[{Thomaz and Breazeal(2008)}]{thomaz2008teachable}
Thomaz, A.~L.; and Breazeal, C. 2008.
\newblock Teachable robots: Understanding human teaching behavior to build more
  effective robot learners.
\newblock \emph{Artificial Intelligence} 172(6-7): 716--737.

\bibitem[{Tukey(1953)}]{tukey1953section}
Tukey, J.~W. 1953.
\newblock Section of mathematics and engineering: Some selected quick and easy
  methods of statistical analysis.
\newblock \emph{Transactions of the New York Academy of Sciences} 16(2 Series
  II): 88--97.

\bibitem[{Udagawa and Aizawa(2019)}]{Udagawa_2019}
Udagawa, T.; and Aizawa, A. 2019.
\newblock A Natural Language Corpus of Common Grounding under Continuous and
  Partially-Observable Context.
\newblock \emph{AAAI} 33: 7120–7127.
\newblock ISSN 2159-5399.

\bibitem[{van~der Kleij, Feskens, and Eggen(2015)}]{van_der_klej_2015}
van~der Kleij, F.; Feskens, R.; and Eggen, T. 2015.
\newblock Effects of Feedback in a Computer-Based Learning Environment on
  Students' Learning Outcomes: A Meta-Analysis.
\newblock \emph{Review of Educational Research} 85.

\bibitem[{Wang, Liang, and Manning(2016)}]{Wang_2016}
Wang, S.~I.; Liang, P.; and Manning, C.~D. 2016.
\newblock Learning Language Games through Interaction.
\newblock \emph{ACL} .

\bibitem[{Wang et~al.(2019)Wang, Huang, Çelikyilmaz, Gao, Shen, Wang, Wang,
  and Zhang}]{wang_2019_navigation}
Wang, X.; Huang, Q.; Çelikyilmaz, A.; Gao, J.; Shen, D.; Wang, Y.-F.; Wang,
  W.~Y.; and Zhang, L. 2019.
\newblock Reinforced Cross-Modal Matching and Self-Supervised Imitation
  Learning for Vision-Language Navigation.
\newblock In \emph{CVPR}, 6629--6638.

\bibitem[{{Williams} et~al.(2018){Williams}, {Gopalan}, {Rhee}, and
  {Tellex}}]{tellex_2018_rewards}
{Williams}, E.~C.; {Gopalan}, N.; {Rhee}, M.; and {Tellex}, S. 2018.
\newblock Learning to Parse Natural Language to Grounded Reward Functions with
  Weak Supervision.
\newblock In \emph{ICRA}, 4430--4436.

\bibitem[{Xu et~al.(2019)Xu, Liu, Shu, and Philip}]{xu2019bertsentiment}
Xu, H.; Liu, B.; Shu, L.; and Philip, S.~Y. 2019.
\newblock BERT Post-Training for Review Reading Comprehension and Aspect-based
  Sentiment Analysis.
\newblock In \emph{NAACL}.

\bibitem[{Zhou and Small(2020)}]{zhou2020inverse}
Zhou, L.; and Small, K. 2020.
\newblock Inverse Reinforcement Learning with Natural Language Goals.
\newblock \emph{arXiv} abs/2008.06924.

\end{thebibliography}
