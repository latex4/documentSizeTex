\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Bertsekas and
  Tsitsiklis}{1996}]{Bertsekas:1996neuro}
Bertsekas, D.~P., and Tsitsiklis, J.
\newblock 1996.
\newblock {\em Neuro-Dynamic Programming}.
\newblock Athena Scientific.

\bibitem[\protect\citeauthoryear{Brockman \bgroup et al\mbox.\egroup
  }{2016}]{Brockman:2016gym}
Brockman, G.; Cheung, V.; Pettersson, L.; Schneider, J.; Schulman, J.; Tang,
  J.; and Zaremba, W.
\newblock 2016.
\newblock Open{AI} {G}ym.
\newblock {\em arXiv preprint arXiv:1606.01540}.

\bibitem[\protect\citeauthoryear{Duan \bgroup et al\mbox.\egroup
  }{2016}]{Duan:2016benchmarking}
Duan, Y.; Chen, X.; Houthooft, R.; Schulman, J.; and Abbeel, P.
\newblock 2016.
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock In {\em International Conference on Machine Learning},  1329--1338.

\bibitem[\protect\citeauthoryear{Dulac-Arnold \bgroup et al\mbox.\egroup
  }{2015}]{Dulac:2015}
Dulac-Arnold, G.; Evans, R.; van Hasselt, H.; Sunehag, P.; Lillicrap, T.; Hunt,
  J.; Mann, T.; Weber, T.; Degris, T.; and Coppin, B.
\newblock 2015.
\newblock Deep reinforcement learning in large discrete action spaces.
\newblock {\em arXiv preprint arXiv:1512.07679}.

\bibitem[\protect\citeauthoryear{Glorot and Bengio}{2010}]{Glorot:2010xavier}
Glorot, X., and Bengio, Y.
\newblock 2010.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics},  249--256.

\bibitem[\protect\citeauthoryear{Glorot, Bordes, and
  Bengio}{2011}]{Glorot:2011ReLU}
Glorot, X.; Bordes, A.; and Bengio, Y.
\newblock 2011.
\newblock Deep sparse rectifier neural networks.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics},  315--323.

\bibitem[\protect\citeauthoryear{Godfrey-Smith}{2016}]{Godfrey:2016octopus}
Godfrey-Smith, P.
\newblock 2016.
\newblock {\em Other Minds: The Octopus, the Sea, and the Deep Origins of
  Consciousness}.
\newblock Farrar, Straus and Giroux.

\bibitem[\protect\citeauthoryear{Goodfellow, Bengio, and
  Courville}{2016}]{Goodfellow:2016DLbook}
Goodfellow, I.; Bengio, Y.; and Courville, A.
\newblock 2016.
\newblock {\em Deep Learning}.
\newblock MIT Press.

\bibitem[\protect\citeauthoryear{Gu \bgroup et al\mbox.\egroup
  }{2016}]{Gu:2016naf}
Gu, S.; Lillicrap, T.; Sutskever, I.; and Levine, S.
\newblock 2016.
\newblock Continuous deep {Q}-learning with model-based acceleration.
\newblock In {\em International Conference on Machine Learning},  2829--2838.

\bibitem[\protect\citeauthoryear{Gu \bgroup et al\mbox.\egroup
  }{2017}]{Gu:2017qprop}
Gu, S.; Lillicrap, T.; Ghahramani, Z.; Turner, R.~E.; and Levine, S.
\newblock 2017.
\newblock Q-{P}rop: Sample-efficient policy gradient with an off-policy critic.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[\protect\citeauthoryear{Hesse \bgroup et al\mbox.\egroup
  }{2017}]{baselines}
Hesse, C.; Plappert, M.; Radford, A.; Schulman, J.; Sidor, S.; and Wu, Y.
\newblock 2017.
\newblock Open{AI} {B}aselines.
\newblock \url{https://github.com/openai/baselines}.

\bibitem[\protect\citeauthoryear{Hessel \bgroup et al\mbox.\egroup
  }{2017}]{Hessel:2017Rainbow}
Hessel, M.; Modayil, J.; van Hasselt, H.; Schaul, T.; Ostrovski, G.; Dabney,
  W.; Horgan, D.; Piot, B.; Azar, M.; and Silver, D.
\newblock 2017.
\newblock Rainbow: Combining improvements in deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1710.02298}.

\bibitem[\protect\citeauthoryear{Kingma and Ba}{2015}]{Kingma:2015adam}
Kingma, D., and Ba, J.
\newblock 2015.
\newblock {A}dam: A method for stochastic optimization.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[\protect\citeauthoryear{LeCun, Bengio, and
  Hinton}{2015}]{Lecun:2015deep}
LeCun, Y.; Bengio, Y.; and Hinton, G.
\newblock 2015.
\newblock Deep learning.
\newblock {\em Nature} 521(7553):436--444.

\bibitem[\protect\citeauthoryear{Lillicrap \bgroup et al\mbox.\egroup
  }{2016}]{Lillicrap:2016ddpg}
Lillicrap, T.~P.; Hunt, J.~J.; Pritzel, A.; Heess, N.; Erez, T.; Tassa, Y.;
  Silver, D.; and Wierstra, D.
\newblock 2016.
\newblock Continuous control with deep reinforcement learning.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[\protect\citeauthoryear{Matignon, Laurent, and
  Le~Fort-Piat}{2012}]{Matignon:2012independent}
Matignon, L.; Laurent, G.~J.; and Le~Fort-Piat, N.
\newblock 2012.
\newblock Independent reinforcement learners in cooperative markov games: A
  survey regarding coordination problems.
\newblock {\em The Knowledge Engineering Review} 27(1):1--31.

\bibitem[\protect\citeauthoryear{Metz \bgroup et al\mbox.\egroup
  }{2017}]{Metz:2017}
Metz, L.; Ibarz, J.; Jaitly, N.; and Davidson, J.
\newblock 2017.
\newblock Discrete sequential prediction of continuous actions for deep
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:1705.05035}.

\bibitem[\protect\citeauthoryear{Mnih \bgroup et al\mbox.\egroup
  }{2013}]{Mnih:2013}
Mnih, V.; Kavukcuoglu, K.; Silver, D.; Graves, A.; Antonoglou, I.; Wierstra,
  D.; and Riedmiller, M.
\newblock 2013.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1312.5602}.

\bibitem[\protect\citeauthoryear{Mnih \bgroup et al\mbox.\egroup
  }{2015}]{Mnih:2015natureDQN}
Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A.~A.; Veness, J.; Bellemare,
  M.~G.; Graves, A.; Riedmiller, M.; Fidjeland, A.~K.; Ostrovski, G.; Petersen,
  S.; Beattie, C.; Sadik, A.; Antonoglou, I.; King, H.; Kumaran, D.; Wierstra,
  D.; Legg, S.; and Hassabis, D.
\newblock 2015.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature} 518(7540):529--533.

\bibitem[\protect\citeauthoryear{Schaul \bgroup et al\mbox.\egroup
  }{2016}]{Schaul:2016prior}
Schaul, T.; Quan, J.; Antonoglou, I.; and Silver, D.
\newblock 2016.
\newblock Prioritized experience replay.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[\protect\citeauthoryear{Schmidhuber}{2015}]{Schmidhuber:2015NN}
Schmidhuber, J.
\newblock 2015.
\newblock Deep learning in neural networks: An overview.
\newblock {\em Neural Networks} 61:85--117.

\bibitem[\protect\citeauthoryear{Schulman \bgroup et al\mbox.\egroup
  }{2017}]{Schulman:2017ppo}
Schulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; and Klimov, O.
\newblock 2017.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}.

\bibitem[\protect\citeauthoryear{Silver \bgroup et al\mbox.\egroup
  }{2016}]{Silver:2016AlphaGo}
Silver, D.; Huang, A.; Maddison, C.~J.; Guez, A.; Sifre, L.; van~den Driessche,
  G.; Schrittwieser, J.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.;
  Dieleman, S.; Grewe, D.; Nham, J.; Kalchbrenner, N.; Sutskever, I.;
  Lillicrap, T.; Leach, M.; Kavukcuoglu, K.; Graepel, T.; and Hassabis, D.
\newblock 2016.
\newblock Mastering the game of {Go} with deep neural networks and tree search.
\newblock {\em Nature} 529(7587):484--489.

\bibitem[\protect\citeauthoryear{Silver \bgroup et al\mbox.\egroup
  }{2017}]{Silver:2017AlphaGoZero}
Silver, D.; Schrittwieser, J.; Simonyan, K.; Antonoglou, I.; Huang, A.; Guez,
  A.; Hubert, T.; Baker, L.; Lai, M.; Bolton, A.; Chen, Y.; Lillicrap, T.; Hui,
  F.; Sifre, L.; van~den Driessche, G.; Graepel, T.; and Hassabis, D.
\newblock 2017.
\newblock Mastering the game of {Go} without human knowledge.
\newblock {\em Nature} 550(7676):354--359.

\bibitem[\protect\citeauthoryear{Sutton and Barto}{1998}]{Sutton:1998RLbook}
Sutton, R.~S., and Barto, A.~G.
\newblock 1998.
\newblock {\em Reinforcement Learning: An Introduction}.
\newblock MIT Press.

\bibitem[\protect\citeauthoryear{Szepesv\'ari}{2010}]{Szepesvari:2010algorithms}
Szepesv\'ari, C.
\newblock 2010.
\newblock {\em Algorithms for Reinforcement Learning}.
\newblock Morgan and Claypool.

\bibitem[\protect\citeauthoryear{Tampuu \bgroup et al\mbox.\egroup
  }{2017}]{Tampuu:2017independentDQN}
Tampuu, A.; Matiisen, T.; Kodelja, D.; Kuzovkin, I.; Korjus, K.; Aru, J.; Aru,
  J.; and Vicente, R.
\newblock 2017.
\newblock Multiagent cooperation and competition with deep reinforcement
  learning.
\newblock {\em PLOS ONE} 12(4):1--15.

\bibitem[\protect\citeauthoryear{Todorov, Erez, and
  Tassa}{2012}]{Todorov:2012mujoco}
Todorov, E.; Erez, T.; and Tassa, Y.
\newblock 2012.
\newblock {MuJoCo}: a physics engine for model-based control.
\newblock In {\em IEEE/RSJ International Conference on Intelligent Robots and
  Systems},  5026--5033.

\bibitem[\protect\citeauthoryear{Uhlenbeck and
  Ornstein}{1930}]{Uhlenbeck:1930theory}
Uhlenbeck, G.~E., and Ornstein, L.~S.
\newblock 1930.
\newblock On the theory of the {B}rownian motion.
\newblock {\em Physical Review} 36(5):823--841.

\bibitem[\protect\citeauthoryear{van Hasselt, Guez, and
  Silver}{2016}]{Hasselt:2016ddq}
van Hasselt, H.; Guez, A.; and Silver, D.
\newblock 2016.
\newblock Deep reinforcement learning with double {Q}-learning.
\newblock In {\em AAAI Conference on Artificial Intelligence},  2094--2100.

\bibitem[\protect\citeauthoryear{van Hasselt}{2010}]{Hasselt:2010dq}
van Hasselt, H.
\newblock 2010.
\newblock Double {Q}-learning.
\newblock In {\em Advances in Neural Information Processing Systems},
  2613--2621.

\bibitem[\protect\citeauthoryear{Wang \bgroup et al\mbox.\egroup
  }{2016}]{Wang:2016}
Wang, Z.; Schaul, T.; Hessel, M.; van Hasselt, H.; Lanctot, M.; and de~Freitas,
  N.
\newblock 2016.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock In {\em International Conference on Machine Learning},  1995--2003.

\bibitem[\protect\citeauthoryear{Watkins and Dayan}{1992}]{Watkins:1992Q}
Watkins, C. J. C.~H., and Dayan, P.
\newblock 1992.
\newblock {Q}-learning.
\newblock {\em Machine Learning} 8(3):279--292.

\end{thebibliography}
