@article{blackwell1962discrete,
  title={Discrete dynamic programming},
  author={Blackwell, David},
  journal={The Annals of Mathematical Statistics},
  pages={719--726},
  year={1962},
  publisher={JSTOR}
}

@article{praRL,
  title={Reinforcement learning with function approximation for traffic signal control},
  author={Prashanth, LA and Bhatnagar, Shalabh},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={12},
  number={2},
  pages={412--421},
  year={2010},
  publisher={IEEE}
}

@article{HARRL,
  title={Hierarchical average reward reinforcement learning},
  author={Ghavamzadeh, Mohammad and Mahadevan, Sridhar},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={Nov},
  pages={2629--2669},
  year={2007}
}

@article{RAllocEmergency,
  title={A scenario planning approach for the flood emergency logistics preparation problem under uncertainty},
  author={Chang, Mei-Shiang and Tseng, Ya-Ling and Chen, Jing-Wen},
  journal={Transportation Research Part E: Logistics and Transportation Review},
  volume={43},
  number={6},
  pages={737--754},
  year={2007},
  publisher={Elsevier}
}

@article{RAllocDTN,
 author = {Balasubramanian, Aruna and Levine, Brian and Venkataramani, Arun},
 title = {DTN Routing As a Resource Allocation Problem},
 journal = {SIGCOMM Comput. Commun. Rev.},
 issue_date = {October 2007},
 volume = {37},
 number = {4},
 month = aug,
 year = {2007},
 issn = {0146-4833},
 pages = {373--384},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1282427.1282422},
 doi = {10.1145/1282427.1282422},
 acmid = {1282422},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {DTN, deployment, mobility, routing, utility},
} 

@article{RAllocEarthquake,
  title={Optimized resource allocation for emergency response after earthquake disasters},
  author={Fiedrich, Frank and Gehbauer, Fritz and Rickers, Uwe},
  journal={Safety science},
  volume={35},
  number={1-3},
  pages={41--57},
  year={2000},
  publisher={Elsevier}
}

@Article{AvgRewFoundtionsMahadevan,
author="Mahadevan, Sridhar",
title="Average Reward Reinforcement Learning: Foundations, Algorithms, and Empirical Results",
journal="Machine Learning",
year="1996",
month="Jan",
day="01",
volume="22",
number="1",
pages="159--195",
issn="1573-0565",
doi="10.1023/A:1018064306595",
url="https://doi.org/10.1023/A:1018064306595"
}

@book{ModContrSystems,
  title={Modern control systems},
  author={Dorf, Richard C and Bishop, Robert H},
  year={2011},
  publisher={Pearson}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, et. all},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{oc,
  title={The option-critic architecture},
  author={Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{hoc,
  title={Learning abstract options},
  author={Riemer, Matthew and Liu, Miao and Tesauro, Gerald},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10424--10434},
  year={2018}
}

@article{inventoryMan,
  title={Inventory management in supply chains: a reinforcement learning approach},
  author={Giannoccaro, Ilaria and Pontrandolfo, Pierpaolo},
  journal={International Journal of Production Economics},
  volume={78},
  number={2},
  pages={153--161},
  year={2002},
  publisher={Elsevier}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@inproceedings{feudal,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3540--3549},
  year={2017},
  organization={JMLR. org}
}

@book{bertsekas1995dynamic,
  title={Dynamic programming and optimal control},
  author={Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P},
  volume={1},
  number={2},
  year={1995},
  publisher={Athena scientific Belmont, MA}
}

@article{bhatnagar2009natural,
  title={Natural actor--critic algorithms},
  author={Bhatnagar, Shalabh and Sutton, Richard S and Ghavamzadeh, Mohammad and Lee, Mark},
  journal={Automatica},
  volume={45},
  number={11},
  pages={2471--2482},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{prashanth2011AverageTraffic,
  title={Reinforcement learning with average cost for adaptive control of traffic lights at intersections},
  author={Prashanth, LA and Bhatnagar, Shalabh},
  booktitle={2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC)},
  pages={1640--1645},
  year={2011},
  organization={IEEE}
}

@inproceedings{mahadevanFactoryAvRew1997self,
  title={Self-improving factory simulation using continuous-time average-reward reinforcement learning},
  year="1997",
  author={Mahadevan, Sridhar and Marchalleck, Nicholas and Das, Tapas K and Gosavi, Abhijit}
}

@Article{Gosavi2004AirlineAvRew,
author="Gosavi, Abhijit",
title="A Reinforcement Learning Algorithm Based on Policy Iteration for Average Reward: Empirical Results with Yield Management and Convergence Analysis",
journal="Machine Learning",
year="2004",
month="Apr",
day="01",
volume="55",
number="1",
pages="5--29",
doi="10.1023/B:MACH.0000019802.64038.6c",
url="https://doi.org/10.1023/B:MACH.0000019802.64038.6c"
}

@paper{AAAI2016EffAvRewRL,
	author = {Shangdong Yang and Yang Gao and Bo An and Hao Wang and Xingguo Chen},
	title = {Efficient Average Reward Reinforcement Learning Using Constant Shifting Values},
	conference = {AAAI Conference on Artificial Intelligence},
	year = {2016},
	keywords = {Reinforcement Learning; Average Reward; Constant Shifting Value},
	url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12346}
}

@article{jmlr,
  title={Hierarchical average reward reinforcement learning},
  author={Ghavamzadeh, Mohammad and Mahadevan, Sridhar},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={Nov},
  pages={2629--2669},
  year={2007}
}

@inproceedings{ortner2012online,
  title={Online regret bounds for undiscounted continuous reinforcement learning},
  author={Ortner, Ronald and Ryabko, Daniil},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1763--1771},
  year={2012}
}

@paper{ARDCOP,
	author = {Duc Thien Nguyen and William Yeoh and Hoong Chuin Lau and Shlomo Zilberstein and Chongjie Zhang},
	title = {Decentralized Multi-Agent Reinforcement Learning in Average-Reward Dynamic DCOPs},
	conference = {AAAI Conference on Artificial Intelligence},
	year = {2014},
	keywords = {},
	url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8413}
}

@inproceedings{Levy2011,
  title={Unified inter and intra options learning using policy gradient methods},
  author={Levy, Kfir Y and Shimkin, Nahum},
  booktitle={European Workshop on Reinforcement Learning},
  pages={153--164},
  year={2011},
  organization={Springer}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{ppo,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{ddpg,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{ham,
  title={Reinforcement learning with hierarchies of machines},
  author={Parr, Ronald and Russell, Stuart J},
  booktitle={Advances in neural information processing systems},
  pages={1043--1049},
  year={1998}
}

@article{MAXQ,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of Artificial Intelligence Research},
  volume={13},
  pages={227--303},
  year={2000}
}

@article{smdp,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{lapOptionDiscovery,
  title={A laplacian framework for option discovery in reinforcement learning},
  author={Machado, Marios C and Bellemare, Marc G and Bowling, Michael},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2295--2304},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{thrun1995finding,
  title={Finding structure in reinforcement learning},
  author={Thrun, Sebastian and Schwartz, Anton},
  booktitle={Advances in neural information processing systems},
  pages={385--392},
  year={1995}
}

@inproceedings{skillDiscovery2009,
  title={Skill discovery in continuous reinforcement learning domains using skill chaining},
  author={Konidaris, George and Barto, Andrew G},
  booktitle={Advances in neural information processing systems},
  pages={1015--1023},
  year={2009}
}

@inproceedings{nonLinConv,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S and Maei, Hamid R and Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1204--1212},
  year={2009}
}

@article{blackbox,
  title={A survey of methods for explaining black box models},
  author={Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
  journal={ACM computing surveys (CSUR)},
  volume={51},
  number={5},
  pages={93},
  year={2018},
  publisher={ACM}
}

@article{konda1999actor,
  title={Actor-Critic--Type Learning Algorithms for Markov Decision Processes},
  author={Konda, Vijaymohan R and Borkar, Vivek S},
  journal={SIAM Journal on control and Optimization},
  volume={38},
  number={1},
  pages={94--123},
  year={1999},
  publisher={SIAM}
}

@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1075--1081},
  year={1997}
}

@book{bhatnagarSPSABook,
  title={Stochastic recursive algorithms for optimization: simultaneous perturbation methods},
  author={Bhatnagar, Shalabh and Prasad, HL and Prashanth, LA},
  volume={434},
  year={2012},
  publisher={Springer}
}

@incollection{GANconvProof,
title = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {6626--6637},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7240-gans-trained-by-a-two-time-scale-update-rule-converge-to-a-local-nash-equilibrium.pdf}
}

@inproceedings{naturalACTraffic,
  title={Natural actor-critic for road traffic optimisation},
  author={Richter, Silvia and Aberdeen, Douglas and Yu, Jin},
  booktitle={Advances in neural information processing systems},
  pages={1169--1176},
  year={2007}
}

@inproceedings{mitHRL,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
  booktitle={Advances in neural information processing systems},
  pages={3675--3683},
  year={2016}
}

@inproceedings{flowLagra,
  title={Lagrangian control through deep-rl: Applications to bottleneck decongestion},
  author={Vinitsky, Eugene and Parvate, Kanaad and Kreidieh, Aboudy and Wu, Cathy and Bayen, Alexandre},
  booktitle={2018 21st International Conference on Intelligent Transportation Systems (ITSC)},
  pages={759--765},
  year={2018},
  organization={IEEE}
}

@article{flow,
  title={Flow: Architecture and benchmarking for reinforcement learning in traffic control},
  author={Wu, Cathy and Kreidieh, Aboudy and Parvate, Kanaad and Vinitsky, Eugene and Bayen, Alexandre M},
  journal={arXiv preprint arXiv:1710.05465},
  year={2017}
}

@inproceedings{AAAIAvRew,
  title={Efficient average reward reinforcement learning using constant shifting values},
  author={Yang, Shangdong and Gao, Yang and An, Bo and Wang, Hao and Chen, Xingguo},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@article{options,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{weightsharingandoptions,
 title={On the Role of Weight Sharing During Deep Option Learning},
 author={Riemer, Matthew and Cases, Ignacio and Rosenbaum, Clemens and Liu, Miao and Tesauro, Gerald},
 journal={arXiv preprint},
 year={2019}
}

@inproceedings{weightsharingAAAI,
  title={On the Role of Weight Sharing During Deep Option Learning},
  author={Riemer, Matthew and Cases, Ignacio and Rosenbaum, Clemens and Liu, Miao and Tesauro, Gerald},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{abstractoptions,
  title={Learning abstract options},
  author={Riemer, Matthew and Liu, Miao and Tesauro, Gerald},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10424--10434},
  year={2018}
}