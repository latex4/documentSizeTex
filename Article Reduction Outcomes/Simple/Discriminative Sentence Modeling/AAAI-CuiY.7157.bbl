\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Abadi \bgroup et al\mbox.\egroup
  }{2016}]{abadi2016tensorflow}
Abadi, M.; Barham, P.; Chen, J.; Chen, Z.; Davis, A.; Dean, J.; Devin, M.;
  Ghemawat, S.; Irving, G.; Isard, M.; et~al.
\newblock 2016.
\newblock Tensorflow: a system for large-scale machine learning.
\newblock In {\em OSDI}, volume~16,  265--283.

\bibitem[\protect\citeauthoryear{Bird and Loper}{2004}]{nltk}
Bird, S., and Loper, E.
\newblock 2004.
\newblock Nltk: The natural language toolkit.
\newblock In {\em Proceedings of the ACL Interactive Poster and Demonstration
  Sessions}.

\bibitem[\protect\citeauthoryear{Cai, Tu, and Gimpel}{2017}]{cai-etal-2017}
Cai, Z.; Tu, L.; and Gimpel, K.
\newblock 2017.
\newblock Pay attention to the ending:strong neural baselines for the roc story
  cloze task.
\newblock In {\em Proceedings of ACL 2017 (Volume 2: Short Papers)},  616--622.

\bibitem[\protect\citeauthoryear{Chaturvedi, Peng, and
  Roth}{2017}]{chaturvedi-etal-2017}
Chaturvedi, S.; Peng, H.; and Roth, D.
\newblock 2017.
\newblock Story comprehension for predicting what happens next.
\newblock In {\em Proceedings of EMNLP 2017},  1604--1615.

\bibitem[\protect\citeauthoryear{Chen, Qiu, and
  Huang}{2016}]{chen-etal-2016-order}
Chen, X.; Qiu, X.; and Huang, X.
\newblock 2016.
\newblock Neural sentence ordering.
\newblock {\em arXiv preprint arXiv:1607.06952}.

\bibitem[\protect\citeauthoryear{Chollet}{2015}]{chollet2015keras}
Chollet, F.
\newblock 2015.
\newblock Keras.
\newblock \url{https://github.com/fchollet/keras}.

\bibitem[\protect\citeauthoryear{Chopra, Hadsell, and
  LeCun}{2005}]{chopra-etal-2005}
Chopra, S.; Hadsell, R.; and LeCun, Y.
\newblock 2005.
\newblock Learning a similarity metric discriminatively, with application to
  face verification.
\newblock In {\em CVPR 2005}, volume~1,  539--546.
\newblock IEEE.

\bibitem[\protect\citeauthoryear{Cui \bgroup et al\mbox.\egroup
  }{2016}]{cui-etal-2016}
Cui, Y.; Liu, T.; Chen, Z.; Wang, S.; and Hu, G.
\newblock 2016.
\newblock Consensus attention-based neural networks for chinese reading
  comprehension.
\newblock In {\em Proceedings of COLING 2016, the 26th International Conference
  on Computational Linguistics: Technical Papers},  1777--1786.
\newblock The COLING 2016 Organizing Committee.

\bibitem[\protect\citeauthoryear{Cui \bgroup et al\mbox.\egroup
  }{2017}]{cui-acl2017-aoa}
Cui, Y.; Chen, Z.; Wei, S.; Wang, S.; Liu, T.; and Hu, G.
\newblock 2017.
\newblock Attention-over-attention neural networks for reading comprehension.
\newblock In {\em Proceedings of the 55th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)},  593--602.
\newblock Association for Computational Linguistics.

\bibitem[\protect\citeauthoryear{Devlin \bgroup et al\mbox.\egroup
  }{2019}]{devlin2018bert}
Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K.
\newblock 2019.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)},  4171--4186.
\newblock Minneapolis, Minnesota: Association for Computational Linguistics.

\bibitem[\protect\citeauthoryear{Dhingra \bgroup et al\mbox.\egroup
  }{2017}]{dhingra-etal-2017}
Dhingra, B.; Liu, H.; Yang, Z.; Cohen, W.; and Salakhutdinov, R.
\newblock 2017.
\newblock Gated-attention readers for text comprehension.
\newblock In {\em Proceedings of ACL 2017},  1832--1846.

\bibitem[\protect\citeauthoryear{Graves and
  Schmidhuber}{2005}]{graves-etal-2005}
Graves, A., and Schmidhuber, J.
\newblock 2005.
\newblock Framewise phoneme classification with bidirectional lstm and other
  neural network architectures.
\newblock {\em Neural Networks} 18(5):602--610.

\bibitem[\protect\citeauthoryear{Hermann \bgroup et al\mbox.\egroup
  }{2015}]{hermann-etal-2015}
Hermann, K.~M.; Kocisky, T.; Grefenstette, E.; Espeholt, L.; Kay, W.; Suleyman,
  M.; and Blunsom, P.
\newblock 2015.
\newblock Teaching machines to read and comprehend.
\newblock In {\em Advances in Neural Information Processing Systems},
  1684--1692.

\bibitem[\protect\citeauthoryear{Hill \bgroup et al\mbox.\egroup
  }{2015}]{hill-etal-2015}
Hill, F.; Bordes, A.; Chopra, S.; and Weston, J.
\newblock 2015.
\newblock The goldilocks principle: Reading children's books with explicit
  memory representations.
\newblock {\em arXiv preprint arXiv:1511.02301}.

\bibitem[\protect\citeauthoryear{Kadlec \bgroup et al\mbox.\egroup
  }{2016}]{kadlec-etal-2016}
Kadlec, R.; Schmid, M.; Bajgar, O.; and Kleindienst, J.
\newblock 2016.
\newblock Text understanding with the attention sum reader network.
\newblock In {\em Proceedings of ACL 2016 (Volume 1: Long Papers)},  908--918.

\bibitem[\protect\citeauthoryear{Kingma and Ba}{2014}]{kingma2014adam}
Kingma, D., and Ba, J.
\newblock 2014.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}.

\bibitem[\protect\citeauthoryear{Klambauer \bgroup et al\mbox.\egroup
  }{2017}]{klambauer-etal-2017}
Klambauer, G.; Unterthiner, T.; Mayr, A.; and Hochreiter, S.
\newblock 2017.
\newblock Self-normalizing neural networks.
\newblock In {\em Advances in Neural Information Processing Systems},
  972--981.

\bibitem[\protect\citeauthoryear{Lin, Sun, and Han}{2017}]{lin-etal-2017}
Lin, H.; Sun, L.; and Han, X.
\newblock 2017.
\newblock Reasoning with heterogeneous knowledge for commonsense machine
  comprehension.
\newblock In {\em Proceedings of EMNLP 2017},  2032--2043.
\newblock ACL.

\bibitem[\protect\citeauthoryear{Liu \bgroup et al\mbox.\egroup
  }{2017}]{liu-etal-2017}
Liu, T.; Cui, Y.; Yin, Q.; Zhang, W.-N.; Wang, S.; and Hu, G.
\newblock 2017.
\newblock Generating and exploiting large-scale pseudo training data for zero
  pronoun resolution.
\newblock In {\em Proceedings of the 55th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)},  102--111.
\newblock ACL.

\bibitem[\protect\citeauthoryear{Mostafazadeh \bgroup et al\mbox.\egroup
  }{2016}]{mostafazadeh-etal-2016}
Mostafazadeh, N.; Chambers, N.; He, X.; Parikh, D.; Batra, D.; Vanderwende, L.;
  Kohli, P.; and Allen, J.
\newblock 2016.
\newblock A corpus and cloze evaluation for deeper understanding of commonsense
  stories.
\newblock In {\em Proceedings of NAACL 2016},  839--849.

\bibitem[\protect\citeauthoryear{Pascanu, Mikolov, and
  Bengio}{2013}]{pascanu-etal-2013}
Pascanu, R.; Mikolov, T.; and Bengio, Y.
\newblock 2013.
\newblock On the difficulty of training recurrent neural networks.
\newblock {\em ICML (3)} 28:1310--1318.

\bibitem[\protect\citeauthoryear{Pennington, Socher, and
  Manning}{2014}]{pennington-etal-2014}
Pennington, J.; Socher, R.; and Manning, C.
\newblock 2014.
\newblock Glove: Global vectors for word representation.
\newblock In {\em Proceedings of EMNLP 2014},  1532--1543.

\bibitem[\protect\citeauthoryear{Porter}{1980}]{porter1980algorithm}
Porter, M.~F.
\newblock 1980.
\newblock An algorithm for suffix stripping.
\newblock {\em Program} 14(3):130--137.

\bibitem[\protect\citeauthoryear{Radford \bgroup et al\mbox.\egroup
  }{2018}]{openai-gpt}
Radford, A.; Narasimhan, K.; Salimans, T.; and Sutskever, I.
\newblock 2018.
\newblock Improving language understanding by generative pre-training.

\bibitem[\protect\citeauthoryear{Rajpurkar \bgroup et al\mbox.\egroup
  }{2016}]{rajpurkar-etal-2016}
Rajpurkar, P.; Zhang, J.; Lopyrev, K.; and Liang, P.
\newblock 2016.
\newblock Squad: 100,000+ questions for machine comprehension of text.
\newblock In {\em Proceedings of EMNLP 2016},  2383--2392.

\bibitem[\protect\citeauthoryear{Schwartz \bgroup et al\mbox.\egroup
  }{2017}]{schwartz-etal-2017}
Schwartz, R.; Sap, M.; Konstas, I.; Zilles, L.; Choi, Y.; and Smith, N.~A.
\newblock 2017.
\newblock The effect of different writing tasks on linguistic style: A case
  study of the {ROC} story cloze task.
\newblock In {\em Proceedings of the 21st Conference on Computational Natural
  Language Learning ({C}o{NLL} 2017)},  15--25.
\newblock Vancouver, Canada: Association for Computational Linguistics.

\bibitem[\protect\citeauthoryear{Seo \bgroup et al\mbox.\egroup
  }{2016}]{seo-etal-2016}
Seo, M.; Kembhavi, A.; Farhadi, A.; and Hajishirzi, H.
\newblock 2016.
\newblock Bi-directional attention flow for machine comprehension.
\newblock {\em arXiv preprint arXiv:1611.01603}.

\bibitem[\protect\citeauthoryear{Sharma \bgroup et al\mbox.\egroup
  }{2018}]{sharma-etal-2018-tackling}
Sharma, R.; Allen, J.; Bakhshandeh, O.; and Mostafazadeh, N.
\newblock 2018.
\newblock Tackling the story ending biases in the story cloze test.
\newblock In {\em Proceedings of the 56th Annual Meeting of the Association for
  Computational Linguistics (Volume 2: Short Papers)},  752--757.
\newblock Melbourne, Australia: Association for Computational Linguistics.

\bibitem[\protect\citeauthoryear{Srivastava \bgroup et al\mbox.\egroup
  }{2014}]{srivastava-etal-2014}
Srivastava, N.; Hinton, G.~E.; Krizhevsky, A.; Sutskever, I.; and
  Salakhutdinov, R.
\newblock 2014.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock {\em Journal of Machine Learning Research} 15(1):1929--1958.

\bibitem[\protect\citeauthoryear{Srivastava, Greff, and
  Schmidhuber}{2015}]{srivastava-etal-2015}
Srivastava, R.~K.; Greff, K.; and Schmidhuber, J.
\newblock 2015.
\newblock Highway networks.
\newblock {\em arXiv preprint arXiv:1505.00387}.

\bibitem[\protect\citeauthoryear{Wang and Jiang}{2016}]{wang-and-jiang-2016}
Wang, S., and Jiang, J.
\newblock 2016.
\newblock Machine comprehension using match-lstm and answer pointer.
\newblock {\em arXiv preprint arXiv:1608.07905}.

\bibitem[\protect\citeauthoryear{Wang, Liu, and
  Zhao}{2017}]{bingning-etal-2017}
Wang, B.; Liu, K.; and Zhao, J.
\newblock 2017.
\newblock Conditional generative adversarial networks for commonsense machine
  comprehension.
\newblock In {\em Proceedings of IJCAI-17},  4123--4129.

\end{thebibliography}
