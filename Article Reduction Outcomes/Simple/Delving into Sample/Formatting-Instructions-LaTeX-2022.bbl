\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Antoniou, Edwards, and Storkey(2019)}]{antoniou2018train}
Antoniou, A.; Edwards, H.; and Storkey, A.~J. 2019.
\newblock How to train your MAML.
\newblock In \emph{ICLR}.

\bibitem[{Bengio et~al.(2009)Bengio, Louradour, Collobert, and
  Weston}]{bengio2009curriculum}
Bengio, Y.; Louradour, J.; Collobert, R.; and Weston, J. 2009.
\newblock Curriculum learning.
\newblock In \emph{ICML}.

\bibitem[{Brooks(2011)}]{brooks2011support}
Brooks, J.~P. 2011.
\newblock Support vector machines with the ramp loss and the hard margin loss.
\newblock \emph{Operations research}, 59(2): 467--479.

\bibitem[{Cao et~al.(2021)Cao, Chen, Lu, Arechiga, Gaidon, and
  Ma}]{cao2020heteroskedastic}
Cao, K.; Chen, Y.; Lu, J.; Arechiga, N.; Gaidon, A.; and Ma, T. 2021.
\newblock Heteroskedastic and imbalanced deep learning with adaptive
  regularization.
\newblock In \emph{ICLR}.

\bibitem[{Cao et~al.(2019)Cao, Wei, Gaidon, Arechiga, and Ma}]{cao2019learning}
Cao, K.; Wei, C.; Gaidon, A.; Arechiga, N.; and Ma, T. 2019.
\newblock Learning Imbalanced Datasets with Label-Distribution-Aware Margin
  Loss.
\newblock In \emph{NeurIPS}.

\bibitem[{Cui et~al.(2019)Cui, Jia, Lin, Song, and Belongie}]{cui2019class}
Cui, Y.; Jia, M.; Lin, T.-Y.; Song, Y.; and Belongie, S. 2019.
\newblock Class-balanced loss based on effective number of samples.
\newblock In \emph{CVPR}.

\bibitem[{Cui et~al.(2018)Cui, Song, Sun, Howard, and Belongie}]{cui2018large}
Cui, Y.; Song, Y.; Sun, C.; Howard, A.; and Belongie, S. 2018.
\newblock Large scale fine-grained categorization and domain-specific transfer
  learning.
\newblock In \emph{CVPR}.

\bibitem[{Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei}]{5206848}
Deng, J.; Dong, W.; Socher, R.; Li, L.-J.; Li, K.; and Fei-Fei, L. 2009.
\newblock ImageNet: A large-scale hierarchical image database.
\newblock In \emph{CVPR}.

\bibitem[{Dong, Gong, and Zhu(2017)}]{dong2017class}
Dong, Q.; Gong, S.; and Zhu, X. 2017.
\newblock Class rectification hard mining for imbalanced deep learning.
\newblock In \emph{ICCV}.

\bibitem[{Finn, Abbeel, and Levine(2017)}]{finn2017model}
Finn, C.; Abbeel, P.; and Levine, S. 2017.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{ICML}.

\bibitem[{Freund and Schapire(1997)}]{freund1997decision}
Freund, Y.; and Schapire, R.~E. 1997.
\newblock A decision-theoretic generalization of on-line learning and an
  application to boosting.
\newblock \emph{Journal of computer and system sciences}, 55(1): 119--139.

\bibitem[{Goldberger and Ben{-}Reuven(2017)}]{goldberger2016training}
Goldberger, J.; and Ben{-}Reuven, E. 2017.
\newblock Training deep neural-networks using a noise adaptation layer.
\newblock In \emph{ICLR}.

\bibitem[{Han et~al.(2018)Han, Yao, Yu, Niu, Xu, Hu, Tsang, and
  Sugiyama}]{han2018co}
Han, B.; Yao, Q.; Yu, X.; Niu, G.; Xu, M.; Hu, W.; Tsang, I.; and Sugiyama, M.
  2018.
\newblock Co-teaching: Robust Training of Deep Neural Networks with Extremely
  Noisy Labels.
\newblock In \emph{NeurIPS}.

\bibitem[{Han, Luo, and Wang(2019)}]{han2019deep}
Han, J.; Luo, P.; and Wang, X. 2019.
\newblock Deep self-learning from noisy labels.
\newblock In \emph{ICCV}.

\bibitem[{He and Garcia(2009)}]{he2009learning}
He, H.; and Garcia, E.~A. 2009.
\newblock Learning from imbalanced data.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering}, 21(9):
  1263--1284.

\bibitem[{He et~al.(2016)He, Zhang, Ren, and Sun}]{he2016deep}
He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}.

\bibitem[{Hendrycks et~al.(2018)Hendrycks, Mazeika, Wilson, and
  Gimpel}]{hendrycks2018using}
Hendrycks, D.; Mazeika, M.; Wilson, D.; and Gimpel, K. 2018.
\newblock Using Trusted Data to Train Deep Networks on Labels Corrupted by
  Severe Noise.
\newblock In \emph{NeurIPS}.

\bibitem[{Hu, Shen, and Sun(2018)}]{hu2018squeeze}
Hu, J.; Shen, L.; and Sun, G. 2018.
\newblock Squeeze-and-excitation networks.
\newblock In \emph{CVPR}.

\bibitem[{Huang et~al.(2016)Huang, Li, Loy, and Tang}]{huang2016learning}
Huang, C.; Li, Y.; Loy, C.~C.; and Tang, X. 2016.
\newblock Learning deep representation for imbalanced classification.
\newblock In \emph{CVPR}.

\bibitem[{Huang et~al.(2019)Huang, Qu, Jia, and Zhao}]{huang2019o2u}
Huang, J.; Qu, L.; Jia, R.; and Zhao, B. 2019.
\newblock O2u-net: A simple noisy label detection approach for deep neural
  networks.
\newblock In \emph{ICCV}.

\bibitem[{Jiang et~al.(2014{\natexlab{a}})Jiang, Meng, Mitamura, and
  Hauptmann}]{jiang2014easy}
Jiang, L.; Meng, D.; Mitamura, T.; and Hauptmann, A.~G. 2014{\natexlab{a}}.
\newblock Easy samples first: Self-paced reranking for zero-example multimedia
  search.
\newblock In \emph{ACM MM}.

\bibitem[{Jiang et~al.(2014{\natexlab{b}})Jiang, Meng, Yu, Lan, Shan, and
  Hauptmann}]{jiang2014self}
Jiang, L.; Meng, D.; Yu, S.-I.; Lan, Z.; Shan, S.; and Hauptmann, A.
  2014{\natexlab{b}}.
\newblock Self-paced learning with diversity.
\newblock In \emph{NeurIPS}.

\bibitem[{Jiang et~al.(2018)Jiang, Zhou, Leung, Li, and
  Fei-Fei}]{jiang2018mentornet}
Jiang, L.; Zhou, Z.; Leung, T.; Li, L.-J.; and Fei-Fei, L. 2018.
\newblock Mentornet: Learning data-driven curriculum for very deep neural
  networks on corrupted labels.
\newblock In \emph{ICML}.

\bibitem[{Kang et~al.(2019)Kang, Xie, Rohrbach, Yan, Gordo, Feng, and
  Kalantidis}]{kang2019decoupling}
Kang, B.; Xie, S.; Rohrbach, M.; Yan, Z.; Gordo, A.; Feng, J.; and Kalantidis,
  Y. 2019.
\newblock Decoupling Representation and Classifier for Long-Tailed Recognition.
\newblock In \emph{ICLR}.

\bibitem[{Krizhevsky, Hinton et~al.(2009)}]{krizhevsky2009learning}
Krizhevsky, A.; Hinton, G.; et~al. 2009.
\newblock Learning multiple layers of features from tiny images.

\bibitem[{Kumar, Packer, and Koller(2010)}]{kumar2010self}
Kumar, M.~P.; Packer, B.; and Koller, D. 2010.
\newblock Self-Paced Learning for Latent Variable Models.
\newblock In \emph{NeurIPS}.

\bibitem[{Lee et~al.(2018)Lee, He, Zhang, and Yang}]{lee2018cleannet}
Lee, K.-H.; He, X.; Zhang, L.; and Yang, L. 2018.
\newblock Cleannet: Transfer learning for scalable image classifier training
  with label noise.
\newblock In \emph{CVPR}.

\bibitem[{Li et~al.(2019)Li, Wong, Zhao, and Kankanhalli}]{li2019learning}
Li, J.; Wong, Y.; Zhao, Q.; and Kankanhalli, M.~S. 2019.
\newblock Learning to learn from noisy labeled data.
\newblock In \emph{CVPR}.

\bibitem[{Li et~al.(2017)Li, Zhou, Chen, and Li}]{li2017meta}
Li, Z.; Zhou, F.; Chen, F.; and Li, H. 2017.
\newblock Meta-sgd: Learning to learn quickly for few-shot learning.
\newblock \emph{arXiv preprint arXiv:1707.09835}.

\bibitem[{Lin et~al.(2017)Lin, Goyal, Girshick, He, and
  Doll{\'a}r}]{lin2017focal}
Lin, T.-Y.; Goyal, P.; Girshick, R.; He, K.; and Doll{\'a}r, P. 2017.
\newblock Focal loss for dense object detection.
\newblock In \emph{ICCV}.

\bibitem[{Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick}]{10.1007/978-3-319-10602-1_48}
Lin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.;
  Doll{\'a}r, P.; and Zitnick, C.~L. 2014.
\newblock Microsoft COCO: Common Objects in Context.
\newblock In \emph{ECCV}.

\bibitem[{Liu et~al.(2019)Liu, Miao, Zhan, Wang, Gong, and Yu}]{liu2019large}
Liu, Z.; Miao, Z.; Zhan, X.; Wang, J.; Gong, B.; and Yu, S.~X. 2019.
\newblock Large-scale long-tailed recognition in an open world.
\newblock In \emph{CVPR}.

\bibitem[{Ma et~al.(2018)Ma, Wang, Houle, Zhou, Erfani, Xia, Wijewickrema, and
  Bailey}]{ma2018dimensionality}
Ma, X.; Wang, Y.; Houle, M.~E.; Zhou, S.; Erfani, S.; Xia, S.; Wijewickrema,
  S.; and Bailey, J. 2018.
\newblock Dimensionality-driven learning with noisy labels.
\newblock In \emph{ICML}.

\bibitem[{Mahajan et~al.(2018)Mahajan, Girshick, Ramanathan, He, Paluri, Li,
  Bharambe, and Van Der~Maaten}]{mahajan2018exploring}
Mahajan, D.; Girshick, R.; Ramanathan, V.; He, K.; Paluri, M.; Li, Y.;
  Bharambe, A.; and Van Der~Maaten, L. 2018.
\newblock Exploring the limits of weakly supervised pretraining.
\newblock In \emph{ECCV}.

\bibitem[{Malisiewicz, Gupta, and Efros(2011)}]{malisiewicz2011ensemble}
Malisiewicz, T.; Gupta, A.; and Efros, A.~A. 2011.
\newblock Ensemble of exemplar-svms for object detection and beyond.
\newblock In \emph{ICCV}.

\bibitem[{Masnadi-shirazi and Vasconcelos(2009)}]{masnadi2008design}
Masnadi-shirazi, H.; and Vasconcelos, N. 2009.
\newblock On the Design of Loss Functions for Classification: theory,
  robustness to outliers, and SavageBoost.
\newblock In \emph{NeurIPS}.

\bibitem[{Mikolov et~al.(2013)Mikolov, Sutskever, Chen, Corrado, and
  Dean}]{mikolov2013distributed}
Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G.~S.; and Dean, J. 2013.
\newblock Distributed Representations of Words and Phrases and their
  Compositionality.
\newblock In \emph{NeurIPS}.

\bibitem[{Pi et~al.(2016)Pi, Li, Zhang, Meng, Wu, Xiao, and
  Zhuang}]{pi2016self}
Pi, T.; Li, X.; Zhang, Z.; Meng, D.; Wu, F.; Xiao, J.; and Zhuang, Y. 2016.
\newblock Self-paced boost learning for classification.
\newblock In \emph{IJCAI}.

\bibitem[{Ravi and Larochelle(2017)}]{ravi2016optimization}
Ravi, S.; and Larochelle, H. 2017.
\newblock Optimization as a Model for Few-Shot Learning.
\newblock In \emph{IICLR}.

\bibitem[{Reed et~al.(2014)Reed, Lee, Anguelov, Szegedy, Erhan, and
  Rabinovich}]{reed2014training}
Reed, S.; Lee, H.; Anguelov, D.; Szegedy, C.; Erhan, D.; and Rabinovich, A.
  2014.
\newblock Training deep neural networks on noisy labels with bootstrapping.
\newblock \emph{arXiv preprint arXiv:1412.6596}.

\bibitem[{Ren et~al.(2018)Ren, Zeng, Yang, and Urtasun}]{ren2018learning}
Ren, M.; Zeng, W.; Yang, B.; and Urtasun, R. 2018.
\newblock Learning to reweight examples for robust deep learning.
\newblock In \emph{ICML}.

\bibitem[{Shu et~al.(2019)Shu, Xie, Yi, Zhao, Zhou, Xu, and Meng}]{shu2019meta}
Shu, J.; Xie, Q.; Yi, L.; Zhao, Q.; Zhou, S.; Xu, Z.; and Meng, D. 2019.
\newblock Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting.
\newblock In \emph{NeurIPS}.

\bibitem[{Shu, Xu, and Meng(2018)}]{shu2018small}
Shu, J.; Xu, Z.; and Meng, D. 2018.
\newblock Small sample learning in big data era.
\newblock \emph{arXiv preprint arXiv:1808.04572}.

\bibitem[{Simonyan and Zisserman(2015)}]{simonyan2014very}
Simonyan, K.; and Zisserman, A. 2015.
\newblock Very Deep Convolutional Networks for Large-Scale Image Recognition.
\newblock In \emph{ICLR}.

\bibitem[{Smith(2017)}]{smith2017cyclical}
Smith, L.~N. 2017.
\newblock Cyclical learning rates for training neural networks.
\newblock In \emph{WACV}.

\bibitem[{Tan et~al.(2020)Tan, Wang, Li, Li, Ouyang, Yin, and
  Yan}]{tan2020equalization}
Tan, J.; Wang, C.; Li, B.; Li, Q.; Ouyang, W.; Yin, C.; and Yan, J. 2020.
\newblock Equalization loss for long-tailed object recognition.
\newblock In \emph{CVPR}.

\bibitem[{van Rooyen, Menon, and Williamson(2015)}]{van2015learning}
van Rooyen, B.; Menon, A.~K.; and Williamson, R.~C. 2015.
\newblock Learning with Symmetric Label Noise: The Importance of Being
  Unhinged.
\newblock In \emph{NeurIPS}.

\bibitem[{Wang, Ramanan, and Hebert(2017)}]{wang2017learning}
Wang, Y.-X.; Ramanan, D.; and Hebert, M. 2017.
\newblock Learning to model the tail.
\newblock In \emph{NeurIPS}.

\bibitem[{Wu et~al.(2018)Wu, Tian, Xia, Fan, Qin, Lai, and
  Liu}]{wu2018learning}
Wu, L.; Tian, F.; Xia, Y.; Fan, Y.; Qin, T.; Lai, J.-H.; and Liu, T.-Y. 2018.
\newblock Learning to Teach with Dynamic Loss Functions.
\newblock In \emph{NeurIPS}.

\bibitem[{Xiao et~al.(2015)Xiao, Xia, Yang, Huang, and Wang}]{xiao2015learning}
Xiao, T.; Xia, T.; Yang, Y.; Huang, C.; and Wang, X. 2015.
\newblock Learning From Massive Noisy Labeled Data for Image Classification.
\newblock In \emph{CVPR}.

\bibitem[{Xu et~al.(2021)Xu, Zhu, Jiang, and Yang}]{Xu2021FaMUS}
Xu, Y.; Zhu, L.; Jiang, L.; and Yang, Y. 2021.
\newblock Faster Meta Update Strategy for Noise-Robust Deep Learning.
\newblock In \emph{CVPR}.

\bibitem[{Zhang et~al.(2021)Zhang, Bengio, Hardt, Recht, and
  Vinyals}]{zhang2016understanding}
Zhang, C.; Bengio, S.; Hardt, M.; Recht, B.; and Vinyals, O. 2021.
\newblock Understanding Deep Learning (Still) Requires Rethinking
  Generalization.
\newblock \emph{Commun. ACM}, 64(3): 107–115.

\bibitem[{Zhang, Wang, and Qiao(2019)}]{zhang2019metacleaner}
Zhang, W.; Wang, Y.; and Qiao, Y. 2019.
\newblock Metacleaner: Learning to hallucinate clean representations for
  noisy-labeled visual recognition.
\newblock In \emph{CVPR}.

\bibitem[{Zhang et~al.(2017)Zhang, Fang, Wen, Li, and Qiao}]{zhang2017range}
Zhang, X.; Fang, Z.; Wen, Y.; Li, Z.; and Qiao, Y. 2017.
\newblock Range loss for deep face recognition with long-tailed training data.
\newblock In \emph{ICCV}.

\bibitem[{Zhang et~al.(2020)Zhang, Zhang, Arik, Lee, and
  Pfister}]{zhang2020distilling}
Zhang, Z.; Zhang, H.; Arik, S.~O.; Lee, H.; and Pfister, T. 2020.
\newblock Distilling effective supervision from severe label noise.
\newblock In \emph{CVPR}.

\end{thebibliography}
