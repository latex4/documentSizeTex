\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Abbasi-Yadkori, P{\'a}l, and
  Szepesv{\'a}ri}{2011}]{abbasi2011improved}
Abbasi-Yadkori, Y.; P{\'a}l, D.; and Szepesv{\'a}ri, C.
\newblock 2011.
\newblock Improved algorithms for linear stochastic bandits.
\newblock In {\em NIPS}.

\bibitem[\protect\citeauthoryear{Agarwal \bgroup et al\mbox.\egroup
  }{2014}]{agarwal-ilovetoconbandits}
Agarwal, A.; Hsu, D.; Kale, S.; Langford, J.; Li, L.; and Schapire, R.
\newblock 2014.
\newblock Taming the monster: A fast and simple algorithm for contextual
  bandits.
\newblock {\em ICML}.

\bibitem[\protect\citeauthoryear{Agarwal \bgroup et al\mbox.\egroup
  }{2016}]{agarwal-debt}
Agarwal, A.; Bird, S.; Cozowicz, M.; Hoang, L.; Langford, J.; Lee, S.; Li, J.;
  Melamed, D.; Oshri, G.; Ribas, O.; Sen, S.; and Slivkins, A.
\newblock 2016.
\newblock Making contextual decisions with low technical debt.
\newblock {\em arXiv preprint arXiv:1606.03966}.

\bibitem[\protect\citeauthoryear{Agrawal and Goyal}{2012}]{agrawal-ts}
Agrawal, S., and Goyal, N.
\newblock 2012.
\newblock Analysis of thompson sampling for the multi-armed bandit problem.
\newblock {\em Journal of Machine Learning Research Workshop and Conference
  Proceedings}.

\bibitem[\protect\citeauthoryear{Agrawal and Goyal}{2013}]{agrawal-lints}
Agrawal, S., and Goyal, N.
\newblock 2013.
\newblock Thompson sampling for contextual bandits with linear payoffs.
\newblock {\em ICML}.

\bibitem[\protect\citeauthoryear{Athey and Wager}{2017}]{athey-offline}
Athey, S., and Wager, S.
\newblock 2017.
\newblock Efficient policy learning.
\newblock {\em arXiv preprint arXiv:1702.02896}.

\bibitem[\protect\citeauthoryear{Athey, Imbens, and Wager}{2018}]{athey-arb}
Athey, S.; Imbens, G.~W.; and Wager, S.
\newblock 2018.
\newblock Approximate residual balancing: debiased inference of average
  treatment effects in high dimensions.
\newblock {\em Journal of the Royal Statistical Society}.

\bibitem[\protect\citeauthoryear{Auer, Cesa-Bianchi, and
  Fischer}{2002}]{auer-ucb}
Auer, P.; Cesa-Bianchi, N.; and Fischer, P.
\newblock 2002.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock {\em Machine Learning}.

\bibitem[\protect\citeauthoryear{Auer}{2002}]{auer2002using}
Auer, P.
\newblock 2002.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock {\em Journal of Machine Learning Research} 3(Nov).

\bibitem[\protect\citeauthoryear{Auer}{2003}]{auer-linrel}
Auer, P.
\newblock 2003.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock {\em Journal of Machine Learning Research}.

\bibitem[\protect\citeauthoryear{Bareinboim and
  Pearl}{2015}]{bareinboim-fusion}
Bareinboim, E., and Pearl, J.
\newblock 2015.
\newblock Causal inference and the data-fusion problem.
\newblock {\em Proceedings of the National Academy of Sciences}.

\bibitem[\protect\citeauthoryear{Bareinboim, Forney, and
  Pearl}{2015}]{bareinboim-bandits}
Bareinboim, E.; Forney, A.; and Pearl, J.
\newblock 2015.
\newblock Bandits with unobserved confounders: A causal approach.
\newblock {\em ICML}.

\bibitem[\protect\citeauthoryear{Bastani and Bayati}{2015}]{bastani2015online}
Bastani, H., and Bayati, M.
\newblock 2015.
\newblock Online decision-making with high-dimensional covariates.

\bibitem[\protect\citeauthoryear{Bietti, Agarwal, and
  Langford}{2018}]{bietti2018contextual}
Bietti, A.; Agarwal, A.; and Langford, J.
\newblock 2018.
\newblock A contextual bandit bake-off.
\newblock {\em arXiv preprint arXiv:1802.04064}.

\bibitem[\protect\citeauthoryear{Bubeck and
  Cesa-Bianchi}{2012}]{bubeck2012regret}
Bubeck, S., and Cesa-Bianchi, N.
\newblock 2012.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock {\em Foundations and Trends in Machine Learning}.

\bibitem[\protect\citeauthoryear{Chapelle and Li}{2011}]{chapelle-tsucb}
Chapelle, O., and Li, L.
\newblock 2011.
\newblock An empirical evaluation of thompson sampling.
\newblock {\em NIPS}.

\bibitem[\protect\citeauthoryear{Chu \bgroup et al\mbox.\egroup
  }{2011}]{chu2011contextual}
Chu, W.; Li, L.; Reyzin, L.; and Schapire, R.
\newblock 2011.
\newblock Contextual bandits with linear payoff functions.
\newblock In {\em AISTATS}.

\bibitem[\protect\citeauthoryear{Cortes, Mansour, and Mohri}{2010}]{cortes-ml}
Cortes, C.; Mansour, Y.; and Mohri, M.
\newblock 2010.
\newblock Learning bounds for importance eeighting.
\newblock {\em NIPS}.

\bibitem[\protect\citeauthoryear{Crump \bgroup et al\mbox.\egroup
  }{2009}]{crump2009dealing}
Crump, R.~K.; Hotz, V.~J.; Imbens, G.~W.; and Mitnik, O.~A.
\newblock 2009.
\newblock Dealing with limited overlap in estimation of average treatment
  effects.
\newblock {\em Biometrika} 96(1):187--199.

\bibitem[\protect\citeauthoryear{Deshpande \bgroup et al\mbox.\egroup
  }{2017}]{deshpande-offline}
Deshpande, Y.; Mackey, L.; Syrgkanis, V.; and Taddy, M.
\newblock 2017.
\newblock Accurate inference in adaptive linear models.
\newblock {\em arXiv preprint arXiv:1712.06695}.

\bibitem[\protect\citeauthoryear{Dimakopoulou \bgroup et al\mbox.\egroup
  }{2017}]{dimakopoulou2017estimation}
Dimakopoulou, M.; Zhou, Z.; Athey, S.; and Imbens, G.
\newblock 2017.
\newblock Estimation considerations in contextual bandits.
\newblock {\em arXiv preprint arXiv:1711.07077}.

\bibitem[\protect\citeauthoryear{Dud{\'\i}k \bgroup et al\mbox.\egroup
  }{2014}]{dudik-offline-2}
Dud{\'\i}k, M.; Erhan, D.; Langford, J.; and Li, L.
\newblock 2014.
\newblock Doubly robust policy evaluation and optimization.
\newblock {\em Statistical Science}.

\bibitem[\protect\citeauthoryear{Dud{\'\i}k, Langford, and
  Li}{2011}]{dudik-offline-1}
Dud{\'\i}k, M.; Langford, J.; and Li, L.
\newblock 2011.
\newblock Doubly robust policy evaluation and learning.
\newblock {\em ICML}.

\bibitem[\protect\citeauthoryear{Forney, Pearl, and
  Bareinboim}{2017}]{forney-fusion}
Forney, A.; Pearl, J.; and Bareinboim, E.
\newblock 2017.
\newblock Counterfactual data-fusion for online reinforcement learners.
\newblock {\em ICML}.

\bibitem[\protect\citeauthoryear{Huang \bgroup et al\mbox.\egroup
  }{2007}]{huang-ml}
Huang, J.; Gretton, A.; Borgwardt, K.~M.; Scholkopf, B.; and Smola, A.~J.
\newblock 2007.
\newblock Correcting sample selection bias by unlabeled data.
\newblock {\em NIPS}.

\bibitem[\protect\citeauthoryear{Imbens and Rubin}{2015}]{imbens-ci}
Imbens, G.~W., and Rubin, D.~B.
\newblock 2015.
\newblock {\em Causal Inference in Statistics, Social, and Biomedical
  Sciences}.

\bibitem[\protect\citeauthoryear{Jiang and Li}{2016}]{jiang-offline}
Jiang, N., and Li, L.
\newblock 2016.
\newblock Doubly robust off-policy value evaluation for reinforcement learning.
\newblock {\em ICML}.

\bibitem[\protect\citeauthoryear{Kallus and Zhou}{2018}]{kallus2018policy}
Kallus, N., and Zhou, A.
\newblock 2018.
\newblock Policy evaluation and optimization with continuous treatments.
\newblock {\em AISTATS}.

\bibitem[\protect\citeauthoryear{Kallus}{2017}]{kallus-offline}
Kallus, N.
\newblock 2017.
\newblock Balanced policy evaluation and learning.
\newblock {\em arXiv preprint arXiv:1705.07384}.

\bibitem[\protect\citeauthoryear{Lai and Robbins}{1985}]{lai-ucb}
Lai, T., and Robbins, H.
\newblock 1985.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock {\em Advances in Applied Mathematics}.

\bibitem[\protect\citeauthoryear{Lattimore, Lattimore, and
  Reid}{2016}]{lattimore-causalbandit}
Lattimore, F.; Lattimore, T.; and Reid, M.~D.
\newblock 2016.
\newblock Causal bandits: Learning good interventions via causal inference.
\newblock {\em NIPS}.

\bibitem[\protect\citeauthoryear{Lei, Tewari, and Murphy}{2017}]{lei-mhealth}
Lei, H.; Tewari, A.; and Murphy, S.
\newblock 2017.
\newblock An actor-critic contextual bandit algorithm for personalized mobile
  health interventions.
\newblock {\em arXiv preprint arXiv:1706.09090}.

\bibitem[\protect\citeauthoryear{Li \bgroup et al\mbox.\egroup
  }{2010}]{li-linucb}
Li, L.; Chu, W.; Langford, J.; and Schapire, R.
\newblock 2010.
\newblock A contextual-bandit approach to personalized news article
  recommendation.
\newblock {\em WWW}.

\bibitem[\protect\citeauthoryear{Li \bgroup et al\mbox.\egroup
  }{2012}]{li-offline-1}
Li, L.; Chu, W.; Langford, J.; Moon, T.; and Wang, X.
\newblock 2012.
\newblock An unbiased offline evaluation of contextual bandit algorithms with
  generalized linear models.
\newblock {\em Journal of Machine Learning Research Workshop and Conference
  Proceedings}.

\bibitem[\protect\citeauthoryear{Li \bgroup et al\mbox.\egroup
  }{2014}]{li-offline-2}
Li, L.; Chen, S.; Kleban, J.; and Gupta, A.
\newblock 2014.
\newblock Counterfactual estimation and optimization of click metrics for
  search engines.
\newblock {\em arXiv preprint arXiv:1403.1891}.

\bibitem[\protect\citeauthoryear{Nie \bgroup et al\mbox.\egroup
  }{2018}]{nie-online}
Nie, X.; Tian, X.; Taylor, J.; and Zou, J.
\newblock 2018.
\newblock Why adaptively collected data have negative bias and how to correct
  for it.
\newblock {\em International Conference on Artificial Intelligence and
  Statistics}.

\bibitem[\protect\citeauthoryear{Perchet and
  Rigollet}{2013}]{perchet-nonparamtheory}
Perchet, V., and Rigollet, P.
\newblock 2013.
\newblock The multi-armed bandit problem with covariates.
\newblock {\em The Annals of Statistics}.

\bibitem[\protect\citeauthoryear{Rigollet and
  Zeevi}{2010}]{rigollet-nonparamtheory}
Rigollet, P., and Zeevi, R.
\newblock 2010.
\newblock Nonparametric bandits with covariates.
\newblock {\em COLT}.

\bibitem[\protect\citeauthoryear{Russo and {Van Roy}}{2014}]{russo-vanroy}
Russo, D., and {Van Roy}, B.
\newblock 2014.
\newblock Learning to optimize via posterior sampling.
\newblock {\em Mathematics of Operations Research}.

\bibitem[\protect\citeauthoryear{Russo \bgroup et al\mbox.\egroup
  }{2018}]{russo2018tutorial}
Russo, D.~J.; Van~Roy, B.; Kazerouni, A.; Osband, I.; and Wen, Z.
\newblock 2018.
\newblock A tutorial on thompson sampling.
\newblock {\em Foundations and Trends in Machine Learning}.

\bibitem[\protect\citeauthoryear{Scharfstein, Rotnitzky, and
  Robins}{1999}]{scharfstein1999adjusting}
Scharfstein, D.~O.; Rotnitzky, A.; and Robins, J.~M.
\newblock 1999.
\newblock Adjusting for nonignorable drop-out using semiparametric nonresponse
  models.
\newblock {\em Journal of the American Statistical Association}
  94(448):1096--1120.

\bibitem[\protect\citeauthoryear{Scott}{2010}]{scott-ts}
Scott, S.
\newblock 2010.
\newblock A modern bayesian look at the multi-armed bandit.
\newblock {\em Applied Stochastic Models in Business and Industry}.

\bibitem[\protect\citeauthoryear{Slivkins}{2014}]{slivkins-nonparamtheory}
Slivkins, A.
\newblock 2014.
\newblock Contextual bandits with similarity information.
\newblock {\em Journal of Machine Learning Research}.

\bibitem[\protect\citeauthoryear{Strehl \bgroup et al\mbox.\egroup
  }{2010}]{strehl2010learning}
Strehl, A.; Langford, J.; Li, L.; and Kakade, S.~M.
\newblock 2010.
\newblock Learning from logged implicit exploration data.
\newblock In {\em NIPS}.

\bibitem[\protect\citeauthoryear{Swaminathan and
  Joachims}{2015}]{swaminathan-offline}
Swaminathan, A., and Joachims, T.
\newblock 2015.
\newblock Batch learning from logged bandit feedback through counterfactual
  risk minimization.
\newblock {\em Journal of Machine Learning Research}.

\bibitem[\protect\citeauthoryear{Thomas and Brunskill}{2016}]{thomas-offline}
Thomas, P., and Brunskill, E.
\newblock 2016.
\newblock Data-efficient off-policy policy evaluation for reinforcement
  learning.
\newblock {\em ICML}.

\bibitem[\protect\citeauthoryear{Thompson}{1933}]{thompson-ts}
Thompson, W.
\newblock 1933.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock {\em Biometrika}.

\bibitem[\protect\citeauthoryear{Villar, Bowden, and
  Wason}{2015}]{villar-online}
Villar, S.; Bowden, J.; and Wason, J.
\newblock 2015.
\newblock Multi-armed bandit models for the optimal design of clinical trials:
  benefits and challenges.
\newblock {\em Statistical Science}.

\bibitem[\protect\citeauthoryear{Wang, Agarwal, and
  Dud{\'\i}k}{2017}]{wang-offline}
Wang, Y.~X.; Agarwal, A.; and Dud{\'\i}k, M.
\newblock 2017.
\newblock Optimal and adaptive off-policy evaluation in contextual bandits.
\newblock {\em ICML}.

\bibitem[\protect\citeauthoryear{Zadrozny}{2004}]{zadrozny-ml}
Zadrozny, B.
\newblock 2004.
\newblock Learning and evaluating classifiers under sample selection bias.
\newblock {\em ICML}.

\bibitem[\protect\citeauthoryear{Zhou, Athey, and
  Wager}{2018}]{zhou2018offline}
Zhou, Z.; Athey, S.; and Wager, S.
\newblock 2018.
\newblock Offline multi-action policy learning: Generalization and
  optimization.
\newblock {\em arXiv preprint arXiv:1810.04778}.

\end{thebibliography}
