
\newpage
\onecolumn


\section{Probability Distribution  of Algorithm~\ref{alg:lll-sampler}}\label{appendix:prob-dist}
\subsection{Definitions and Notations}
This section is for the proofs related to the probability distribution in the proposed Algorithm~\ref{alg:lll-sampler}. For convenience, commonly used notations are listed in Table~\ref{tab:quantifier}. We make some slight changes to some notations that appear in the main paper to make sure they are consistent and well-defined in this proof.



Similar to the previous analysis~\cite{DBLP:journals/jacm/GuoJL19,DBLP:journals/arxiv/jerrum2021}, we begin by introducing the concept ``dependency graph'' (in Definition~\ref{def:dep-graph}) for the constraints $\mathcal{C}$. 


\begin{definition}[Dependency Graph] \label{def:dep-graph}
The dependency graph $G=(\mathcal{C},E)$, where the vertex set is the set of constraints $\mathcal{C}$.  Two vertices $c_i$ and $c_j$ are connected with an edge $(c_i,c_j)\in E$ if and only if they are defined on at least one common random variable, i.e., $\var(c_i)\cap\var(c_j) \neq \emptyset$. 
\end{definition}



For keeping track of the whole sampling procedure, we need the concept ``sampling record''(in Definition~\ref{def:record})~\cite{DBLP:journals/jacm/GuoJL19}, which are the broken constraints at every round in Algorithm~\ref{alg:lll-sampler}. It is also known as the witness tree in~\citet{DBLP:journals/jacm/MoserT10}.  This allows us to check the constraint satisfaction of the assignment at every round.

Under Condition~\ref{cond:extreme}, for any edge in the dependency graph $(c_i,c_j) \in E$,   either $\mathbf{1}(x,c_i)=0$ or $\mathbf{1}(x,c_j)=0$ for all $x\in \mathcal{X}$.
In other words, two constraints with shared related variables, representing two \textit{adjacent vertices} in the dependency graph $G$, are not broken simultaneously. Thus, the constraints in record $S_t$ form an \textit{independent set}\footnote{A set of vertices with no two adjacent vertices in the graph.} over the dependency graph under Condition~\ref{cond:extreme}.

\begin{definition}[Sampling Record] \label{def:record} 
Given dependency graph $G(\mathcal{C},E)$, let $X_t=x$ be  one possible assignment obtained at round $t$ of Algorithm~\ref{alg:lll-sampler}. Let $S_t\subseteq \mathcal{C}$ be the set of vertices in graph $G$ (subset of constraints) that $x$ violates
\begin{align}
    S_t = \{c_i|c_i\in \mathcal{C}\text{ and } \mathbf{1}(x,c_i)=0\},
\end{align}
where indicator function $\mathbf{1}(x,c_i)=0$ implies  $x$ violates constraint $c_i$  at round $t$.
Define the sampling record as the sequence of violated constraints  $S_1,\ldots,S_t$ throughout the execution.
\end{definition}






At round $t$  ($t \geq 1$) of Algorithm~\ref{alg:lll-sampler}, suppose the violated constraints is $S_t\subseteq \mathcal{C}$. The constraints that are not adjacent to $S_t$ in the dependency graph are still satisfied after re-sample. The only possible constraints that might be broken after the re-sample operation are among $S_t$ itself, or those constraints directly connected to  $S_t$ in the dependency graph. Therefore,
\begin{equation*}
S_{t+1} \subset \Gamma(S_t),    \qquad \text{ for all } t\ge 1.
\end{equation*}
where $\Gamma(S_t)$ is the set of vertices of $S_t$ and its adjacent neighbors
in the dependency graph $G$ (see Table~\ref{tab:quantifier}).  When Algorithm~\ref{alg:lll-sampler} terminates at round $T+1$, no  constraints are violated anymore, i.e., $s_{T+1}=\emptyset$.  To summarize the above discussion on a sampling record by Algorithm~\ref{alg:lll-sampler}, we have the following Claim~\ref{claim:record}.
\begin{claim}~\label{claim:record}
Under Condition~\ref{cond:extreme}, a potential sampling record of length $T+1$ by the Algorithm~\ref{alg:lll-sampler} is a sequence of independent sets: $S_1, S_2, \ldots,S_T,\emptyset$ with 
\begin{enumerate}
    \item $S_{t+1} \subseteq \Gamma(S_{t})$ and $S_t\neq\emptyset$, for $1 \leq t\leq T$; 
    \item $s_{T+1}=\emptyset$.
\end{enumerate}
\end{claim}






\begin{table}[!t]
    \centering
    \caption{Summary of all the notations used in the theoretical analysis of Algorithm~\ref{alg:lll-sampler}.}\label{tab:quantifier}
    \begin{tabular}{ll}
    \hline
    Notation& Definition \\
    \hline
        $X=\{X_i\}_{i=1}^n$ & set of discrete random variables \\
        \hline
        $x\in\mathcal{X}$ & possible assignments for variables $X$ \\
        \hline
        $x_i\in\mathcal{X}_i$ & variable $X_i$ can take all values in $\mathcal{X}_i$\\
        \hline
        $\mathcal{C}=\{c_j\}_{j=1}^{m}$ & given constraints \\
        \hline
        $S_t\subseteq\mathcal{C}$& subset of constraints violated at round  $t$ of Algorithm~\ref{alg:lll-sampler} \\
        \hline
        $G(\mathcal{C},E)$& the dependency graph (in Definition~\ref{def:dep-graph})\\
        \hline
        $\var(c_j)$& the indices of domain variables that are related to constraint $c_i$\\
        \hline
        $\var(S_t)$& the indices for domain variables that are related to constraints $S_t$\\
        \hline
        $\Gamma(c_j)$ &$c_j$ and its direct neighbors in the dependency graph\\
        \hline
        $\Gamma(S_t)$ &$S_t$ and direct neighbors of $S_t$ in the      dependency graph\\
        \hline
        $\mathcal{C}\backslash \Gamma(S_t)$ &all constraints in $\mathcal{C}$ but not in $\Gamma(S_t)$ \\
        \hline
        $S_1,\ldots,S_{T},\emptyset$ & a sampling record of Algorithm~\ref{alg:lll-sampler}  (in Definition~\ref{def:record}) \\
        \hline
        $\mathbf{1}(x,c_i)$ & indicator function that evaluates if    assignment $x$ satisfies constraint $c_i$ \\
        \hline
        $\mathbf{1}(x,S_t)$ & indicator function that evaluates if assignment $x$ satisfies constraints in $S_t$ \\
        \hline
        $\mathbf{1}(x,\mathcal{C})$ & indicator function that evaluates if  assignment $x$ satisfies all constraints $\mathcal{C}$ \\
        \hline
        $P_{\theta}(X|\mathcal{C}\backslash\Gamma(S_t))$& see Definition~\ref{def:general-cmrf}\\
        \hline
        $\p(X|S_t)$ & see Definition~\ref{def:prs-prob}\\
    \hline
    \end{tabular}
\end{table}


\subsubsection{Extra Notations related to Constrained MRF}
The constrained MRF model over constraints set $\mathcal{C}$ is defined as:
\begin{align*}
P_{\theta}(X=x|\mathcal{C})&=\frac{\exp(\sum_{i=1}^n\theta_i x_i)\mathbf{1}(x,\mathcal{C})}{\sum_{x'\in\mathcal{X}}\exp(\sum_{i=1}^n\theta_i x'_i)\mathbf{1}(x',\mathcal{C})}
\end{align*}
where the partition function only sums over valid assignments in $\mathcal{X}$. Note that $C(x)$ in Equation~\eqref{eq:constr_mrf_single} is the same as $\mathbf{1}(x',\mathcal{C})$ in the above equation. We slightly change the notations for consistency in this proof. Also notice that the output distribution can no longer be factorized after constraints are enforced, since the partition function cannot be factorized. Our task is to draw samples from this distribution. 

To analyze the intermediate steps in Algorithm~\ref{alg:lll-sampler}, we further need to define the following notations.
\begin{definition}  \label{def:general-cmrf}
The constrained MRF distribution for constraints $\mathcal{C}\backslash \Gamma(S_t)$ is
\begin{equation*}\footnotesize
\begin{aligned}
P_{\theta}(X=x|\mathcal{C}\backslash \Gamma(S_t))&=\frac{\exp(\sum_{i=1}^n\theta_i x_i)\mathbf{1}(x,\mathcal{C}\backslash \Gamma(S_t))}{\sum_{x'\in\mathcal{X}}\exp(\sum_{i=1}^n\theta_i x'_i)\mathbf{1}(x',\mathcal{C}\backslash \Gamma(S_t))}
\end{aligned}
\end{equation*}
\end{definition}

\begin{definition}  \label{def:prs-prob}
At round $t$ of Algorithm~\ref{alg:lll-sampler}, assume $S_t\subseteq\mathcal{C}$ are the set of broken constraints,  Define $\p(X_{t+1}=x|S_1,\ldots, S_t)$ to be the probability of obtaining a new assignment $x$ after we re-sample random variables indexed by $\var(S_t)$.
\end{definition}









\subsection{Ratio Property Lemma}



\begin{lemma}[Ratio Property] \label{lem:ratio-prob}
Under Condition~\ref{cond:extreme}, assume Algorithm~\ref{alg:lll-sampler} is at round $t$. Conditioning on observing one possible sampling record $S_1,\ldots,S_t$, Algorithm~\ref{alg:lll-sampler} step 4 will re-sample variables in $\var(S_t)$ at round $t+1$. Let $x,x'\in\mathcal{X}$ be two possible assignments after this re-sample.  The probability ratio  of obtaining these two results equals that under constrained MRF
$P_{\theta}(x|\mathcal{C}\backslash \Gamma(S_t))$:
\begin{equation} \label{eq:ratio}
\frac{\p(X_{t+1}= x |S_1,\ldots, S_t)}{\p(X_{t+1}= x'|S_1,\ldots, S_t)} = \frac{P_{\theta}(X = x |\mathcal{C}\backslash \Gamma(S_t))}{P_{\theta}(X = x'|\mathcal{C}\backslash \Gamma(S_t))},
\end{equation} 
where $\p(X_{t+1}= x |S_1,\ldots, S_t)$ is the probability of Algorithm~\ref{alg:lll-sampler} step 4 produces assignment $x$ at round $t+1$, conditioning on the observed record $S_1,\ldots, S_t$ and re-sample $\var(S_t)$. $P_{\theta}(X = x |\mathcal{C}\backslash \Gamma(S_t))$ is the constrained MRF (for the constraints  $\mathcal{C}\backslash \Gamma(S_t)$) probability on assignment $x$.
\begin{proof}
During the intermediate step of the algorithm, assume the set of constraints $S_t$ are violated. We want to re-sample variables indexed by $\var(S_t)$, so  variables indexed by $\var(\mathcal{C}\backslash\Gamma(S_t))$ won't change assignments. Also, because $\Gamma(S_t)$ is the largest possible set of constraints that can be infected by the re-sample, constraints $\mathcal{C}\backslash \Gamma(S_t)$ are still satisfied after the re-sample. 

At round $t$,  we re-sample variables in $\var(S_t)$ according to step 4 in Algorithm~\ref{alg:lll-sampler}, we thus have:
\begin{equation*}
\p(X^{t+1}_{\var(S_t)}=x_{\var(S_t)}|S_1 \ldots S_t)=\underset{{i\in\var(S_t)}}{\prod}\frac{\exp(\theta_i x_i)}{\underset{x'_i\in \mathcal{X}_i}{\sum}\exp(\theta_ix'_i)}.
\end{equation*}
Here the notation $X^{t+1}_{\var(S_t)}=x_{\var(S_t)}$ means $X_i=x_i$ for $i\in\var(S_t)$ at round $t$. For any two possible assignments $x,x'$ after the re-sample,
\begin{equation*}
x_i=x'_i,\quad \text{ for }i\in \{1,\ldots,n\}\backslash \var(S_t)
\end{equation*}
since the rest variable's assignments are kept the same after re-sample. Thus, we can have ratio:
\begin{equation}\label{eq:ratio-nelson}
\frac{\p(X_{t+1}=x|S_1,\ldots,S_t)}{\p(X_{t+1}=x'|S_1,\ldots, S_t)}=\frac{\exp(\sum_{i\in\var(S_t)}\theta_ix_i)}{\exp(\sum_{i\in\var(S_t)}\theta_ix'_i)} =\frac{\exp(\sum_{i\in\var(\Gamma(S_t))}\theta_ix_i)}{\exp(\sum_{i\in\var(\Gamma(S_t))}\theta_ix'_i)}.
\end{equation}
For the last step, since every assignment outside $\var(S_t)$ is not changed, we can enlarge the index set of summation to $\Gamma(S_t)$ by multiplying
\begin{align*}
1 = \frac{\exp(\sum_{i\in\var(\Gamma(S_t)) \backslash \var(S_t)}\theta_ix_i)}{\exp(\sum_{i\in\var(\Gamma(S_t))\backslash \var(S_t)}\theta_ix'_i)}.
\end{align*}
After re-sample, we knows that $x$ must satisfy the constraints $\mathcal{C}\backslash\Gamma(S_t)$. Thus, the probability of this $x$ conditioned on constraints $\mathcal{C}\backslash\Gamma(S_t)$ holding in the constrained MRF model is:
\begin{equation*}
P_{\theta}(X=x|\mathcal{C} \backslash \Gamma(S_t))
=\frac{\exp(\sum_{i=1}^n\theta_i x_i)\mathbf{1}(x,\mathcal{C}\backslash \Gamma(S_t))}{\sum_{x'\in\mathcal{X}} \exp(\sum_{i=1}^n\theta_i x'_i)\mathbf{1}\left(x',\mathcal{C}\backslash \Gamma(S_t)\right)}=\frac{\exp(\sum_{i=1}^n\theta_i x_i)}{\sum_{x'\in\mathcal{X}} \exp(\sum_{i=1}^n\theta_i x'_i)\mathbf{1}\left(x',\mathcal{C}\backslash \Gamma(S_t)\right)}.
\end{equation*}
In the constrained MRF model (for constraints  $\mathcal{C}\backslash\Gamma(S_t)$), the ratio of these two probabilistic assignments $x,x'$ is:
\begin{equation}\label{eq:ratio-cmrf}
\begin{aligned}
\frac{P_{\theta}(X=x|\mathcal{C}\backslash \Gamma(S_t))}{P_{\theta}(X=x'|\mathcal{C}\backslash\Gamma(S_t))}=\frac{\exp(\sum_{i\in \var(\Gamma(S_t))}\theta_ix_i)}{\exp(\sum_{i\in \var(\Gamma(S_t))}\theta_ix'_i)},
\end{aligned}
\end{equation}
because the $x_i$ outside $\var(\Gamma(S_t))$ remains the same. Note that $x,x'$ are two possible assignments produced according to to step 4 in Algorithm~\ref{alg:lll-sampler} at round $t$. 
Combining Equation~\eqref{eq:ratio-nelson} and Equation~\eqref{eq:ratio-cmrf}, we conclude that:
\begin{equation*}
\begin{aligned}
\frac{\p(X_{t+1}=x|S_1,\ldots,S_t)}{\p(X_{t+1}=x'|S_1,\ldots,S_t)}=\frac{P_{\theta}(X=x|\mathcal{C}\backslash \Gamma(S_t))}{P_{\theta}(X=x'|\mathcal{C}\backslash\Gamma(S_t))}.
\end{aligned}
\end{equation*}
The proof is finished. 
\end{proof}
\end{lemma}

\subsection{Proof of Theorem~\ref{th:product-dist}}
Suppose the re-sampling process terminates at round $T+1$ and we obtain a valid sample $x$. Upon the termination of Algorithm~\ref{alg:lll-sampler}, all the constraints are satisfied. So we have: $S_{T+1}=\emptyset$. In other words, $\mathbf{1}(x,\mathcal{C})=1$. 

Let $x,x'$ be two possible valid assignments produced at round $T+1$ by the Algorithm~\ref{alg:lll-sampler}. Using the analysis in Lemma~\ref{lem:ratio-prob}, we can still have:
\begin{equation*}
\frac{\p(X_{T+1}=x|S_1,\ldots, S_T)}{\p(X_{T+1}=x'|S_1,\ldots, S_T)}=\frac{\exp(\sum_{i\in\var(S_T)}\theta_ix_i)}{\exp(\sum_{i\in\var(S_T)}\theta_ix'_i)}.
\end{equation*}
The probability of this $x$ in the constrained MRF model  (for constraints  $\mathcal{C}$) is:
\begin{equation*}
P_{\theta}(X=x|\mathcal{C})=\frac{\exp(\sum_{i=1}^n\theta_i x_i)\mathbf{1}(x,\mathcal{C})}{\sum_{x'\in\mathcal{X}}  \exp(\sum_{i=1}^n\theta_i x'_i)\mathbf{1}\left(x',\mathcal{C}\right)}
=\frac{\exp(\sum_{i=1}^n\theta_i x_i)}{\sum_{x'\in\mathcal{X}}  \exp(\sum_{i=1}^n\theta_i x'_i)\mathbf{1}\left(x',\mathcal{C}\right)}.
\end{equation*}
Then we conclude that:
\begin{equation*}
\frac{\p(X_{T+1}=x|S_1,\ldots, S_T)}{\p(X_{T+1}=x'|S_1,\ldots, S_T)}=\frac{P_{\theta}(X=x|\mathcal{C})}{P_{\theta}(X=x'|\mathcal{C})}.
\end{equation*}
Note that this ratio property holds for all the possible sampling records $S_1,\ldots, S_T,\emptyset$.


\subsubsection{Summation of All Possible Sampling Records} Define $\p(S_1,\ldots,S_T)$ to be the probability of observing record $S_1,\ldots,S_T$ by Algorithm~\ref{alg:lll-sampler}.
For any possible sampling record $S_1,\ldots,S_{T}, \emptyset$, the ratio property still holds:
\begin{equation*}
\frac{\p(X_{T+1}=x|S_1,\ldots S_T)\p(S_1,\ldots,S_T)}{\p(X_{T+1}=x'|S_1,\ldots,S_T)\p(S_1,\ldots,S_T)}=\frac{P_{\theta}(X=x|\mathcal{C})}{P_{\theta}(X=x'|\mathcal{C})}
\end{equation*}
where the term $\p(S_1,\ldots,S_T)$ on the Left-hand-side (LHS) is actually the same.
After we summarize over all possible sampling records $S_1,\ldots,S_{T},\emptyset$, the ratio property still holds. Let $\p(X_{T+1}=x)$ be the probability of obtaining one valid assignment $x$ by the execution of Algorithm~\ref{alg:lll-sampler}.
\begin{equation} \label{eq:ratio-final}
\frac{\p(X_{T+1}=x)}{\p(X_{T+1}=x')}=\frac{\sum_{S_1,\ldots,S_T}\p(X_{T+1}=x|S_1,\ldots,S_T)\p(S_1,\ldots,S_T)}{\sum_{S_1,\ldots,S_T}\p(X_{T+1}=x'|S_1,\ldots,S_T)\p(S_1,\ldots,S_T)}=\frac{P_{\theta}(X=x|\mathcal{C})}{P_{\theta}(X=x'|\mathcal{C})}
\end{equation}

\subsubsection{Sample Space Analysis At Termination}
We need one more statement to show Theorem~\ref{th:product-dist} holds. Let $\mathcal{X}_{\text{LLL}}$ be the set of all possible  assignments $x$ that can be generated by Algorithm~\ref{alg:lll-sampler}:
\begin{equation*}
\mathcal{X}_{\text{LLL}}=\bigcup_{S_1\ldots S_T}\{x|\p(X_{T+1}=x|S_1\ldots S_T) \neq 0 \text{ and } \p(S_1\ldots S_T)\neq 0\}.
\end{equation*}
{where $ \p(S_1\ldots S_T)\neq 0$ means $S_1,\ldots,S_T$ is a possible record. $\p(X_{T+1}=x|S_1\ldots S_T) \neq 0$ means it is possible to obtain $x$ given the record $S_1,\ldots,S_T$.}

Let $\mathcal{X}_{\mathcal{C}}$ be the set of assignments $x$ that satisfy all the constraints in the constrained MRF (for constraints $\mathcal{C}$):
\begin{equation*}
\mathcal{X}_{\mathcal{C}}=\{x|P_{\theta}(X=x|\mathcal{C}) \neq 0, \text{ for all }x\in\mathcal{X}\}.
\end{equation*}


\begin{lemma}\label{lem:space}
$\mathcal{X}_{\text{LLL}}\subseteq\mathcal{X}_{\mathcal{C}}$ and $\mathcal{X}_{\mathcal{C}}\subseteq\mathcal{X}_{\text{LLL}}$, thus $\mathcal{X}_{\text{LLL}}=\mathcal{X}_{\mathcal{C}}$.
\begin{proof}
When Algorithm~\ref{alg:lll-sampler} terminates, it only produces valid assignments; thus, we must have: $\mathcal{X}_{\text{LLL}}\subseteq\mathcal{X}_{\mathcal{C}}$. On the other hand,   there is always a non-zero probability that Algorithm~\ref{alg:lll-sampler} will generate every valid assignment $x\in\mathcal{X}_\mathcal{C}$, which implies that $\mathcal{X}_{\mathcal{C}}\subseteq\mathcal{X}_{\text{LLL}}$. Therefore we can conclude that $\mathcal{X}_{\text{LLL}}=\mathcal{X}_{\mathcal{C}}$.
\end{proof}
\end{lemma}
Lemma~\ref{lem:space} show that the two distributions have the same sample space when Algorithm~\ref{alg:lll-sampler} terminates. What's more, Equation~\eqref{eq:ratio-final} shows they have the same probability ratio for any possible valid assignments $x,x'$. This shows that the execution of the Algorithm~\ref{alg:lll-sampler} is a random draw from the constrained MRF distribution $P_{\theta}(X=x|\mathcal{C})$. The proof of Theorem~\ref{th:product-dist} is finished. 

\subsection{Difference to the Original Proof} 
 The main difference in the above proof to the existing proof in~\cite[Lemma 7]{DBLP:journals/jacm/GuoJL19} is that: We  show Lemma~\ref{lem:ratio-prob} that characterizes the proportional ratio of getting different assignments of variables, which is more general than the descriptive proof for \citet[Lemma 7]{DBLP:journals/jacm/GuoJL19}.


\subsection{{A Running Example in View of Markov Chain}}
{We dedicate this section to demonstrate the execution of Algorithm~\ref{alg:lll-sampler} with Example~\ref{example:matrix}. Algorithm~\ref{alg:lll-sampler} can be viewed as a Markov chain, so  we will show the probability of obtaining valid samples is unbiased by running thousands of steps of the Markov chain. }
The constraints are $\mathcal{C}=\{c_1=(X_1\vee X_2), c_2=(\neg X_1 \vee X_3)\}$. We use the assignment of all the variables as the states $s_1,\ldots, s_8$ in the rounds of Algorithm~\ref{alg:lll-sampler}.
\begin{equation}
\begin{aligned}
s_1&=(X_0=0,X_1=0,X_2=0) \\
s_2&=(X_0=0,X_1=0,X_2=1) \\
s_3&=(X_0=0,X_1=1,X_2=0) \\
s_4&=(X_0=0,X_1=1,X_2=1) \\
s_5&=(X_0=1,X_1=0,X_2=0) \\
s_6&=(X_0=1,X_1=0,X_2=1) \\
s_7&=(X_0=1,X_1=1,X_2=0) \\
s_8&=(X_0=1,X_1=1,X_2=1) \\
\end{aligned}
\end{equation}
Here $s_1,s_2,s_3,s_4$ correspond to \textit{valid} assignments of variables with respect to the constraints $\mathcal{C}$ and $s_5,s_6,s_7,s_8$ correspond to \textit{invalid} assignments of variables, that requires resampling.

For simplicity, we consider the uniform setting where $\theta_1=\theta_2=\theta_3$. The goal is to sample every valid assignment with equal probability. Therefore, the probability for every variable is: 
\begin{equation*}
P(X_i)=\begin{cases}
\frac{1}{2} &\text{ for variable } X_i\text{ taking value }1 \\
\frac{1}{2} &\text{ for variable } X_i\text{ taking value }0 \\
\end{cases}
\end{equation*}
for $i=1,2, 3$. Based on Algorithm~\ref{alg:lll-sampler}, we know the probability of transferring from $s_i$ to $s_j$ ($1\le i,j\le 8$). Thus we can construct the transition matrix between every state:
\begin{equation}
T=\begin{bNiceMatrix}[
  first-row,code-for-first-row=\normalsize,
  first-col,code-for-first-col=\normalsize,
]
 &s_1 &s_2 & s_3  & s_4 & s_5 & s_6 & s_7 & s_8 \\
s_1& \mathbf{1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 s_2& 0 & \mathbf{1} & 0 & 0 & 0& 0 & 0 & 0\\
s_3& 0 & 0 &  \mathbf{1}  & 0 & 0& 0 & 0 & 0\\
s_4& 0 & 0 & 0 & \mathbf{1} & 0 & 0 & 0 & 0\\
s_5& \frac{1}{4} & \frac{1}{4} & \frac{1}{4} & 0& \frac{1}{4} & 0 & 0 & 0 \\
s_6 & 0 & \frac{1}{4} & 0 & 0& \frac{1}{4} & \frac{1}{4} & 0 & \frac{1}{4} \\
s_7 & \frac{1}{4} & 0 & \frac{1}{4} & \frac{1}{4}& 0 & 0 & \frac{1}{4}  & 0 \\
s_8& 0 & 0 & \frac{1}{4} & 0& 0 & \frac{1}{4}  & \frac{1}{4}  & \frac{1}{4}  \\
\end{bNiceMatrix}
\end{equation}
where $T_{ij}=T(s_i,s_j)$ denotes the transition probability from state $s_i$ to state $s_j$. 

{Taking state $s_5$ as an example, it violates constraint $C_2$ thus $X_2,X_3$ will be resampled. There are 4 possible assignments of  $X_2,X_3$, which corresponds to states $\{s_1,s_2,s_3,s_5\}$. Since each variable is resampled uniformly at random, the probability of transition from state $s_5$ to the states $\{s_1,s_2,s_3,s_5\}$ are $1/4$. The Algorithm~\ref{alg:lll-sampler} will terminate once it reaches states $\{s_1,s_2,s_3,s_4\}$, which corresponds to the (valid) state only transit to itself with probability 1. Thus we find $T(s_i,s_i)=1$ for $i=1,2,3,4$.}


For a randomly initialized assignment:
\begin{equation}
x=\begin{bNiceMatrix}[
  first-row,code-for-first-row=\normalsize,
  first-col,code-for-first-col=\normalsize,
]
 &s_1 &s_2 & s_3  & s_4 & s_5 & s_6 & s_7 & s_8 \\
 &\frac{1}{8} & \frac{1}{8} & \frac{1}{8} & \frac{1}{8} & \frac{1}{8} & \frac{1}{8} & \frac{1}{8} & \frac{1}{8} \\
\end{bNiceMatrix}
\end{equation}
that has an equal probability of being any state.
After executing Algorithm~\ref{alg:lll-sampler} for 2000 steps, we have:
\begin{equation}
T^{2000}=\begin{bNiceMatrix}[
  first-row,code-for-first-row=\normalsize,
  first-col,code-for-first-col=\normalsize,
]
 &s_1 &s_2 & s_3  & s_4 & s_5 & s_6 & s_7 & s_8 \\
s_1& \mathbf{1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 s_2& 0 & \mathbf{1} & 0 & 0 & 0& 0 & 0 & 0\\
s_3& 0 & 0 &  \mathbf{1}  & 0 & 0& 0 & 0 & 0\\
s_4& 0 & 0 & 0 & \mathbf{1} & 0 & 0 & 0 & 0\\
s_5& \frac{1}{3} & \frac{1}{3} & \frac{1}{3} & 0& 0 & 0 & 0 & 0 \\
s_6 & \frac{1}{6} & \frac{1}{2} & \frac{1}{6} & \frac{1}{6} & 0 & 0 & 0 & \frac{1}{4} \\
s_7 & \frac{1}{3} & 0 & \frac{1}{3} & \frac{1}{3}& 0 & 0 &  0  & 0 \\
s_8& \frac{1}{6} & \frac{1}{6}  & \frac{1}{6}  & \frac{1}{2} & 0 & 0 &  0  & 0 \\
\end{bNiceMatrix},\quad xT^{2000}=\begin{bNiceMatrix}[
  first-row,code-for-first-row=\normalsize,
  first-col,code-for-first-col=\normalsize,
]
 &s_1 &s_2 & s_3  & s_4 & s_5 & s_6 & s_7 & s_8 \\
 &\frac{1}{4} & \frac{1}{4} & \frac{1}{4} & \frac{1}{4} & 0 & 0 & 0 & 0 \\
\end{bNiceMatrix}
\end{equation}
This implies Algorithm~\ref{alg:lll-sampler} outputs every valid assignment with the same probability in the uniform setting, which follows the result in Theorem~\ref{th:product-dist}.