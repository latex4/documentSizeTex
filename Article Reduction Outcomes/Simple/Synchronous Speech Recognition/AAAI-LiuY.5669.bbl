\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{{Anastasopoulos} and
  {Chiang}}{2018a}]{anastasopoulos2018tied}
{Anastasopoulos}, A., and {Chiang}, D.
\newblock 2018a.
\newblock Tied multitask learning for neural speech translation.
\newblock {\em In Proceedings of NAACL} 1:82--91.

\bibitem[\protect\citeauthoryear{Anastasopoulos and
  Chiang}{2018b}]{anastasopoulos2018leveraging}
Anastasopoulos, A., and Chiang, D.
\newblock 2018b.
\newblock Leveraging translations for speech transcription in low-resource
  settings.
\newblock {\em In Proceedings of Interspeech}  1279--1283.

\bibitem[\protect\citeauthoryear{Ba, Kiros, and Hinton}{2016}]{ba2016layer}
Ba, J.~L.; Kiros, J.~R.; and Hinton, G.~E.
\newblock 2016.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}.

\bibitem[\protect\citeauthoryear{Bahdanau, Cho, and
  Bengio}{2015}]{Bahdanau:2015}
Bahdanau, D.; Cho, K.; and Bengio, Y.
\newblock 2015.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock {\em In Proceedings of ICLR}.

\bibitem[\protect\citeauthoryear{Bansal \bgroup et al\mbox.\egroup
  }{2018}]{bansal2018pre}
Bansal, S.; Kamper, H.; Livescu, K.; Lopez, A.; and Goldwater, S.
\newblock 2018.
\newblock Pre-training on high-resource speech recognition improves
  low-resource speech-to-text translation.
\newblock {\em In Proceedings of NAACL}  58--68.

\bibitem[\protect\citeauthoryear{B{\'e}rard \bgroup et al\mbox.\egroup
  }{2016}]{berard2016listen}
B{\'e}rard, A.; Pietquin, O.; Servan, C.; and Besacier, L.
\newblock 2016.
\newblock Listen and translate: A proof of concept for end-to-end
  speech-to-text translation.
\newblock {\em In Proceedings of NIPS}.

\bibitem[\protect\citeauthoryear{B{\'e}rard \bgroup et al\mbox.\egroup
  }{2018}]{berard2018end}
B{\'e}rard, A.; Besacier, L.; Kocabiyikoglu, A.~C.; and Pietquin, O.
\newblock 2018.
\newblock End-to-end automatic speech translation of audiobooks.
\newblock {\em In Proceedings of ICASSP}  6224--6228.

\bibitem[\protect\citeauthoryear{Chan \bgroup et al\mbox.\egroup
  }{2016}]{chan2016listen}
Chan, W.; Jaitly, N.; Le, Q.; and Vinyals, O.
\newblock 2016.
\newblock Listen, attend and spell: A neural network for large vocabulary
  conversational speech recognition.
\newblock {\em In Proceedings of ICASSP}  4960--4964.

\bibitem[\protect\citeauthoryear{Chiu \bgroup et al\mbox.\egroup
  }{2017}]{chiu2017state}
Chiu, C.-C.; Sainath, T.~N.; Wu, Y.; Prabhavalkar, R.; Nguyen, P.; Chen, Z.;
  Kannan, A.; Weiss, R.~J.; Rao, K.; Gonina, K.; et~al.
\newblock 2017.
\newblock State-of-the-art speech recognition with sequence-to-sequence models.
\newblock {\em In Proceedings of ICASSP}.

\bibitem[\protect\citeauthoryear{Dong, Xu, and Xu}{2018}]{dong2018speech}
Dong, L.; Xu, S.; and Xu, B.
\newblock 2018.
\newblock Speech-transformer: a no-recurrence sequence-to-sequence model for
  speech recognition.
\newblock {\em In Proceedings of ICASSP}  5884--5888.

\bibitem[\protect\citeauthoryear{{Gangi} \bgroup et al\mbox.\egroup
  }{2019}]{gangi2019must}
{Gangi}, M. A.~D.; {Cattoni}, R.; {Bentivogli}, L.; {Negri}, M.; and {Turchi},
  M.
\newblock 2019.
\newblock Must-c: a multilingual speech translation corpus.
\newblock {\em In Proceedings of NAACL}  2012--2017.

\bibitem[\protect\citeauthoryear{He \bgroup et al\mbox.\egroup
  }{2016}]{he2016deep}
He, K.; Zhang, X.; Ren, S.; and Sun, J.
\newblock 2016.
\newblock Deep residual learning for image recognition.
\newblock {\em In Proceedings of CVPR}  770--778.

\bibitem[\protect\citeauthoryear{{Jia} \bgroup et al\mbox.\egroup
  }{2019}]{jia2019leveraging}
{Jia}, Y.; {Johnson}, M.; {Macherey}, W.; {Weiss}, R.~J.; {Cao}, Y.; {Chiu},
  C.-C.; {Ari}, N.; {Laurenzo}, S.~M.; and {Wu}, Y.
\newblock 2019.
\newblock Leveraging weakly supervised data to improve end-to-end
  speech-to-text translation.
\newblock {\em In Proceedings of ICASSP}  7180--7184.

\bibitem[\protect\citeauthoryear{{Kano}, {Sakti}, and
  {Nakamura}}{2017}]{kano2017structured}
{Kano}, T.; {Sakti}, S.; and {Nakamura}, S.
\newblock 2017.
\newblock Structured-based curriculum learning for end-to-end english-japanese
  speech translation.
\newblock {\em In Proceedings of Interspeech}  2630--2634.

\bibitem[\protect\citeauthoryear{Kingma and Ba}{2015}]{kingma2014adam}
Kingma, D.~P., and Ba, J.
\newblock 2015.
\newblock Adam: A method for stochastic optimization.
\newblock {\em In Proceedings of ICLR}.

\bibitem[\protect\citeauthoryear{{Liu} \bgroup et al\mbox.\egroup
  }{2019}]{liu2019end}
{Liu}, Y.; {Xiong}, H.; {Zhang}, J.; {He}, Z.; {Wu}, H.; {Wang}, H.; and
  {Zong}, C.
\newblock 2019.
\newblock End-to-end speech translation with knowledge distillation.
\newblock {\em In Proceedings of Interspeech}  1128--1132.

\bibitem[\protect\citeauthoryear{{Ma} \bgroup et al\mbox.\egroup
  }{2019}]{ma2018stacl}
{Ma}, M.; {Huang}, L.; {Xiong}, H.; {Liu}, K.; {Zhang}, C.; {He}, Z.; {Liu},
  H.; {Li}, X.; and {Wang}, H.
\newblock 2019.
\newblock Stacl: Simultaneous translation with implicit anticipation and
  controllable latency using prefix-to-prefix framework.
\newblock {\em in Proceddings of ACL}  3025--3036.

\bibitem[\protect\citeauthoryear{Papineni \bgroup et al\mbox.\egroup
  }{2002}]{papineni2002bleu}
Papineni, K.; Roukos, S.; Ward, T.; and Zhu, W.-J.
\newblock 2002.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock {\em In Proceedings of ACL}  311--318.

\bibitem[\protect\citeauthoryear{Post \bgroup et al\mbox.\egroup
  }{2013}]{post2013improved}
Post, M.; Kumar, G.; Lopez, A.; Karakos, D.; Callison-Burch, C.; and Khudanpur,
  S.
\newblock 2013.
\newblock Improved speech-to-text translation with the fisher and callhome
  spanish--english speech translation corpus.
\newblock {\em In Proceedings of IWSLT}.

\bibitem[\protect\citeauthoryear{Sak \bgroup et al\mbox.\egroup
  }{2015}]{sak2015fast}
Sak, H.; Senior, A.; Rao, K.; and Beaufays, F.
\newblock 2015.
\newblock Fast and accurate recurrent neural network acoustic models for speech
  recognition.
\newblock {\em In Proceedings of ICASSP}  1468--1472.

\bibitem[\protect\citeauthoryear{Sennrich \bgroup et al\mbox.\egroup
  }{2016}]{sennrich2015neural}
Sennrich, R.; Haddow, B.; Birch, A.; and Haddow, B.
\newblock 2016.
\newblock Neural machine translation of rare words with subword units.
\newblock {\em In Proceedings of ACL}  1715--1725.

\bibitem[\protect\citeauthoryear{{Sperber} \bgroup et al\mbox.\egroup
  }{2019}]{sperber2019attention}
{Sperber}, M.; {Neubig}, G.; {Niehues}, J.; and {Waibel}, A.
\newblock 2019.
\newblock Attention-passing models for robust and data-efficient end-to-end
  speech translation.
\newblock {\em Transactions of ACL} 7:313--325.

\bibitem[\protect\citeauthoryear{Sutskever, Vinyals, and
  Le}{2014}]{sutskever2014sequence}
Sutskever, I.; Vinyals, O.; and Le, Q.~V.
\newblock 2014.
\newblock Sequence to sequence learning with neural networks.
\newblock {\em In Proceedings of NIPS}  3104--3112.

\bibitem[\protect\citeauthoryear{Vaswani \bgroup et al\mbox.\egroup
  }{2017}]{vaswani2017attention}
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.~N.;
  Kaiser, {\L}.; and Polosukhin, I.
\newblock 2017.
\newblock Attention is all you need.
\newblock {\em In Proceedings of NIPS}  5998--6008.

\bibitem[\protect\citeauthoryear{{Wang} \bgroup et al\mbox.\egroup
  }{2019}]{wang2019synchronously}
{Wang}, Y.; {Zhang}, J.; {Zhou}, L.; {Liu}, Y.; and {Zong}, C.
\newblock 2019.
\newblock Synchronously generating two languages with interactive decoding.
\newblock {\em In Proceedings of EMNLP}  3341--3346.

\bibitem[\protect\citeauthoryear{Weiss \bgroup et al\mbox.\egroup
  }{2017}]{weiss2017sequence}
Weiss, R.~J.; Chorowski, J.; Jaitly, N.; Wu, Y.; and Chen, Z.
\newblock 2017.
\newblock Sequence-to-sequence models can directly translate foreign speech.
\newblock {\em In Proceedings of Interspeech}  2625--2629.

\bibitem[\protect\citeauthoryear{Zhang \bgroup et al\mbox.\egroup
  }{2019}]{zhang2019synchronous}
Zhang, J.; Zhou, L.; Zhao, Y.; and Zong, C.
\newblock 2019.
\newblock Synchronous bidirectional inference for neural sequence generation.
\newblock {\em arXiv preprint arXiv:1902.08955}.

\bibitem[\protect\citeauthoryear{Zhou \bgroup et al\mbox.\egroup
  }{2018}]{zhou2018syllable}
Zhou, S.; Dong, L.; Xu, S.; and Xu, B.
\newblock 2018.
\newblock Syllable-based sequence-to-sequence speech recognition with the
  transformer in mandarin chinese.
\newblock {\em In Proceedings of Interspeech}  791--795.

\bibitem[\protect\citeauthoryear{Zhou, Zhang, and
  Zong}{2019}]{zhou2019synchronous}
Zhou, L.; Zhang, J.; and Zong, C.
\newblock 2019.
\newblock Synchronous bidirectional neural machine translation.
\newblock {\em Transactions of ACL} 7:91--105.

\bibitem[\protect\citeauthoryear{Zong \bgroup et al\mbox.\egroup
  }{1999}]{1999The}
Zong, C.; Huang, T.; Xu, B.; and Xu, B.
\newblock 1999.
\newblock The technical analysis on automatic spoken language translation
  systems (in chinese).
\newblock {\em In Journal of Chinese Information Processing}.

\end{thebibliography}
