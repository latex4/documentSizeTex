\begin{thebibliography}{63}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Baevski et~al.(2021)Baevski, Hsu, Conneau, and Auli}]{baevski2021unsupervised}
Baevski, A.; Hsu, W.-N.; Conneau, A.; and Auli, M. 2021.
\newblock Unsupervised Speech Recognition.
\newblock In \emph{NeurIPS}.

\bibitem[{Baevski et~al.(2020)Baevski, Zhou, Mohamed, and Auli}]{baevski2020wav2vec}
Baevski, A.; Zhou, Y.; Mohamed, A.; and Auli, M. 2020.
\newblock Wav2Vec 2.0: A Framework for Self-Supervised Learning of Speech Representations.
\newblock In \emph{NeurIPS}.

\bibitem[{Black, Zen, and Tokuda(2007)}]{black2007statistical}
Black, A.~W.; Zen, H.; and Tokuda, K. 2007.
\newblock Statistical Parametric Speech Synthesis.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Bulut, Lee, and Narayanan(2007)}]{bulut2007analysis}
Bulut, M.; Lee, S.; and Narayanan, S.~S. 2007.
\newblock Analysis of Emotional Speech Prosody in Terms of Part of Speech Tags.
\newblock In \emph{Proc. Interspeech}.

\bibitem[{Chang, Yang, and Lee(2022)}]{chang2022distilhubert}
Chang, H.-J.; Yang, S.-w.; and Lee, H.-y. 2022.
\newblock DistilHuBERT: Speech Representation Learning by Layer-Wise Distillation of Hidden-Unit BERT.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton}]{bachman2019learning}
Chen, T.; Kornblith, S.; Norouzi, M.; and Hinton, G. 2020.
\newblock A Simple Framework for Contrastive Learning of Visual Representations.
\newblock In \emph{Proc. ICML}.

\bibitem[{Choi et~al.(2021)Choi, Lee, Kim, Lee, Heo, and Lee}]{choi2021neural}
Choi, H.-S.; Lee, J.; Kim, W.; Lee, J.; Heo, H.; and Lee, K. 2021.
\newblock Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations.
\newblock In \emph{NeurIPS}.

\bibitem[{Chung et~al.(2017)Chung, Senior, Vinyals, and Zisserman}]{son2017lip}
Chung, J.~S.; Senior, A.; Vinyals, O.; and Zisserman, A. 2017.
\newblock Lip Reading Sentences in the Wild.
\newblock In \emph{Proc. CVPR}.

\bibitem[{Cooke et~al.(2006)Cooke, Barker, Cunningham, and Shao}]{cooke2006audio}
Cooke, M.; Barker, J.; Cunningham, S.; and Shao, X. 2006.
\newblock An Audio-Visual Corpus for Speech Perception and Automatic Speech Recognition.
\newblock \emph{The Journal of the Acoustical Society of America}, 120(5): 2421--2424.

\bibitem[{Daubechies(1988)}]{daubechies1988orthonormal}
Daubechies, I. 1988.
\newblock Orthonormal Bases of Compactly Supported Wavelets.
\newblock \emph{Communications on pure and applied mathematics}, 41(7): 909--996.

\bibitem[{Elias et~al.(2021)Elias, Zen, Shen, Zhang, Jia, Weiss, and Wu}]{elias2021parallel}
Elias, I.; Zen, H.; Shen, J.; Zhang, Y.; Jia, Y.; Weiss, R.~J.; and Wu, Y. 2021.
\newblock Parallel Tacotron: Non-Autoregressive and Controllable TTS.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Ephrat and Peleg(2017)}]{ephrat2017vid2speech}
Ephrat, A.; and Peleg, S. 2017.
\newblock Vid2Speech: Speech Reconstruction from Silent Video.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Fan et~al.(2021)Fan, Li, Zhou, and Xu}]{fan2020exploring}
Fan, Z.; Li, M.; Zhou, S.; and Xu, B. 2021.
\newblock {Exploring Wav2Vec 2.0 on Speaker Verification and Language Identification}.
\newblock In \emph{Proc. Interspeech}.

\bibitem[{Griffin and Lim(1984)}]{griffin1984signal}
Griffin, D.; and Lim, J. 1984.
\newblock Signal Estimation from Modified Short-Time Fourier Transform.
\newblock \emph{IEEE Transactions on acoustics, speech, and signal processing}, 32(2): 236--243.

\bibitem[{Gulati et~al.(2020)Gulati, Qin, Chiu, Parmar, Zhang, Yu, Han, Wang, Zhang, Wu, and Pang}]{gulati2020conformer}
Gulati, A.; Qin, J.; Chiu, C.-C.; Parmar, N.; Zhang, Y.; Yu, J.; Han, W.; Wang, S.; Zhang, Z.; Wu, Y.; and Pang, R. 2020.
\newblock Conformer: Convolution-Augmented Transformer for Speech Recognition.
\newblock In \emph{Proc. Interspeech}.

\bibitem[{Guo et~al.(2022)Guo, Han, Wu, Tang, Chen, Wang, and Xu}]{guo2022cmt}
Guo, J.; Han, K.; Wu, H.; Tang, Y.; Chen, X.; Wang, Y.; and Xu, C. 2022.
\newblock CMT: Convolutional Neural Networks Meet Vision Transformers.
\newblock In \emph{Proc. CVPR}.

\bibitem[{He et~al.(2022)He, Zhao, Ren, Liu, Huai, and Yuan}]{he2022flow}
He, J.; Zhao, Z.; Ren, Y.; Liu, J.; Huai, B.; and Yuan, N. 2022.
\newblock Flow-Based Unconstrained Lip to Speech Generation.
\newblock In \emph{Proc. AAAI}.

\bibitem[{He et~al.(2016)He, Zhang, Ren, and Sun}]{he2016deep}
He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016.
\newblock Deep Residual Learning for Image Recognition.
\newblock In \emph{Proc. CVPR}.

\bibitem[{Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and Mohamed}]{hsu2021hubert}
Hsu, W.-N.; Bolte, B.; Tsai, Y.-H.~H.; Lakhotia, K.; Salakhutdinov, R.; and Mohamed, A. 2021.
\newblock HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units.
\newblock \emph{IEEE/ACM Trans. on Audio, Speech, and Language Processing}, 29: 3451--3460.

\bibitem[{Hunt and Black(1996)}]{hunt1996unit}
Hunt, A.~J.; and Black, A.~W. 1996.
\newblock Unit Selection in a Concatenative Speech Synthesis System Using a Large Speech Database.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Ji et~al.(2012)Ji, Xu, Yang, and Yu}]{ji20123d}
Ji, S.; Xu, W.; Yang, M.; and Yu, K. 2012.
\newblock 3D Convolutional Neural Networks for Human Action Recognition.
\newblock \emph{IEEE Trans. on Pattern Analysis and Machine Intelligence}, 35(1): 221--231.

\bibitem[{Kenton and Toutanova(2019)}]{devlin2018bert}
Kenton, J. D. M.-W.~C.; and Toutanova, L.~K. 2019.
\newblock BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.
\newblock In \emph{Proc. NAACL}.

\bibitem[{Kim et~al.(2022)Kim, Um, Yoon, and Kang}]{kim2022fluenttts}
Kim, C.; Um, S.~Y.; Yoon, H.; and Kang, H.~G. 2022.
\newblock FluentTTS: Text-Dependent Fine-Grained Style Control for Multi-Style TTS.
\newblock In \emph{Proc. Interspeech}.

\bibitem[{Kim et~al.(2021)Kim, Lee, Lee, and Lee}]{kim21f_interspeech}
Kim, J.-H.; Lee, S.-H.; Lee, J.-H.; and Lee, S.-W. 2021.
\newblock {Fre-GAN: Adversarial Frequency-Consistent Audio Synthesis}.
\newblock In \emph{Proc. Interspeech}.

\bibitem[{Kim, Hong, and Ro(2021)}]{kim2021lip}
Kim, M.; Hong, J.; and Ro, Y.~M. 2021.
\newblock Lip to Speech Synthesis with Visual Context Attentional GAN.
\newblock In \emph{NeurIPS}.

\bibitem[{Kim, Hong, and Ro(2023)}]{kim2023lip}
Kim, M.; Hong, J.; and Ro, Y.~M. 2023.
\newblock Lip-to-Speech Synthesis in the Wild with Multi-Task Learning.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Kim, Yeo, and Ro(2022)}]{kim2022distinguishing}
Kim, M.; Yeo, J.~H.; and Ro, Y.~M. 2022.
\newblock Distinguishing Homophenes Using Multi-Head Visual-Audio Memory for Lip Reading.
\newblock In \emph{Proc. AAAI}.

\bibitem[{Kong, Kim, and Bae(2020)}]{kong2020hifi}
Kong, J.; Kim, J.; and Bae, J. 2020.
\newblock Hifi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis.
\newblock In \emph{NeurIPS}.

\bibitem[{Kreuk et~al.(2022)Kreuk, Polyak, Copet, Kharitonov, Nguyen, Rivi{\`e}re, Hsu, Mohamed, Dupoux, and Adi}]{kreuk2021textless}
Kreuk, F.; Polyak, A.; Copet, J.; Kharitonov, E.; Nguyen, T.-A.; Rivi{\`e}re, M.; Hsu, W.-N.; Mohamed, A.; Dupoux, E.; and Adi, Y. 2022.
\newblock Textless Speech Emotion Conversion using Discrete and Decomposed Representations.
\newblock In \emph{Proc. EMNLP}.

\bibitem[{Kumar et~al.(2019)Kumar, Jain, Salik, Shah, Yin, and Zimmermann}]{kumar2019lipper}
Kumar, Y.; Jain, R.; Salik, K.~M.; Shah, R.~R.; Yin, Y.; and Zimmermann, R. 2019.
\newblock Lipper: Synthesizing Thy Speech Using Multi-View Lipreading.
\newblock In \emph{Proc. AAAI}.

\bibitem[{Lakhotia et~al.(2021)Lakhotia, Kharitonov, Hsu, Adi, Polyak, Bolte, Nguyen, Copet, Baevski, Mohamed et~al.}]{lakhotia2021generative}
Lakhotia, K.; Kharitonov, E.; Hsu, W.-N.; Adi, Y.; Polyak, A.; Bolte, B.; Nguyen, T.-A.; Copet, J.; Baevski, A.; Mohamed, A.; et~al. 2021.
\newblock On Generative Spoken Language Modeling from Raw Audio.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 9: 1336--1354.

\bibitem[{{\L}a{\'n}cucki(2021)}]{lancucki2021fastpitch}
{\L}a{\'n}cucki, A. 2021.
\newblock Fastpitch: Parallel Text-to-Speech with Pitch Prediction.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Le~Cornu and Milner(2015)}]{le2015reconstructing}
Le~Cornu, T.; and Milner, B. 2015.
\newblock Reconstructing Intelligible Audio Speech from Visual Speech Features.
\newblock In \emph{Proc. Interspeech}.

\bibitem[{Le~Cornu and Milner(2017)}]{le2017generating}
Le~Cornu, T.; and Milner, B. 2017.
\newblock Generating Intelligible Audio Speech from Visual Speech.
\newblock \emph{IEEE/ACM Trans. on Audio, Speech, and Language Processing}, 25(9): 1751--1761.

\bibitem[{Lee et~al.(2021{\natexlab{a}})Lee, Kim, Chung, and Lee}]{lee2021voicemixer}
Lee, S.-H.; Kim, J.-H.; Chung, H.; and Lee, S.-W. 2021{\natexlab{a}}.
\newblock VoiceMixer: Adversarial Voice Style Mixup.
\newblock In \emph{NeurIPS}.

\bibitem[{Lee et~al.(2022)Lee, Kim, Lee, Song, Hwang, and Lee}]{lee2022hierspeech}
Lee, S.-H.; Kim, S.-B.; Lee, J.-H.; Song, E.; Hwang, M.-J.; and Lee, S.-W. 2022.
\newblock HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference using Self-supervised Representations for Speech Synthesis.
\newblock In \emph{NeurIPS}.

\bibitem[{Lee et~al.(2021{\natexlab{b}})Lee, Yoon, Noh, Kim, and Lee}]{lee2021multi}
Lee, S.-H.; Yoon, H.-W.; Noh, H.-R.; Kim, J.-H.; and Lee, S.-W. 2021{\natexlab{b}}.
\newblock Multi-SpectroGAN: High-Diversity and High-Fidelity Spectrogram Generation with Adversarial Style Combination for Speech Synthesis.
\newblock In \emph{Proc. AAAI}.

\bibitem[{Lin et~al.(2021)Lin, Gou, Liu, Li, Lv, and Peng}]{lin2021completer}
Lin, Y.; Gou, Y.; Liu, Z.; Li, B.; Lv, J.; and Peng, X. 2021.
\newblock Completer: Incomplete Multi-view Clustering via Contrastive Prediction.
\newblock In \emph{Proc. CVPR}.

\bibitem[{Liu et~al.(2022)Liu, Li, Ren, Chen, and Zhao}]{liu2022diffsinger}
Liu, J.; Li, C.; Ren, Y.; Chen, F.; and Zhao, Z. 2022.
\newblock DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism.
\newblock In \emph{Proc. AAAI}.

\bibitem[{Loshchilov and Hutter(2019)}]{loshchilov2017decoupled}
Loshchilov, I.; and Hutter, F. 2019.
\newblock Decoupled Weight Decay Regularization.
\newblock In \emph{Proc. ICLR}.

\bibitem[{Ma, Petridis, and Pantic(2022)}]{ma2022visual}
Ma, P.; Petridis, S.; and Pantic, M. 2022.
\newblock Visual Speech Recognition for Multiple Languages in the Wild.
\newblock \emph{Nature Machine Intelligence}, 4(11): 930--939.

\bibitem[{Mauch and Dixon(2014)}]{mauch2014pyin}
Mauch, M.; and Dixon, S. 2014.
\newblock pYIN: A Fundamental Frequency Estimator Using Probabilistic Threshold Distributions.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Midgley(2006)}]{midgley2006new}
Midgley, N. 2006.
\newblock New Technology Catches Hitler Off Guard.
\newblock \emph{Telegraph}.

\bibitem[{Mira et~al.(2022)Mira, Haliassos, Petridis, Schuller, and Pantic}]{mira2022svts}
Mira, R.; Haliassos, A.; Petridis, S.; Schuller, B.~W.; and Pantic, M. 2022.
\newblock SVTS: Scalable Video-to-Speech Synthesis.
\newblock In \emph{Proc. Interspeech}.

\bibitem[{Petridis et~al.(2018)Petridis, Stafylakis, Ma, Cai, Tzimiropoulos, and Pantic}]{petridis2018end}
Petridis, S.; Stafylakis, T.; Ma, P.; Cai, F.; Tzimiropoulos, G.; and Pantic, M. 2018.
\newblock End-to-End Audiovisual Speech Recognition.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Polyak et~al.(2021)Polyak, Adi, Copet, Kharitonov, Lakhotia, Hsu, Mohamed, and Dupoux}]{polyak2021speech}
Polyak, A.; Adi, Y.; Copet, J.; Kharitonov, E.; Lakhotia, K.; Hsu, W.-N.; Mohamed, A.; and Dupoux, E. 2021.
\newblock Speech Resynthesis from Discrete Disentangled Self-Supervised Representations.
\newblock In \emph{Proc. Interspeech}.

\bibitem[{Popov et~al.(2021)Popov, Vovk, Gogoryan, Sadekova, and Kudinov}]{popov2021grad}
Popov, V.; Vovk, I.; Gogoryan, V.; Sadekova, T.; and Kudinov, M. 2021.
\newblock Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech.
\newblock In \emph{Proc. ICML}.

\bibitem[{Prajwal et~al.(2020)Prajwal, Mukhopadhyay, Namboodiri, and Jawahar}]{prajwal2020learning}
Prajwal, K.; Mukhopadhyay, R.; Namboodiri, V.~P.; and Jawahar, C. 2020.
\newblock Learning Individual Speaking Styles for Accurate Lip to Speech Synthesis.
\newblock In \emph{Proc. CVPR}.

\bibitem[{Prenger, Valle, and Catanzaro(2019)}]{prenger2019waveglow}
Prenger, R.; Valle, R.; and Catanzaro, B. 2019.
\newblock WaveGlow: A Flow-based Generative Network for Speech Synthesis.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Radford et~al.(2023)Radford, Kim, Xu, Brockman, McLeavey, and Sutskever}]{radford2023robust}
Radford, A.; Kim, J.~W.; Xu, T.; Brockman, G.; McLeavey, C.; and Sutskever, I. 2023.
\newblock Robust Speech Recognition via Large-Scale Weak Supervision.
\newblock In \emph{Proc. ICML}.

\bibitem[{Ren et~al.(2021)Ren, Hu, Tan, Qin, Zhao, Zhao, and Liu}]{ren2020fastspeech2}
Ren, Y.; Hu, C.; Tan, X.; Qin, T.; Zhao, S.; Zhao, Z.; and Liu, T.-Y. 2021.
\newblock FastSpeech 2: Fast and High-Quality End-to-End Text to Speech.
\newblock In \emph{Proc. ICLR}.

\bibitem[{Ren, Liu, and Zhao(2021)}]{ren2021portaspeech}
Ren, Y.; Liu, J.; and Zhao, Z. 2021.
\newblock PortaSpeech: Portable and High-Quality Generative Text-to-Speech.
\newblock In \emph{NeurIPS}.

\bibitem[{Ren et~al.(2022)Ren, Tan, Qin, Zhao, and Liu}]{ren2022revisiting}
Ren, Y.; Tan, X.; Qin, T.; Zhao, Z.; and Liu, T.-Y. 2022.
\newblock Revisiting Over-Smoothness in Text to Speech.
\newblock In \emph{Proc. ACL}.

\bibitem[{Shen et~al.(2018)Shen, Pang, Weiss, Schuster, Jaitly, Yang, Chen, Zhang, Wang, Skerrv-Ryan et~al.}]{shen2018natural}
Shen, J.; Pang, R.; Weiss, R.~J.; Schuster, M.; Jaitly, N.; Yang, Z.; Chen, Z.; Zhang, Y.; Wang, Y.; Skerrv-Ryan, R.; et~al. 2018.
\newblock Natural TTS Synthesis by Conditioning Wavenet on Mel Spectrogram Predictions.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Skerry-Ryan et~al.(2018)Skerry-Ryan, Battenberg, Xiao, Wang, Stanton, Shor, Weiss, Clark, and Saurous}]{skerry2018towards}
Skerry-Ryan, R.; Battenberg, E.; Xiao, Y.; Wang, Y.; Stanton, D.; Shor, J.; Weiss, R.; Clark, R.; and Saurous, R.~A. 2018.
\newblock Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron.
\newblock In \emph{Proc. ICML}.

\bibitem[{Smith(1987)}]{smith1987when}
Smith, J. 1987.
\newblock When Lip Reading between the Lines Had the Subtitles Beat by a Long Sight.
\newblock \emph{LA Times}.

\bibitem[{Sun et~al.(2020)Sun, Zhang, Weiss, Cao, Zen, and Wu}]{sun2020fully}
Sun, G.; Zhang, Y.; Weiss, R.~J.; Cao, Y.; Zen, H.; and Wu, Y. 2020.
\newblock Fully-Hierarchical Fine-grained Prosody Modeling for Interpretable Speech Synthesis.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}]{vaswani2017attention}
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.~N.; Kaiser, {\L}.; and Polosukhin, I. 2017.
\newblock Attention is All You Need.
\newblock In \emph{NeurIPS}.

\bibitem[{wen Yang et~al.(2021)wen Yang, Chi, Chuang, Lai, Lakhotia, Lin, Liu, Shi, Chang, Lin, Huang, Tseng, tik Lee, Liu, Huang, Dong, Li, Watanabe, Mohamed, and yi~Lee}]{yang21c_interspeech}
wen Yang, S.; Chi, P.-H.; Chuang, Y.-S.; Lai, C.-I.~J.; Lakhotia, K.; Lin, Y.~Y.; Liu, A.~T.; Shi, J.; Chang, X.; Lin, G.-T.; Huang, T.-H.; Tseng, W.-C.; tik Lee, K.; Liu, D.-R.; Huang, Z.; Dong, S.; Li, S.-W.; Watanabe, S.; Mohamed, A.; and yi~Lee, H. 2021.
\newblock SUPERB: Speech Processing Universal Performance Benchmark.
\newblock In \emph{Proc. Interspeech}.

\bibitem[{Yadav et~al.(2021)Yadav, Sardana, Namboodiri, and Hegde}]{yadav2021speech}
Yadav, R.; Sardana, A.; Namboodiri, V.~P.; and Hegde, R.~M. 2021.
\newblock Speech Prediction in Silent Videos Using Variational Autoencoders.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Yamamoto, Song, and Kim(2020)}]{yamamoto2020parallel}
Yamamoto, R.; Song, E.; and Kim, J.-M. 2020.
\newblock Parallel WaveGAN: A Fast Waveform Generation Model Based on Generative Adversarial Networks with Multi-Resolution Spectrogram.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Yasuda et~al.(2019)Yasuda, Wang, Takaki, and Yamagishi}]{yasuda2019investigation}
Yasuda, Y.; Wang, X.; Takaki, S.; and Yamagishi, J. 2019.
\newblock Investigation of Enhanced Tacotron Text-to-Speech Synthesis Systems with Self-Attention for Pitch Accent Language.
\newblock In \emph{Proc. ICASSP}.

\bibitem[{Zhang et~al.(2022)Zhang, Song, Tan, Tan, Yan, Liu, Wang, Zhou, Qin, Lee et~al.}]{zhang2022mixed}
Zhang, G.; Song, K.; Tan, X.; Tan, D.; Yan, Y.; Liu, Y.; Wang, G.; Zhou, W.; Qin, T.; Lee, T.; et~al. 2022.
\newblock Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme Representations for Text to Speech.
\newblock In \emph{Proc. Interspeech}.

\end{thebibliography}
