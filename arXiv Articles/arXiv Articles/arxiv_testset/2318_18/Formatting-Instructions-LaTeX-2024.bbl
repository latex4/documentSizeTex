\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Arora and Barak(2009)}]{arora2009computational}
Arora, S.; and Barak, B. 2009.
\newblock \emph{Computational complexity: a modern approach}.
\newblock Cambridge University Press.

\bibitem[{Assran et~al.(2020)Assran, Aytekin, Feyzmahdavian, Johansson, and Rabbat}]{assran2020advances}
Assran, M.; Aytekin, A.; Feyzmahdavian, H.~R.; Johansson, M.; and Rabbat, M.~G. 2020.
\newblock Advances in asynchronous parallel and distributed optimization.
\newblock \emph{Proceedings of the IEEE}, 108(11): 2013--2031.

\bibitem[{Avraamidou(2018)}]{avraamidou2018mixed}
Avraamidou, S. 2018.
\newblock Mixed-integer multi-level optimization through multi-parametric programming.

\bibitem[{Ben-Ayed and Blair(1990)}]{ben1990computational}
Ben-Ayed, O.; and Blair, C.~E. 1990.
\newblock Computational difficulties of bilevel linear programming.
\newblock \emph{Operations Research}, 38(3): 556--560.

\bibitem[{Bertsekas(2015)}]{bertsekas2015convex}
Bertsekas, D. 2015.
\newblock \emph{Convex optimization algorithms}.
\newblock Athena Scientific.

\bibitem[{Bertsekas and Yu(2011)}]{bertsekas2011unifying}
Bertsekas, D.~P.; and Yu, H. 2011.
\newblock A unifying polyhedral approximation framework for convex optimization.
\newblock \emph{SIAM Journal on Optimization}, 21(1): 333--360.

\bibitem[{Blair(1992)}]{blair1992computational}
Blair, C. 1992.
\newblock The computational complexity of multi-level linear programs.
\newblock \emph{Annals of Operations Research}, 34.

\bibitem[{B{\"u}rger, Notarstefano, and Allg{\"o}wer(2013)}]{burger2013polyhedral}
B{\"u}rger, M.; Notarstefano, G.; and Allg{\"o}wer, F. 2013.
\newblock A polyhedral approximation framework for convex and robust distributed optimization.
\newblock \emph{IEEE Transactions on Automatic Control}, 59(2): 384--395.

\bibitem[{Chen et~al.(2022{\natexlab{a}})Chen, Feng, Guo, and Yang}]{chen2022trilevel}
Chen, S.; Feng, S.; Guo, Z.; and Yang, Z. 2022{\natexlab{a}}.
\newblock Trilevel optimization model for competitive pricing of electric vehicle charging station considering distribution locational marginal price.
\newblock \emph{IEEE Transactions on Smart Grid}, 13(6): 4716--4729.

\bibitem[{Chen et~al.(2022{\natexlab{b}})Chen, Sun, Xiao, and Yin}]{chen2022single}
Chen, T.; Sun, Y.; Xiao, Q.; and Yin, W. 2022{\natexlab{b}}.
\newblock A single-timescale method for stochastic bilevel optimization.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, 2466--2488. PMLR.

\bibitem[{Choe et~al.(2022)Choe, Neiswanger, Xie, and Xing}]{choe2022betty}
Choe, S.~K.; Neiswanger, W.; Xie, P.; and Xing, E. 2022.
\newblock Betty: An automatic differentiation library for multilevel optimization.
\newblock \emph{arXiv preprint arXiv:2207.02849}.

\bibitem[{Cortez et~al.(2009)Cortez, Cerdeira, Almeida, Matos, and Reis}]{cortez2009modeling}
Cortez, P.; Cerdeira, A.; Almeida, F.; Matos, T.; and Reis, J. 2009.
\newblock Modeling wine preferences by data mining from physicochemical properties.
\newblock \emph{Decision support systems}, 47(4): 547--553.

\bibitem[{Davis and Drusvyatskiy(2019)}]{davis2019stochastic}
Davis, D.; and Drusvyatskiy, D. 2019.
\newblock Stochastic model-based minimization of weakly convex functions.
\newblock \emph{SIAM Journal on Optimization}, 29(1): 207--239.

\bibitem[{Dua, Graff et~al.(2017)}]{dua2017uci}
Dua, D.; Graff, C.; et~al. 2017.
\newblock UCI machine learning repository.

\bibitem[{Franc, Sonnenburg, and Werner(2011)}]{franc2011cutting}
Franc, V.; Sonnenburg, S.; and Werner, T. 2011.
\newblock Cutting plane methods in machine learning.
\newblock \emph{Optimization for Machine Learning}, 185--218.

\bibitem[{Franceschi et~al.(2018)Franceschi, Frasconi, Salzo, Grazzi, and Pontil}]{franceschi2018bilevel}
Franceschi, L.; Frasconi, P.; Salzo, S.; Grazzi, R.; and Pontil, M. 2018.
\newblock Bilevel programming for hyperparameter optimization and meta-learning.
\newblock In \emph{International Conference on Machine Learning}, 1568--1577. PMLR.

\bibitem[{Garg et~al.(2022)Garg, Zhang, Sridhara, Hosseini, Xing, and Xie}]{garg2022learning}
Garg, B.; Zhang, L.; Sridhara, P.; Hosseini, R.; Xing, E.; and Xie, P. 2022.
\newblock Learning from mistakes--a framework for neural architecture search.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~36, 10184--10192.

\bibitem[{Gould et~al.(2016)Gould, Fernando, Cherian, Anderson, Cruz, and Guo}]{gould2016differentiating}
Gould, S.; Fernando, B.; Cherian, A.; Anderson, P.; Cruz, R.~S.; and Guo, E. 2016.
\newblock On differentiating parameterized argmin and argmax problems with application to bi-level optimization.
\newblock \emph{arXiv preprint arXiv:1607.05447}.

\bibitem[{Guo et~al.(2020)Guo, Yang, Xu, Liu, and Lin}]{guo2020meets}
Guo, M.; Yang, Y.; Xu, R.; Liu, Z.; and Lin, D. 2020.
\newblock When nas meets robustness: In search of robust architectures against adversarial attacks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 631--640.

\bibitem[{Han, Shi, and Huang(2023)}]{han2023fedal}
Han, P.; Shi, X.; and Huang, J. 2023.
\newblock FedAL: Black-Box Federated Knowledge Distillation Enabled by Adversarial Learning.
\newblock \emph{arXiv preprint arXiv:2311.16584}.

\bibitem[{Han, Wang, and Leung(2020)}]{han2020adaptive}
Han, P.; Wang, S.; and Leung, K.~K. 2020.
\newblock Adaptive gradient sparsification for efficient federated learning: An online learning approach.
\newblock In \emph{2020 IEEE 40th international conference on distributed computing systems (ICDCS)}, 300--310. IEEE.

\bibitem[{Harrison~Jr and Rubinfeld(1978)}]{harrison1978hedonic}
Harrison~Jr, D.; and Rubinfeld, D.~L. 1978.
\newblock Hedonic housing prices and the demand for clean air.
\newblock \emph{Journal of environmental economics and management}, 5(1): 81--102.

\bibitem[{He et~al.(2020)He, Fan, Wu, Xie, and Girshick}]{he2020momentum}
He, K.; Fan, H.; Wu, Y.; Xie, S.; and Girshick, R. 2020.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 9729--9738.

\bibitem[{Ji, Yang, and Liang(2021)}]{ji2021bilevel}
Ji, K.; Yang, J.; and Liang, Y. 2021.
\newblock Bilevel optimization: Convergence analysis and enhanced design.
\newblock In \emph{International Conference on Machine Learning}, 4882--4892. PMLR.

\bibitem[{Jiao, Yang, and Song(2022)}]{jiao2022distributed}
Jiao, Y.; Yang, K.; and Song, D. 2022.
\newblock Distributed distributionally robust optimization with non-convex objectives.
\newblock \emph{Advances in neural information processing systems}, 35: 7987--7999.

\bibitem[{Jiao et~al.(2022{\natexlab{a}})Jiao, Yang, Song, and Tao}]{jiao2022timeautoad}
Jiao, Y.; Yang, K.; Song, D.; and Tao, D. 2022{\natexlab{a}}.
\newblock TimeAutoAD: Autonomous Anomaly Detection With Self-Supervised Contrastive Loss for Multivariate Time Series.
\newblock \emph{IEEE Transactions on Network Science and Engineering}, 9(3): 1604--1619.

\bibitem[{Jiao et~al.(2022{\natexlab{b}})Jiao, Yang, Wu, Song, and Jian}]{jiao2022asynchronous}
Jiao, Y.; Yang, K.; Wu, T.; Song, D.; and Jian, C. 2022{\natexlab{b}}.
\newblock Asynchronous Distributed Bilevel Optimization.
\newblock In \emph{The Eleventh International Conference on Learning Representations}.

\bibitem[{LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner}]{lecun1998gradient}
LeCun, Y.; Bottou, L.; Bengio, Y.; and Haffner, P. 1998.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86(11): 2278--2324.

\bibitem[{Liu et~al.(2021)Liu, Liu, Zeng, and Zhang}]{liu2021towards}
Liu, R.; Liu, Y.; Zeng, S.; and Zhang, J. 2021.
\newblock Towards gradient-based bilevel optimization with non-convex followers and beyond.
\newblock \emph{Advances in Neural Information Processing Systems}, 34: 8662--8675.

\bibitem[{Lu et~al.(2020)Lu, Tsaknakis, Hong, and Chen}]{lu2020hybrid}
Lu, S.; Tsaknakis, I.; Hong, M.; and Chen, Y. 2020.
\newblock Hybrid block successive approximation for one-sided non-convex min-max problems: algorithms and applications.
\newblock \emph{IEEE Transactions on Signal Processing}, 68: 3676--3691.

\bibitem[{Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and Ng}]{netzer2011reading}
Netzer, Y.; Wang, T.; Coates, A.; Bissacco, A.; Wu, B.; and Ng, A.~Y. 2011.
\newblock Reading digits in natural images with unsupervised feature learning.

\bibitem[{Qian et~al.(2019)Qian, Zhu, Tang, Jin, Sun, and Li}]{qian2019robust}
Qian, Q.; Zhu, S.; Tang, J.; Jin, R.; Sun, B.; and Li, H. 2019.
\newblock Robust optimization over multiple domains.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~33, 4739--4746.

\bibitem[{Raghu et~al.(2021)Raghu, Lorraine, Kornblith, McDermott, and Duvenaud}]{raghu2021meta}
Raghu, A.; Lorraine, J.; Kornblith, S.; McDermott, M.; and Duvenaud, D.~K. 2021.
\newblock Meta-learning to improve pre-training.
\newblock \emph{Advances in Neural Information Processing Systems}, 34: 23231--23244.

\bibitem[{Saheya, Nguyen, and Chen(2019)}]{saheya2019neural}
Saheya, B.; Nguyen, C.~T.; and Chen, J.-S. 2019.
\newblock Neural network based on systematically generated smoothing functions for absolute value equation.
\newblock \emph{Journal of Applied Mathematics and Computing}, 61(1): 533--558.

\bibitem[{Sato, Tanaka, and Takeda(2021)}]{sato2021gradient}
Sato, R.; Tanaka, M.; and Takeda, A. 2021.
\newblock A Gradient Method for Multilevel Optimization.
\newblock \emph{Advances in Neural Information Processing Systems}, 34: 7522--7533.

\bibitem[{Sinha, Malo, and Deb(2017)}]{sinha2017review}
Sinha, A.; Malo, P.; and Deb, K. 2017.
\newblock A review on bilevel optimization: From classical to evolutionary approaches and applications.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 22(2): 276--295.

\bibitem[{Su et~al.(2022)Su, Zhang, Cai, Ren, Wang, Yi, Song, Chen, Deng, Xu et~al.}]{su2022gba}
Su, W.; Zhang, Y.; Cai, Y.; Ren, K.; Wang, P.; Yi, H.; Song, Y.; Chen, J.; Deng, H.; Xu, J.; et~al. 2022.
\newblock GBA: A Tuning-free Approach to Switch between Synchronous and Asynchronous Training for Recommendation Models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35: 29525--29537.

\bibitem[{Subramanya and Riggio(2021)}]{subramanya2021centralized}
Subramanya, T.; and Riggio, R. 2021.
\newblock Centralized and federated learning for predictive {VNF} autoscaling in multi-domain {5G} networks and beyond.
\newblock \emph{IEEE Transactions on Network and Service Management}, 18(1): 63--78.

\bibitem[{Tarzanagh et~al.(2022)Tarzanagh, Li, Thrampoulidis, and Oymak}]{tarzanagh2022fednest}
Tarzanagh, D.~A.; Li, M.; Thrampoulidis, C.; and Oymak, S. 2022.
\newblock Fednest: Federated bilevel, minimax, and compositional optimization.
\newblock In \emph{International Conference on Machine Learning}, 21146--21179. PMLR.

\bibitem[{Tawarmalani and Sahinidis(2005)}]{tawarmalani2005polyhedral}
Tawarmalani, M.; and Sahinidis, N.~V. 2005.
\newblock A polyhedral branch-and-cut approach to global optimization.
\newblock \emph{Mathematical programming}, 103(2): 225--249.

\bibitem[{Trombettoni et~al.(2011)Trombettoni, Araya, Neveu, and Chabert}]{trombettoni2011inner}
Trombettoni, G.; Araya, I.; Neveu, B.; and Chabert, G. 2011.
\newblock Inner regions and interval linearizations for global optimization.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~25, 99--104.

\bibitem[{Wang et~al.(2021)Wang, Chen, Lin, Sigal, and de~Silva}]{wang2021discriminative}
Wang, J.; Chen, J.; Lin, J.; Sigal, L.; and de~Silva, C.~W. 2021.
\newblock Discriminative feature alignment: Improving transferability of unsupervised domain adaptation by Gaussian-guided latent alignment.
\newblock \emph{Pattern Recognition}, 116: 107943.

\bibitem[{Xie, Koyejo, and Gupta(2019)}]{xie2019asynchronous}
Xie, C.; Koyejo, S.; and Gupta, I. 2019.
\newblock Asynchronous federated optimization.
\newblock \emph{arXiv preprint arXiv:1903.03934}.

\bibitem[{Xu et~al.(2020)Xu, Zhang, Xu, and Lan}]{xu2020unified}
Xu, Z.; Zhang, H.; Xu, Y.; and Lan, G. 2020.
\newblock A unified single-loop alternating gradient projection algorithm for nonconvex-concave and convex-nonconcave minimax problems.
\newblock \emph{arXiv preprint arXiv:2006.02032}.

\bibitem[{Yang et~al.(2014)Yang, Huang, Wu, Wang, and Chiang}]{yang2014distributed}
Yang, K.; Huang, J.; Wu, Y.; Wang, X.; and Chiang, M. 2014.
\newblock Distributed robust optimization ({DRO}), part {I}: {Framework} and example.
\newblock \emph{Optimization and Engineering}, 15(1): 35--67.

\bibitem[{Yang et~al.(2008)Yang, Wu, Huang, Wang, and Verd{\'u}}]{yang2008distributed}
Yang, K.; Wu, Y.; Huang, J.; Wang, X.; and Verd{\'u}, S. 2008.
\newblock Distributed robust optimization for communication networks.
\newblock In \emph{IEEE INFOCOM 2008-The 27th Conference on Computer Communications}, 1157--1165. IEEE.

\bibitem[{Zhang and Kwok(2014)}]{zhang2014asynchronous}
Zhang, R.; and Kwok, J. 2014.
\newblock Asynchronous distributed {ADMM} for consensus optimization.
\newblock In \emph{International conference on machine learning}, 1701--1709. PMLR.

\bibitem[{Zhang et~al.(2022)Zhang, Zhang, Khanduri, Hong, Chang, and Liu}]{zhang2022revisiting}
Zhang, Y.; Zhang, G.; Khanduri, P.; Hong, M.; Chang, S.; and Liu, S. 2022.
\newblock Revisiting and advancing fast adversarial training through the lens of bi-level optimization.
\newblock In \emph{International Conference on Machine Learning}, 26693--26712. PMLR.

\end{thebibliography}
