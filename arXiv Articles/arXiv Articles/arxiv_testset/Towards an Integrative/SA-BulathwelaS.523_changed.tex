\def\year{2020}\relax
%File: formatting-instruction.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai20}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet} % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{graphicx}  % DO NOT CHANGE THIS
\usepackage{xcolor}
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
\usepackage{amssymb}
%\nocopyright
%PDF Info Is REQUIRED.
% For /Author, add all authors within the parentheses, separated by commas. No accents or commands.
% For /Title, add Title in Mixed Case. No accents or commands. Retain the parentheses.
% /Title ()
% Put your actual complete title (no codes, scripts, shortcuts, or LaTeX commands) within the parentheses in mixed case
% Leave the space between \Title and the beginning parenthesis alone
% /Author ()
% Put your actual complete list of authors (no codes, scripts, shortcuts, or LaTeX commands) within the parentheses in mixed case.
% Each author should be only by a comma. If the name contains accents, remove them. If there are any LaTeX commands,
% remove them.

\usepackage{booktabs}
\usepackage{amsmath}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{caption} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \natbib} -- This package is specifically forbidden -- use the following workaround:
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
%  -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
%  -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai20.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%
\setlength\titlebox{2.5in} % If your paper contains an overfull \vbox too high warning at the beginning of the document, use this
% command to correct it. You may not alter the value below 2.5 in
\title{Towards an Integrative Educational Recommender \\ for Lifelong Learners
% (Student Abstract)
}
%Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
% \author{Author(s) Anonymised}
%
\author{
% Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{Primarily Mike Hamilton of the Live Oak Press, LLC, with help from the AAAI Publications Committee}\\ \Large \textbf{AAAI Style Contributions by
% Pater Patel Schneider,} \\
\Large \textbf{Sahan Bulathwela, Mar\'ia P\'erez-Ortiz, Emine Yilmaz and John Shawe-Taylor}\\ % All authors must be in the same font size and format. Use \Large and \textbf to achieve this result when breaking a line
Department of Computer Science, University College London \\
Gower Street, London WC1E 6BT, UK\\ %If you have multiple authors and multiple affiliations
% use superscripts in text and roman font to identify them. For example, Sunil Issar,\textsuperscript{\rm 2} J. Scott Penberthy\textsuperscript{\rm 3} George Ferguson,\textsuperscript{\rm 4} Hans Guesgen\textsuperscript{\rm 5}. Note that the comma should be placed BEFORE the superscript for optimum readability
\{m.bulathwela, maria.perez, emine.yilmaz, j.shawe-taylor\}@ucl.ac.uk  % email address must be in roman text type, not monospace or sans serif
}
 \begin{document}

 \maketitle

\begin{abstract}
%The recent advances in computer-assisted learning systems and the availability of open educational resources today promise a pathway to provide cost-efficient high-quality education to large masses of learners. One of the most ambitious use cases of computer-assisted learning is to build a lifelong learning system. This is because, unlike short-term courses, lifelong learning presents many more challenges and requires sophisticated recommendation models that account for factors such as background knowledge of learners and novelty of the material to the learner. %In this context of lifelong learning, these aspects should be modelled over significantly long periods of time, accounting for their dynamic nature.
%Scaling such models over millions of learners for long periods of time is another of its challenges, which motivates the use of online learning light algorithms.
%This work presents the foundations towards building a dynamic and online model of learner's knowledge from implicit data. We i) use a text ontology based on Wikipedia to automatically extract knowledge components of educational resources and, ii) propose a set of Bayesian strategies that learn from learner's engagement. We further iii) construct an open educational video lectures dataset and test the performance of the proposed algorithms.
% The recent advances in computer-assisted learning systems and the availability of educational resources today promise a pathway to provide cost-efficient, high-quality education to large masses of learners.

One of the most ambitious use cases of computer-assisted learning is to build a recommendation system for lifelong learning. Most recommender algorithms exploit similarities between content and users, overseeing the necessity to leverage sensible learning trajectories for the learner. Lifelong learning thus presents unique challenges, requiring scalable and transparent models that can account for learner knowledge and content novelty simultaneously, while also retaining accurate learners representations for long periods of time. We attempt to build a novel educational recommender, that relies on an integrative approach combining multiple drivers of learners engagement. Our first step towards this goal is TrueLearn, which models content novelty and background knowledge of learners and achieves promising performance while retaining a human interpretable learner model.

% This work presents the foundations towards building a dynamic, scalable and transparent recommendation system for education, modelling learner's knowledge from implicit data in the form of engagement with educational resources. We i) use a text ontology based on Wikipedia to automatically extract knowledge components of educational resources and, ii) propose a set of online Bayesian strategies inspired by the well-known areas of item response theory and knowledge tracing. Our proposal, TrueLearn, focuses on recommendations for which the learner has enough background knowledge (so they are able to understand and learn from the material), and the material has enough novelty that would help the learner to improve their knowledge about the subject and keep them engaged. We further construct a large open educational video lectures dataset and test the performance of the proposed algorithms, which show clear promise towards building an effective lifelong learning recommendation system.

\end{abstract}

\section{Introduction}
As the world population grows, more innovative approaches should be sought to provide  high quality lifelong learning education opportunities to people of diverse cultures, languages, age groups and backgrounds.
% ~\cite{sdg4}.
% This has motivated the United Nations to prioritise \emph{ensuring lifelong learning opportunities for all} in the Sustainable Development Goals, the worlds best plan to build a better world for people and our planet by 2030.
Machine learning now promises to provide such benefits of personalised teaching to anyone in the world cost effectively.
% because of the use of
%with the aid of novel
%resource creation models  \cite{pawlowski2007open,TVET2018} and platforms such as X5GON \cite{x5gon}
% progressing towards
%making OERs available to learners.
% In the mean time, Open Educational Resources (OERs) have also undergone a significant growth.
%OERs can be  %New resource creation models, such as the Content Explosion Model \cite{pawlowski2007open} and the Open Educational Practice \cite{TVET2018}, are boosting even further educational resource creation at scale, platforms such as X5GON \cite{x5gon} progress towards making them available to learners.
% This work is scoped at creating a personalisation model to identify and recommend the most suitable educational materials, assisting learners on their personal learning pathway to achieve impactful learning outcomes.


% Personalised learning systems usually consist of two components \cite{Lan2014}: (i) {learning analytics},
% that capture %dynamic
% learner's knowledge and (ii) {content analytics}, that extract resource characteristics, such as knowledge components covered and resource quality/difficulty. In the context of learning analytics, the assessment and learning science communities %focus on two paradigms: %Item Response Theory \cite{Rasch1960} and Knowledge Tracing \cite{corbett1994knowledge},
% % both discussed %presented
% % in section \ref{topic:related_work} and
% aim to assess learner's knowledge at a specific time (e.g. a test).
% % Concerning c
% Content analytics,
% % these have
% historically have been provided by human experts. Although expert labelling appears sensible, the growth of educational resources demands for scalable and automatic annotation.

 %e.g. learning from implicit engagement.
%Simultaneously, with new privacy laws and regulations imposing further constraints on data utility and availability in the recent years, a system that uses or stores least amounts of data can be seen as data efficient. Even within the recommendation systems community, there is interest to find algorithms that rely on limited data and can operate with a limited/ time-truncated user history \cite{small_data_recsys}.
% \textcolor{blue}{\textbf{In my opinion data efficient referred to using implicit engagement, rather than explicit feedback. }}
 Since learner engagement is a prerequisite for achieving impactful learning outcomes~\cite{lan2017behavior}, we attempt to build a recommender system that models different drivers of engagement,
%  to match lifelong learners to suitable educational materials
assisting learners on their \emph{personal learning trajectory} to achieve their learning goals. Our approach differs from previous work in that it (i) incorporates different drivers of engagement such as resource quality, novelty, learner knowledge and interests; (ii) matches learners to useful and \emph{engaging fragments} of knowledge, as opposed to lengthy full resources; and (iii) supports a multi-lingual and multi-modal collection of learning resources.


% This paper proposes {a set of Bayesian strategies aimed at providing educational recommendations to lifelong learners} using only learner's engagement. To do so, we use an ontology based on Wikipedia to extract content analytics from the text representation of educational resources. Our objective is to develop an adaptive and scalable system that can recommend suitably difficult material and is transparent to learners. %We hypothesise that there might be other factors involved in engagement apart from knowledge, such as the novelty of the material to the learner.
% Our approach differs from previous work in that (i) it can be applied in situations where explicit feedback about the learner's knowledge is unavailable, as tends to be the case in informal lifelong learning; and (ii) we focus on recovering learner's knowledge, as opposed to previous work on recommender systems which mostly focuses on user interests.
% We test the different models and assumptions using a VideoLectures.net dataset composed of 18,933 learners and 248,643 view log
% entries, with promising results.% The final model




\section{Related Work} \label{topic:related_work}

Conventional recommendation systems that exist today mainly focus on exploiting user interests. On the contrary, educational recommenders face different challenges as a successful educational recommender ought to satisfy additional functionalities, that stem from attempting to bring learners closer to their goals effectively. Some
additional features worth mentioning are accounting for the novelty of materials~\cite{Drachsler:edurec} and identifying sensible learning trajectories.
Although handcrafting learning trajectories~\cite{bauman2018recommending} is an option, such an approach is highly domain specific and lacks scalability. Similarly, handcrafting the \emph{Knowledge Components (KCs)} (or topics/concepts) present in a resource also poses similar drawbacks, which motivate the need for an automatic, domain-agnostic entity linking algorithm.
% the necessity of
%accounting for the novelty of materials~\cite{Drachsler:edurec}.
% , having always been in the spotlight.
Incorporating these additional features to the system envisages i) detecting learners interests and goals, as these can significantly affect their motivation \cite{Salehi2014}; ii) detecting the current knowledge state of learners, the topics covered in a resource and the prerequisites necessary for benefiting from a learning material \cite{bauman2018recommending}; iii) recommending novel and relevant educational resources; and iv) accounting for how different content features of a resource impact how engaging a resource is
%  to the general population
\cite{quality_features,Guo_vid_prod}.

%Although handcrafting learning trajectories and recommendations~\cite{bauman2018recommending} is an option, such a domain specific approach is not scalable. Handcrafting the \emph{Knowledge Components (KCs)} (or topics/entities) present in a resource also poses similar drawbacks, which motivate the need for an automatic entity linking algorithm. Methods such as Wikification \cite{wikifier} offer potential solutions to this problem. %Learner interests and goals can also affect the motivation of learners~\cite{Salehi2014}. Also, different quality factors impact how engaging an education resource is to the general learner population \cite{Guo_vid_prod}.

The majority of work in adaptive educational systems builds on Item Response Theory (IRT)~\cite{Rasch1960,Pelanek2017} and Knowledge Tracing (KT)~\cite{yudelson2013individualized} that focus on estimating learner's knowledge for a narrow set of skills based on test answers. The work focusing on modelling a wide spectrum of skills over longer periods of time, which is our main focus, is surprisingly scarse.
% Majority of work in adaptive educational systems focuses on estimating learner's knowledge based on test answers,
% To do so, one needs to: i) determine the skills required to solve each exercise and ii) infer the learners knowledge state for those skills.
% modelling the learner at a static point in time and assessing a limited set of skills (in most cases, individual skills). However, for lifelong learning, a wider range of skills has to be modelled over long spans of time and prior research in this area is surprisingly scarce. We review in this section content and learning analytics, focusing for the latter on {Item Response Theory} (IRT)~\cite{trueskill} and {Knowledge Tracing} (KT)~\cite{yudelson2013individualized}, from which we draw inspiration.
% Personalised learning systems consist of two components
% \cite{Lan2014}
% : (i) \emph{content analytics}, that extract resource characteristics, such as \textbf{Knowledge Components (KCs)} covered and resource quality/difficulty and (ii) \emph{learning analytics}, that capture learner's knowledge.  Entity linking solutions such as Wikifier~\cite{wikifier} can associate text fragments with relevant Wikipedia concepts providing a human-interpretable, domain-agnostic set of KCs with no expert labelling costs.
% %Recommendation systems are popular across multiple domains. Different approaches such as collaborative filtering, Bayesian match making and extreme classification are used to match resource with consumers.

% %Learner and resource modelling are fundamental to all adaptive educational systems.


% % In the context of learning analytics, the assessment and learning science communities %focus on two paradigms: %Item Response Theory \cite{Rasch1960} and Knowledge Tracing \cite{corbett1994knowledge},

% Most literature
% in adaptive educational systems domain
% focuses on estimating learner's knowledge based on test answers,
% % To do so, one needs to: i) determine the skills required to solve each exercise and ii) infer the learners knowledge state for those skills.
% modelling the learner at a static point in time and assessing a limited set of skills (in most cases, individual skills). However, for lifelong learning, a wider range of skills has to be modelled over long spans of time and prior research in this area is surprisingly scarce. We review in this section content and learning analytics, focusing for the latter on {Item Response Theory} (IRT)~\cite{trueskill} and {Knowledge Tracing} (KT)~\cite{yudelson2013individualized}, from which we draw inspiration.

While excelling on the personalisation front, there are other features that are often overlooked when designing educational recommendation systems. We design our system with these features in mind:
(i) {Cross-modality} (e.g. video, text, audio etc.) and (ii) {cross-linguality} are vital to identifying and recommending educational resources across different modalities and languages. In a lifelong learning setting, these two features will allow matching learning resources to the most suitable learners that come from various backgrounds. (iii) {Transparency} empowers learners by building trust while supporting the learner's metacognition processes, such as planning, monitoring and reflection~\cite{Bull2016}. (iv) {Scalability} and (v) {data efficiency} allows maintaining the states of large masses of learners over longer periods of time while making the best use of available user signals, such as implicit engagement~\cite{Salehi2014}.


% The models proposed in this paper are inspired from multiple research areas related to resource and learning analytics, covered in this section.
% Most of this literature focuses on providing an estimate of learners knowledge based on their answers to tests or questionnaires.
% To do so, one needs to: i) determine the skills required to solve each exercise and ii) infer the learners knowledge state for those skills.  %Individual tests are tagged with KCs that are tested respectively.
%To predict a students performance on an exercise, we thus must: (1) determine which skill or skills are required to solve the exercise, and (2) infer the students knowledge state for those skills. With regard to (1), the correspondence between exercises and skills, which we will refer to as an expert labeling, has historically been provided by human experts. Automated techniques have been proposed, although they either rely on an expert labeling which they then refine [5] or treat the student knowledge state as static [3]. #






% \subsection{Content analytics: Knowledge components}


% %One of the primary requirements in building a recommendation system for education is deriving resource representations.
% %As outlined in sections \ref{topic:kt} and \ref{topic:trueskill}, BKTs use KCs while in different skills of players are modelled separately in TrueSkill 2.
% Content representations play a key role in recommending relevant materials to learners. In education, this entails extracting atomic units of learnable concepts that are contained in a learning resource. We refer to these concepts as \textbf{Knowledge Components (KCs)} that can be learned and mastered. However, KC extraction is challenging and expert labelling is the most commonly used approach. Although automated techniques have been proposed \cite{Lindsey2014}, these usually rely on partial expert labelling or the use of unsupervised learning approaches, which are complex to tune. Advances in deep learning have also led to the proposal of deep models that learn latent KCs \cite{Piech2015}. However, these deep representations make the interpretability of the learner's models and the resource representations more challenging. {Wikification}, a more recent approach, looks promising towards automatically extracting explainable KCs. Wikification identifies Wikipedia concepts present in the resource by connecting natural text to Wikipedia articles via entity linking \cite{wikifier}. This approach avoids expensive expert labelling while providing an ontology of humanly interpretable KCs. However, Wikipedia KCs may not be as accurate as those carefully crafted by education experts.

% This can entail for example extracting the different topics involved in a question/learning material or the difficulty. We refer to these topics as \textbf{knowledge components (KCs), i.e. atomic units of knowledge that can be learned and mastered}.

% In the context of education, extracting KCs can be challenging. In most cases, this is done by expert labelling, which is not scalable. Automated techniques have been proposed \cite{Lindsey2014}, although they either rely on an expert labelling which they then refine or treat the student knowledge state as static. Examples of this are unsupervised topic detection techniques (such as Latent Dirichlet Allocation, which require extensive tuning for optimal results) and deep learning (used to learn latent KPs from resource, however making interpretability and explainability of KPs challenging). \textbf{\textit{Wikification}, a more recent approach, looks more promising towards automatically extracting explainable KCs from a resource}. Wikification identifies Wikipedia concepts that are present in the resource by connecting natural text to Wikipedia articles via entity linking \cite{wikifier}.

% \textcolor{blue}{\textbf{There is some work on estimating difficulty of material, but they mostly assume that all questions/tests are related to the same topic. Estimating difficulty is complex if we do not have enough data. Mention this.}}


%The course creator/ expert carefully analyzing analysing and annotating tests with KPs is the route taken by most ITSs.
%This approach incurs significant time and opportunity costs.



% \subsection{Item Response Theory (IRT) and matchmaking} \label{topic:kt}

% IRT \cite{Rasch1960} focuses on designing, analysing and scoring ability tests by modelling learner's knowledge and question difficulty. However, IRT does not consider changes in knowledge over time. The simplest model, known as Rasch model \cite{Rasch1960}, proposes to compute the probability of scoring a correct answer as a function of the learner's skill $\theta_\ell$ and the difficulty of the question/resource $d_r$:
% \begin{equation}
%     P(\texttt{correct answer} | \theta_\ell, d_r) = f(\theta_\ell - d_r),
% \end{equation} where $f$ is usually a logistic. This idea has been extended to algorithms such as Elo \cite{elo}, to rank chess players based on their game outcomes, where instead of having learners and resources, two players compete. The well-known TrueSkill algorithm \cite{trueskill} improves this skill learning setting using a Bayesian approach, allowing teams of players and adding a dynamic component to update skills over time. Previous work has proposed the use of Elo-based algorithms for modelling learners \cite{Pelanek2017}, because on its similarity to the Rasch model and its computationally light online version. %These ideas are directly applicable to learner knowledge assessment in a lifelong learning setting.


% This very simple idea has also been used for ranking players in gaming based on game outcomes, with one of the first models derived being the Elo algorithm for chess \cite{elo}, in which instead of having $k_i$ and $d_z$ we have two players with associated game skills $s_i$ and $s_z$ competing. The well-known TrueSkill algorithm \cite{trueskill} builds upon the idea behind the Elo algorithm \cite{elo}, modelling skills as Gaussian variables using a Bayesian factor graph, extending the algorithm for team games and adding a dynamic component that allows skills to change over time. The use of Elo to capture learner's knowledge has been proposed in previous work \cite{Pelanek2017}, motivated by its similarity to the Rasch model and its computationally light online version. In this paper, we consider different adapted versions from TrueSkill for the same reasons.
%Similar systems have been introduced to adapt this idea in applications such as prediction of clicks in online advertising platform.

% TrueSkill algorithm estimates skill levels of players based on game outcomes \cite{trueskill}. It builds upon the idea behind the Elo algorithm \cite{elo} and models the data generation process as a Bayesian factor graph while extending the algorithm for team games. In the subsequent version, TrueSkill is improved by modelling different metrics (kills, assists and etc...) that go beyond win/ lose outcome \cite{trueskill2}.

%\textcolor{blue}{\textbf{Check paper: Elo-based learner modeling for the adaptive practice of facts}}

% \subsection{Knowledge Tracing (KT)} \label{topic:kt}

% KT \cite{corbett1994knowledge} is one of the most widespread models in intelligent tutoring systems, the main difference with IRT being that question difficulty is not considered.  It aims to estimate knowledge acquisition as a function of practice opportunities. Numerous variants of KT are emerging, e.g. enabling individualisation \cite{yudelson2013individualized}. More recently, Deep Knowledge Tracing \cite{Piech2015} has shown improvement over KT. However, the challenges in interpretability of the learned KCs can be seen as a major drawback of deep KT.

%Amongst many variants, Bayesian Knowledge Tracing (BKT) is one of the most popular models that attempts to estimate if a learner will succeed in a test based on how the learner has performed in past tests \cite{corbett1994knowledge}.
% Its aim, estimating knowledge acquisition
% as a function of practice opportunities through questions, is similar to the one of Item Response Theory. However, in this case, question difficulty is not considered.
 %Amongst many variants, Bayesian Knowledge Tracing (BKT) is one of the most popular models that attempts to estimate if a learner will succeed in a test based on how the learner has performed in past tests \cite{corbett1994knowledge}.
% KT tries to infer what skills a learner learns over time and based on that knowledge, how the learner will perform in upcoming tests. Consequently, variants of KT, that incorporate additional elements such as individualization \cite{yudelson2013individualized}, have emerged. Deep knowledge tracing has also shown promising in improving the performance of knowledge tracing \cite{Piech2015}. However, like most deep learning models, one of the drawbacks of this model is its hunger for data and the lack of interpretable knowledge components.


% \subsection{Bayesian Recommendation and Matchmaking} \label{topic:trueskill}





%\begin{itemize}
 %   \item Bayesian recommendation systems: Elo, Trueskill, prediction of clicks, matching reviewers to papers...
  %  \item Quality...
   % \item Bishop's book and skill estimation
    %\item Neural approaches.
    %\item Knowledge Tracing \footnote{file:///C:/Users/in4maniac/Downloads/edm2013_submission_20.pdf}
    %\item Wikification
%\end{itemize}


% \subsection{Recommendation from implicit feedback} \label{implicit}
% \textcolor{orange}{Implicit feedback has been used for building recommender systems for nearly two decades with great success \cite{Oard1998ImplicitFF,Jannach2018RecommendingBO}, as an alternative to explicit ratings, which have a high cognitive load on users. For videos, normalised {watch time} is commonly used as an implicit signal, i.e. a proxy for engagement \cite{Covington2016}. }


% \subsection{Educational recommender systems} \label{edurec}
% %Although conventional recommendation approaches have been proposed for education \cite{bobadilla2009collaborative}, educational recommenders need to consider factors such as  introducing  novelty  and accounting for the learning process to provide effective recommendations \cite{Drachsler:edurec}. Hybrid approaches \cite{hybrid_rec,Salehi2014} and incorporating additional information such as learning trajectories, curricula and learning goals \cite{bauman2018recommending,goal_based_edrec} in the recent years has contributed towards improving educational recommenders at the cost of higher complexity and challenge in  interpretability. This demands, investing efforts in developing, accurate, simple, and interpretable educational recommendation systems which we aim to endeavour through this work.

% Although conventional recommendation approaches (e.g. collaborative filtering) have been proposed for education \cite{bobadilla2009collaborative}, educational recommenders have unique challenges, such as  introducing  novelty  or accounting for the learning process \cite{Drachsler:edurec}. In the recent years, hybrid approaches \cite{hybrid_rec,Salehi2014} and deep learning methods \cite{goal_based_edrec} have improved educational recommenders, incorporating additional handcrafted information such as learning trajectories oar learning goals \cite{bauman2018recommending}. However, much still remains to be done. For example, most of these approaches rely on manual handcrafted trajectories, which is not scalable and domain specific. Moreover, hybrid approaches do not address novelty and deep learning methods suffer from a lack of transparency of the learned representations. These challenges motivate the development of accurate, scalable, simple, and transparent educational recommendation systems, which is our aim with this work.
% In the context of recommending educational resources to learners, several methods including collaborative filtering and content based filtering has been proposed. However, educational recommenders  differ significantly from conventional recommendation systems as the recommended materials should adhere to sensible learning pathways that are usually hard to compose with conventional similarity based approaches. Due to this reason, many recent educational recommenders employ
\begin{figure}[!tbp]
 \centering
 \includegraphics[width=\columnwidth]{./engagement_model_truelearn_model_v3.pdf}
 \caption{(i) Graphical model representing learner engagement (dashed arrows indicating the components tested) and (ii) TrueLearn factor graph (also, the part with dashed arrows in (i)), integrating resource topics ($d$), current knowledge ($k$) and novelty ($n$) to predict engagement (output factor). $\varepsilon_\ell$ is a dynamic factor of learner $\ell$ indicating the engagement margin with respect to the amount of novelty. Plates represent $T$ top ranked Wikipedia topics.}
% \caption{Representation of average F1 for users with different associated topic sparsity and number of events. Each data point represents a learner. Colours represent average F1. }
 \label{fig:learner_model}
\end{figure}

\section{Our Approach}
% Based on the literature describing different factors affecting engagement, w
We identify four factors that influence learners' engagement and develop a probabilistic graphical model that aims to recover those hidden variables using implicit engagement signals. Using a graphical model that learns from implicit engagement allows us to infer these hidden variables without compromising learner experience through excessive explicit user interventions. The identified factors are: i) baseline resource quality ($Q$), how engaging a resource is for the average learner; ii) background knowledge of the learner ($B$); iii) novelty of the learning material ($N$); and iv) curiosity or learning goals ($C$) of the learner as outlined in \figurename{ \ref{fig:learner_model}}. As a first step, we reformulate the IRT TrueSkill algorithm \cite{trueskill}, to model learner knowledge and novelty as a function of engagement (dashed arrows in \figurename{ \ref{fig:learner_model} (i)}).

\emph{TrueSkill} has several features that make it an excellent starting point. It is a scalable and online algorithm that shares similarities with our problem and provides a good framework for embedding novelty and a dynamic learner factor (that accounts for knowledge changing over time). TrueSkill algorithm and its successor, TrueSkill 2 \cite{trueskill2}, have been deployed and time-tested with millions of users playing multiplayer video games in the Microsoft Xbox Live system giving substantial evidence of its scalability. The TrueSkill framework also provides a method to address dynamic factor involved in learning how the knowledge state of players changes over time \cite{NIPS2007_3331}. The Gaussian skill parameter in TrueSkill, when used with a humanly interpretable knowledge component space (e.g. the Wikipedia topics covered in a resource), provides an intuitive and transparent knowledge representation. We propose several reformulations of TrueSkill in \cite{Bulathwela2020}, which we name \emph{TrueLearn}. We also propose in \cite{Bulathwela2020} a reformulation of Knowledge Tracing to our problem, demonstrating however in a large dataset the superiority of TrueSkill inspired algorithms.

% \begin{figure}[!tbp]
%  \centering
%  \includegraphics[width=0.62\columnwidth]{AuthorKit20/LaTeX/engagement_graphical_model_v1.pdf}
%  \caption{Learner engagement model. Green arrows indicate the components tested with promising results.}
% % \caption{Representation of average F1 for users with different associated topic sparsity and number of events. Each data point represents a learner. Colours represent average F1. }
%  \label{fig:learner_model}
% \end{figure}



\paragraph{Data:} We construct a dataset from the popular video lectures repository VideoLectures.Net (VLN). Since handcrafting the \emph{Knowledge Components (KCs)} in a resource is not scalable, we use an automatic entity linking algorithm, known as Wikification \cite{wikifier}.  The English transcription of the lecture (or the English translation) is used to annotate the lecture with the 5 most relevant knowledge components using a Wikipedia text ontology through Wikifier \cite{wikifier}. This allows us to work with multiple languages and modalities and automatise the extraction of KCs. We divide the lecture text into multiple fragments of approximately 5,000 characters (equivalent roughly to 5 minutes of lecture) before Wikification. The engagement label is computed by calculating the normalised watch time \cite{Guo_vid_prod}. The final dataset consists of 18,933 unique learners.


\paragraph{Models:} We implement four baseline models to compare TrueLearn against: i) \emph{Na\"ive persistence}, which assumes a static behaviour for all users, i.e. if the learner is engaged, they will remain engaged and vice versa; ii) \emph{Na\"ive majority}, which predicts future engagement based solely on mean past engagement of users; iii) KT model (\emph{Multi-Skill KT}) according to \cite{bishopsnewbook}; and iv) \emph{Vanilla TrueSkill} \cite{trueskill}.% We compare \emph{TrueLearn} model that incorporate content novelty with the above baselines as shown in \figurename \ref{fig:learner_model} (b).



\begin{table}[!h]
  \caption{Mean F1-Score with the full VLN dataset}
  \label{tab:truelearn_performance}
  \centering
  \begin{tabular}{l r}  \toprule
    Algorithm
    % & Acc. & Prec. & Rec.
    & F1-Score \\  \hline

    Na\"ive persistence
    % & \textit{0.769} & \textbf{0.631} & 0.629
    & 0.629 \\
    Na\"ive majority
    % & \textbf{0.774} & 0.561 & \textit{0.640}
    & \textit{0.640} \\
    Vanilla TrueSkill
    % & 0.444 & 0.522 & 0.406
    & 0.400 \\
    Multi skill KT
    % & 0.500 & 0.490 & 0.197
    & 0.259 \\
    TrueLearn
    % & 0.672 & \textit{0.608} & \textbf{0.821}
    & \textbf{0.677} \\
    \hline
  \end{tabular}
\end{table}



\paragraph{Conclusions:} The results in Table \ref{tab:truelearn_performance} show evidence that \emph{TrueLearn} outperforms the baselines while retaining a transparent learner model. The model is run per learner and trained in an online fashion, thus being scalable. The next step is to model content quality and learner curiosity within the same framework. Exploration into future user interfaces for learning with lecture fragments and ways to planning learning trajectories and recommending material are also timely.

\section{Acknowledgments}
 This research is conducted as part of the X5GON project (www.x5gon.org) funded from the EU's Horizon 2020 research and innovation programme grant No 761758 and partially funded by the EPSRC Fellowship titled "Task Based Information Retrieval", under grant No EP/P024289/1.

% \textcolor{blue}{\textbf{We are only concerned with online models. Clarify. Models that are run per user are also preferred for simplicity. }}
%Most education intelligent systems rely on tests and questionnaires for modelling the learner. However,
% Implicit feedback has been used for building recommender systems for nearly two decades with great success \cite{Oard1998ImplicitFF,Jannach2018RecommendingBO}, as an alternative to explicit ratings, which have a high cognitive load on users and are generally sparse. %Requiring learners to provide explicit feedback frequently can hinder their learning experience.
% For videos, normalised {watch time} is commonly used as an implicit proxy for engagement \cite{Covington2016,Guo_vid_prod},
%  %and discourage the use of the system.
% %Instead, we consider the use of {implicit feedback} in the form of
% shown to increase the likelihood of achieving better learning outcomes \cite{pardos2014affective,carini2006student,ramesh2014learning,lan2017behavior}. %The algorithms presented here
% % The algorithms presented here are a set of Bayesian learning algorithms for predicting
% %are aimed at predicting educational engagement.
% We distinguish several factors in the learning science literature that influence engagement: i) background knowledge \cite{yudelson2013individualized}, ii) novelty of the material \cite{Drachsler:edurec}, iii) learners interests or learning goals \cite{Salehi2014} and iv) quality \cite{Lane10} of learning resources. This paper focuses on i) and ii), as a first step towards building an integrative recommendation system that accounts for all four.

%\textcolor{blue}{We need to define engagement better.}
%In the context of learning and education, engagement is extensively studied in relation to learning outcomes \cite{slater2016semantic,lan2017behavior} and has shown positive relationships.
%To incorporate data efficiency, we propose learning from implicit engagement signals.


% We first present two relatively na\"ive baselines for modeling engagement. %which will later serve as priors for our proposed models.
% Secondly, we describe how we adapt two approaches from the literature, namely TrueSkill and KT. Then, we propose an extension of TrueSkill, defining educational engagement as a function of background knowledge and novelty. %\textcolor{blue}{Add literature for novelty, interest, quality, etc.}
% %\figurename{ \ref{fig:graphicalmodel}} explains the intuition behind these three components and shows a representation of the graphical model we propose to capture engagement.
% This is, the proposed system recommends resources for which the learner has the necessary background knowledge but there is novelty. %Although other factors such as resource quality might play a role in engagement, we exclude these components from our model at this point, assuming that all resources are of relatively high quality.
% To be able to handle large-scale scenarios, our work focuses on online learning solutions that are massively parallelisable, prioritising models that can be run per learner, for simplicity and transparency.


% There might be other components to consider for engagement, such as quality. However, we assume that all available resources in the system are of relative high quality. %We will also add a random component that would account for other factors (such as the user not engaging because they need to leave, etc).
 % see if they improve the performance. % We can have a model with only the background component and show its disadvantages and so on.


% \begin{figure*}[ht!]
% \centering
% \includegraphics[width=\textwidth]{./hypotheses.pdf}
% \caption{Graphical representation of different assumptions that can be made when modelling learner's knowledge. The methods tested in this paper are set to test these four hypotheses. }
% \label{fig:hypotheses}
% \end{figure*}


% % \begin{figure}[ht!]
% % \centering
% % \includegraphics[width=1\textwidth]{./graphmodel.pdf}
% % \caption{Graphical model proposed to model the learner's engagement. }
% % \label{fig:graphicalmodel}
% % \end{figure}
% \subsection{Problem formulation and assumptions}
% Consider a learning environment in which a learner $\ell$ interacts with a set of educational resources $S_\ell \subset \{r_1, \ldots, r_Q\}$ over a period of $T= (1,\ldots,t)$ time steps, $Q$ being the total of resources in the system.
% A resource $r_i$ is characterised by a set of top KCs or topics $K_{r_i} \subset \{1, \ldots, N \}$ ($N$ being the total of KCs considered by the system) and the depth of coverage $d_{r_i}$  of those. The key idea is to model the probability of engagement $e_{\ell, r_i}^{t} \in \{ 1, -1\}$ between learner $\ell$ and resource $r_i$ at time $t$ as a function of the learner skill $\theta^t_\ell$ and
% resource representation $d_{r_i}$ for the top KCs covered $K_{r_i}$.
% According to Bayes rule the posterior distribution is proportional to:
% \begin{equation}
%  P({\theta}^t_\ell | e^{t}_{\ell,r_i}, K_{r_i}, d_{r_i} ) \propto P( e^{t}_{\ell,r_i} | \theta^t_\ell, K_{r_i}, d_{r_i}) \cdot P(\theta^t_\ell).
% \end{equation}

% \figurename{ \ref{fig:hypotheses}} shows the intuition behind different hypothesis for modelling learner's skills (for one topic). Hypothesis i) shows the assumption made in IRT and KT (both focused on test scoring). This is, if the learner answers correctly to a test, the skill must exceed the difficulty of the question. The boundary of $\theta_\ell - d_r$ is shown using a dotted line in all cases.
% %Only one topic is considered.
% Hypothesis ii) shows the analogue for engagement (as a function of knowledge), i.e. if the learner is engaged, they have enough background to make use of the resource and vice versa. However, we hypothesize that this is very restrictive and that no assumption can be made from the non-engaged cases (the learner might not be engaged for a myriad of reasons, e.g. the learner being advanced in a topic and finding the resource too easy, in which case we can not say that they lack the necessary background). This idea that we can only learn background knowledge from positive engagement is shown in hypothesis iii) and is a common assumption when learning from implicit feedback \cite{Jannach2018RecommendingBO}. The last plot (hypothesis iv)) shows the combination of knowledge and novelty: if the learner is engaged, they must have the appropriate background and the content must also be novel to them (i.e. neither too easy nor too difficult). We introduce $\varepsilon$ as the engagement margin. %\textcolor{blue}{Think of better way of explaining this.} \textcolor{orange}{Can use a, b and c to refer to sub figures}
% %We test all these assumptions in our experiments.


% \subsection{Baselines for engagement}\label{sec:baselines}

% Since learning from educational engagement is a novel research area we could not find suitable baselines to compare against.
% % there are no baselines that we can compare to per se.
% Our first contribution is to propose two relatively na\"ive baselines: i) persistence, which assumes a static behaviour for all users $P(e_{\ell, \cdot}^t) = P(e_{\ell, \cdot}^{t-1})$, where $(\cdot)$ indicates any resource, i.e. if the learner is engaged, they will remain engaged and vice versa; ii) majority of user engagement, which predicts future engagement based solely on mean past engagement of users, i.e. $P(e_{\ell, \cdot}^t) = \frac{1}{n} \cdot \sum_{i=1}^{t-1} P(e_{\ell, \cdot}^{i})$.
% %and iii) popularity of video lectures, which disregards the learner influence and simply defines engagement as a function of past engagement over all past learners.
% The persistence baseline assumes a common model for both learners and resources. The majority baseline assumes differences between users, and disregards resource differences. %Finally, popularity assumes only differences between resources, but not among learners.



% \subsection{TrueLearn: Modelling knowledge}\label{sec:knowledge}
% Our second contribution is to
% extend the most well-known approaches for modelling skills/knowledge: TrueSkill \cite{trueskill} and KT \cite{corbett1994knowledge}. Our proposed model, {TrueLearn}, is inspired on TrueSkill with regard to representing {and learning skills} (we use TrueSkill because we saw in preliminary experiments that it could predict engagement better than KT).

% In TrueSkill, each player $\ell$  is assumed to have an unknown real skill $\theta^t_\ell \in \mathbb{R}$, exhibiting a performance $p^t_\ell$ drawn according to $p(p^t_\ell| \theta_\ell^t) = \mathcal{N}(p^t_\ell; \theta_\ell^t, \beta^2)$ with fixed variance $\beta^2$. The outcome of the game $y^t_{jz}$ between two players $\ell_j$ and $\ell_z$ (in our case learner $\ell$ and resource $r_i$) is modelled as:
% \begin{equation}
% P(p^t_{\ell_j} > p^t_{\ell_z} | \theta^t_{\ell_j},\theta^t_{\ell_z}) := \Phi  \left ( \frac{ \theta^t_{\ell_j} - \theta^t_{\ell_z} }{\sqrt{2}\beta} \right ),
% \end{equation}
% where $\Phi$ is the cumulative density of a zero-mean unit variance Gaussian.
% %In our case, instead of player $\ell_2$, we consider that learner $\ell_1$ competes against a resource $z$.
% To adapt TrueSkill, we consider three approaches. The first, referred to as \textbf{Vanilla TrueSkill}, represents the original TrueSkill algorithm and models a single skill for the learner $\theta_\ell$ and the depth of the resource $d_{r_i}$ as two players competing.
% Engagement is used as output of the game, meaning that if the learner is engaged, the skill of the learner is equal or larger than the depth of the resource $P(e^t_{\ell, r_i}) = P(p^t_{\ell} > p_{r_i})$.
% However,
% as opposed to Vanilla TrueSkill, we wish to model multiple skills for a learner: $\boldsymbol{\theta}_\ell = (\theta_{\ell,1}, \ldots, \theta_{\ell,N})$.
% TrueSkill also allows for teams, assuming that the performance of a team is the sum of the individual performance of its players.
% The second version of TrueSkill that we consider (our first proposal, \textbf{TrueLearn dynamic-depth}) is based on two teams playing, where both the learner and resource are represented as a "team of skills":
% \begin{equation}
%     p^t_\ell = \sum_{h \in K_{r_i}} \theta^t_{\ell,h}, \; \;\; \; p_{r_i} = \sum_{h \in K_{r_i}} d_{r_i,h}.
% \end{equation}
% Knowledge components $K_z$ thus define teams. We consider this approach rather than assuming that each individual skill has to win over its associated KC depth because we observed that most KCs represent related topics. A similar approach using Elo system and knowledge for only one skill was considered in \cite{Pelanek2017}. For the third model (named \textbf{TrueLearn fixed-depth}), we use a similar approach but fix the branch to the observed knowledge depth, using  text cosine similarity defined in the next section.

% Unlike TrueSkill, KT uses Bernoulli variables to model skills $\theta^t_{\ell,h} \sim \texttt{Bernoulli}(\pi^t_{\ell,h})$, assuming that a learner $\ell$ would have either mastered a skill or not (represented by probability $\pi^t_{\ell,h}$). Since the objective of KT is not to model learning but to capture the state of mastery at given time, %since skills are not expected to change during a test.
% KT considers that once a learner has mastered a skill it cannot be unlearnt.
% For the extension of KT (named \textbf{Multi skill KT}), we also consider multiple skills.
% Skills are initialised using a $\texttt{Bernoulli}(0.5)$ prior, assuming that the latent skill is equally likely to be mastered than not. A noise factor is also included (similarly to $\beta$ in TrueSkill). This reformulation is inspired by \cite{bishopsnewbook}.


% \figurename{ \ref{fig:factorgraph1}} shows a representation of the factor graphs used for these three models, together with TrueLearn, covered in the next section. A factor graph is a bi-partite graph consisting of variable and factor nodes, shown respectively with circles and squares. Gray filled circles represent observed variables. Message passing is used for inference, where messages are approximated as well as possible through moment matching.
%  Since our aim is to report skill estimates in real-time after learner's activity, we use an online
% learning scheme referred to as density filtering for all models, where the posterior distribution is used as the prior distribution for the next time instant.
% The models presented here are used to test hypotheses ii) and iii) in \figurename{ \ref{fig:hypotheses}}. %where it is assumed that we can only gather learner's knowledge from positive engagement data. \textcolor{blue}{Why?}


%  \begin{figure*}[ht!]
% \centering
% \includegraphics[width=0.9\textwidth]{./factographs_reordered.pdf}
% \caption{Factor graph for Multi skill Kt, Vanilla TrueSkill and different versions of the TrueLearn model. Plates represent groups of variables ($N$ Wikipedia topics).}
% \label{fig:factorgraph1}
% \end{figure*}


% \subsection{TrueLearn: Extending knowledge with novelty}\label{sec:truelearn}

% \textbf{TrueLearn novelty} additionally introduces {novelty}, defined as the degree to which a resource contains new information for the learner. %Interest is defined as the learner's personal affinity to the topics contained in the KC.
% Engagement outcomes $e^t_{\ell,r_i}$ between learner $\ell$ and resource $r_i$ are determined in this case as:
% \begin{equation}
% e^t_{\ell,r_i} :=
% \begin{Bmatrix}
% + 1 \; \; \texttt{if} | p^t_{\ell} - p_{r_i} | \leq \varepsilon^t_\ell\\
% -1 \; \; \texttt{otherwise},
%     \end{Bmatrix}
% \end{equation}
% where the parameter $\varepsilon^t_\ell>0$ is referred to as the engagement margin and is learner dependent. This represents the idea that both the learner and resource must be found in a similar knowledge state for the learner to be engaged (hypothesis (iv) in \figurename{ \ref{fig:hypotheses}}).
% This engagement margin $\varepsilon^t_\ell$ is set counting the fraction of engaged outcomes for a learner and relating the margin to the probability of engagement by:
% \begin{equation}
%     P(e^t_{\ell,\cdot}) = \Phi \left ( \frac{\varepsilon^t_\ell}{\sqrt{|K_{r_i}|}\beta} \right ) - \Phi \left ( \frac{-\varepsilon^t_\ell}{\sqrt{|K_{r_i}|}\beta} \right ).
% \end{equation}
% The model can be seen in \figurename{ \ref{fig:factorgraph1}}. %This model implements the assumption in the right part of \figurename{ \ref{fig:hypotheses}}, where we can
% Here, we learn learner's knowledge from positive and negative engagement.
% The function represented by the factor graph
% is the joint distribution $p(\theta^t_\ell, p^t_\ell, p_{r_i} | e^t_{\ell,r_i}, K_{r_i}, d_{r_i})$, given by the product of all the
% functions associated with each factor. The posterior $p(\theta^t_\ell | e^t_{\ell,r_i}, K_{r_i}, d_{r_i})$ is computed from the joint distribution integrating the learner and resource performances $p^t_\ell$ and $p_{r_i}$.

% \paragraph{Dynamics}

% %   \begin{figure}[ht!]
% % \centering
% % \includegraphics[width=0.5\textwidth]{./background.pdf}
% % \caption{Factor graph for the background model. Coloured circles represent the order for the message passing algorithm.}
% % \label{fig:graphicalmodel}
% % \end{figure}

% So far all models assume a stationary data
% distribution and hence in the limit of infinite observations, learning would come to a halt. Like in TrueSkill, we consider a Gaussian drift over skills between time steps given by $p(\theta^t_\ell | \theta^{t-1}_\ell) = \mathcal{N}(\theta_\ell^t; \theta_\ell^{t-1}, \tau^2)$.   This is introduced as an additive variance component in the subsequent prior and is crucial for lifelong learning.  For Multi skill KT,
% we increase the uncertainty by moving $\pi_\ell$ in the direction of 0.5 probability in steps of $\tau$. However, our results show no change when adding this dynamic factor. We hypothesize that this is because most user sessions in our dataset are relatively short (e.g. there are only 20 users with more than 200 events and these events contain a wide range of topics covered).


% \section{Processing OERs: Wikifier and dataset}\label{dataset}

% We set high importance to leveraging cross-modal and cross-lingual capabilities, as these are vital to processing all types of open educational resources in the real-world. We choose text as
% a generic form of raw representation for resources as the majority of modalities (videos, audio, books, web pages, etc.) can be easily converted to text. From text we extract KCs, together with the coverage depth.



% \subsection{Knowledge representation}
% %Deriving knowledge present in educational resources is non-trivial.
% We propose to use an ontology based on Wikipedia to represent KCs.
% %Knowledge state can be decomposed into atomic elements, often referred to as knowledge components
% Specifically, we use {Wikifier}\footnote{\url{www.wikifier.org}}, an entity linking technique that annotates resources with relevant Wikipedia concepts \cite{wikifier}. Two statistics are computed for each Wikipedia topic associated with the resource: (i) {PageRank score} (that represents the authority of a topic within the whole set of topics covered  \cite{pagerank}) and (ii) {cosine similarity} (between the Wikipedia page of the topic and the resource). We use cosine similarity as a proxy for the depth of knowledge covered. %PageRank can be used represents the authority of concepts that are linked with each other \cite{pagerank}. Therefore, we use \textit{PageRank Score} to rank the topics based on authority of concept in relation to the educational resource. We use \textit{Cosine Similarity} to represent the coverage of the respective concept within the resource.
% %Each learnable unit is represented by a set of wiki topics covered.
% %This representation also enhances the transparency and interpretability of the resultant models.
% Each Wikipedia topic is defined as a learnable KC. %Our aim is to infer the knowledge the user has of different wiki topics by analysing engagement.
% We also divide resources into what we call learnable units (fragments). A resource is then composed of different fragments. We believe this is meaningful for two reasons: (i) it enables recommending fine-grained
% resource fragments suited for the learner's learning path, rather than only whole resources, and (ii) because in many cases the learner might not consume the resource entirely (e.g. a book), and we may want to learn exactly from the different fragments consumed.

% \subsection{Dataset} \label{sec:datasets}

% We use data from a popular OER repository to evaluate the performance of the models. The data source consists of users watching video lectures from VideoLectures.Net\footnote{\url{www.videolectures.net}}. The lectures are also accompanied with transcriptions and multiple translations provided by the TransLectures project\footnote{\url{www.translectures.eu}}.
% We use the English transcription of the lecture (or the English translation where the resource is non-English) to annotate the lecture with relevant KCs using Wikifier. We divide the lecture text into multiple fragments of approximately 5,000 characters (equivalent roughly to 5 minutes of lecture).
% Once the fragments are wikified, we rank the topics using a linear combination of pagerank and cosine similarity (further details in the next section) and use the top $k$ ranked topics along with the associated cosine similarity as our feature set.
% %The labels are calculated by computing the Engagement ($E$).
% We define binary engagement $e^t_{\ell,r_i}$ between a learner $\ell$ and a resource $r_i$ as $1$ if the learner watched at least 75\% of the fragment, and -1 otherwise. This is because we hypothesise that the learner must have consumed approximately the whole fragment to learn significantly from it. Note that user view logs are of learners actively accessing videos, i.e. when engagement is negative the leaner has accessed the material but left without spending a significant amount of time on it.


% The source dataset consisted of 25,697 lectures as of February 2018 that were categorised into 21 subjects, e.g.~ Data Science, Computer Science, Arts, Physics, etc.
%  However, as VideoLectures.net has a heavy presence of Computer Science and Data Science lectures, we restricted the dataset to lectures categorised under Computer Science or Data Science categories only. To create the dataset, we extracted the transcripts of the videos and their viewers' view logs. A total of 402,350 view log entries were found between December 8, 2016 and February 17, 2018.
%  These video lectures are long videos that run for 36 minutes on average and hence discuss a large number of KCs in a single lecture. %The fragmentation of lectures leads to lecture fragments that are approx. 5 minutes in length.


% We create three distinct datasets, based on the number of learners and top $k$ topics selected.
% The first two datasets (\texttt{20 learners-10 topics} and \texttt{20 learners-5 topics}) are created using the 20 most active users and 10 and 5 top topics respectively. These $20$ users are associated with 6,613 unique view log entries from 400 different lectures.
% % The dataset with 10 top topics leads to 10,524 unique KCs
% % , as opposed to the top 5 one that leads to 7,948 unique KCs.
% The third dataset (\texttt{All learners-10 topics}) consists of events from all users and is composed of {248,643 view log entries distributed among 18,933 users interacting with 3,884 different lectures}. The 5 highest ranked KCs are used for this dataset. The dataset with 10 topics has 10,524 unique KCs while the other two datasets (20 users and all users) with top 5 ranked topics have 7,948 unique KCs.
% % The dataset consists of 6,084 unique KCs attributed to 3,884 different lectures.



% \section{Experiments} \label{topic:experiments}

% In this section we present the results obtained for the different datasets presented in the previous section. The experiments are set to validate: i) the use of KT against IRT inspired models (and thus the use of Gaussian and Bernoulli variables), ii) the different components that we propose to predict engagement (knowledge and novelty) and iii) the number of top $k$ topics used to characterise a fragment.
% % and the influence of the number of measurements and the sparsity of topics in the performance of the algorithms.


% \paragraph{Validating Wikifier:} Analysing the results Wikifier \cite{wikifier} produced for several lectures we hypothesize that neither pagerank nor cosine similarity alone could be used to reliably rank KCs. Pagerank seemed to be very fine-grained and prone to transcript errors. Cosine similarity, on the other hand, resulted in very general topics, such as 'Science', 'Data' or 'Time'. We firstly experimented with a linear combination of these two and manually validated the superior accuracy obtained. Such a linear combination was also proposed by the authors in \cite{wikifier}, however they did not report improvements. We then proceed to test different weights for the linear combination using our proposed version of KT (Multi skill KT) and the F1-measure. In order to find the linear weights, we executed a grid search where values between [0, 1] were assigned to the weights before training. We concluded that the best results were obtained by weighting pagerank results by 0.4 and cosine by 0.6.
% % (cosine similarity being previously scaled to be in the same scale as pagerank).
% \begin{table*}
%   \caption{Weighted average test performance for accuracy, precision, recall and F1.
% %   with different models.
%   Models labelled with ($\bigtriangleup$) are trained with positive and negative engagement. Models labelled with ($*$) learn multiple skill parameters, one per Wikipedia page.}
%   \label{tab:truelearn_performance}
%   \centering
%   \begin{tabular}{l | rrrr | rrrr | rrrr}
%     \toprule
%      & \multicolumn{4}{c|}{20 learners-5 topics} & \multicolumn{4}{c|}{20 learners-10 topics}  & \multicolumn{4}{c}{All learners-5 topics} \\
%   % \cmidrule(c){2-5} \cmidrule(c){6-9} \cmidrule(c){10-13}\\
%      Algorithm    & Acc. & Prec. & Rec. & F1  & Acc. & Prec. & Rec. & F1   & Acc. & Prec. & Rec. & F1\\
%     \midrule
%     Na\"ive persistence ($\bigtriangleup$) &
%     \textit{.808} & \textbf{.818} & .819 & .819 &
%     .808 & \textbf{.818} & .819 & \textbf{.819} &
%     \textit{.766} & \textbf{.629} & .625 & .625 \\

%     Na\"ive majority ($\bigtriangleup$) &
%     \textbf{.821} & \textit{.775} & .842 & .794 &
%     .821 & \textit{.775} & .842 & .794 &
%     \textbf{.771} & .559 & .633 & .583 \\

%      Vanilla TrueSkill ($\bigtriangleup$) &
%     .739 & .734 & \textit{.982} & \textit{.814} &
%     .794 & .720 & \textit{.955} & .792 &
%     .641 & .608 & \textbf{.837} & \textbf{.679} \\

%     Multi skill KT ($\bigtriangleup$,$*$) &
%     .722 & .748 & .753 & .738 &
%     .714 & .700 & .580 & .631 &
%     .498 & .492 & .188 & .254 \\

%     Multi skill KT ($*$) &
%     .715 & .746 & .776 & .745 &
%     .715 & .701 & .588 & .638 &
%     .497 & .491 & .192 & .256 \\

%      TrueLearn dynamic-depth ($\bigtriangleup$,$*$) &
%      .753 & .732 & .880 & .789 &
%      .790 & .703 & .753 & .726 &
%      .454 & .530 & .431 & .418 \\

%      TrueLearn fixed-depth ($\bigtriangleup$,$*$) &
%      \textit{.808} & .770 & .815 & .790 &
%      \textbf{.841} & .733 & .794 & .761 &
%      .736 & \textit{.610} & .558 & .573 \\

%      TrueLearn fixed-depth ($*$) &
%      .735 & .734 & .\textbf{984} & .813 &
%      .759 & .710 & \textbf{.987} & .783 &
%      .719 & .608 & .686 & .626 \\

%     TrueLearn Novelty ($\bigtriangleup$,$*$) &
%     .793 & .754 & .923 & \textbf{.821} &
%     \textit{.828} & .722 & .875 & .784 &
%     .649 & .603 & \textit{.835} & \textit{.677} \\

%     \bottomrule
%   \end{tabular}
% \end{table*}

% \paragraph{Experimental design and evaluation metrics} Given that we aim to build an online system, we test the different models using a sequential experimental design, where engagement of fragment $t$ is predicted using fragments $1$ to $t-1$. We also use a one hold-out validation approach for hyperparameter tuning where hyperparameters are learned on 70\% of the learners and the model is evaluated on the remaining 30\% with the best hyperparameter combination. Note that we both learn and predict the engagement per fragment.
% Since engagement is binary, predictions for each fragment can be assembled into a confusion matrix, from which we compute well-known binary classification metrics such as accuracy, precision, recall and F1-measure. We average these metrics per learner and weight each learner according to their activity in the system. Note that most learners present an imbalanced setting, where they are mostly engaged or disengaged. Because of this, we do not use Accuracy as the main metric, but rather focus on Recall and F1. %Given the large amount of algorithms tested, we use a hierarchical approach for the experiments, in which we validate a set of hypotheses for a set of more simple algorithms and then apply the conclusions extracted to our final model.
% For all models each user is run separately, except for the original TrueSkill, in which we also need to model the difficulty of content and thus we require all users.
% Regarding initial configurations and hyperparameters, we initialised the initial mean skill of learners to 0 for all reformulations of TrueSkill. We use grid search to find the suitable hyperparameters for the initial variance while keeping $\beta$ constant at 0.5. The search range for the initial variance was [0.1, 2]. For these models, initial hyper parameters are set in the following manner. %First, we compute $\sigma_c^2$, the variance of the cosine similarity values belonging the educational resources. Initial variance of the learner ($\sigma_\ell^2$) is set as $\sigma_\ell^2 = (\sigma_c^2 \times initial\ variance\ factor)^2$. Then we set intial $\beta^2$ as $\beta^2 = (\sigma_\ell * \beta\ factor)^2$
% For the original TrueSkill setting (Vanilla TrueSkill), we set the same hyperparameters used in \cite{trueskill}.
% For the reformulations of KT, we run a hyperparameter grid search for the probability values of the noise factor in the range [0, 0.3].
% We also tested different combinations of $\tau$ ($0.1, 0.05, 0.01$), the hyperparameter controlling the dynamic factor. However, the results did not changed for different settings. This suggests that the dataset might still be relatively small and sparse for this factor to have an impact.
% The algorithms were developed in python, using MapReduce to parallelise the computation per learner. Code will be made available upon acceptance.


% \paragraph{Results}
% We compare the approaches presented in the methodology section to two {na\"ive models, namely persistence and majority}. Persistence assumes that the current state of engagement will prevail, whereas majority uses the majority user engagement to decide on future engagement. We use the dataset with the 20 most active learners to validate as well the number of top $k$ topics, running the same models both for 5 and 10 topics.
% %We first compare the performance of the adapted versions of TrueSkill and KT proposed in Section \ref{sec:baselines}.
% Table \ref{tab:truelearn_performance} shows the results, where highest performance for each dataset is highlighted in \textbf{bold} face and the second best in \textit{italic}.
% %Firstly, we can see that $5$ top topics yields better results, which is why we select $5$ topics for the complete dataset.
% Firstly, we can see that the na\"ive persistence model is very competitive. This is mainly because we are predicting fragments, and persistence has an advantage in this case, as it is usually more probable that if you are engaged, you will stay engaged. However, note that the persistence will perform trivially when recommending new resources. The majority model is very competitive in terms of accuracy, as was expected. However, due to the imbalanced design of the problem we consider F1 to be a more suitable metric.  The algorithms labelled with $\bigtriangleup$ use both positive and negative engagement labels. We run these to validate our hypothesis that no assumption can be made about negative engagement unless using an engagement margin (as shown in \figurename{ \ref{fig:hypotheses}}). As can be seen, both types of models achieve very similar performance in the case of Multi skill KT. In the case of TrueLearn fixed-depth it is better not to use negative engagement. This goes in line with our assumption. We also validate cosine similarity as a proxy for knowledge depth, as  TrueLearn fixed-depth achieves better performance than TrueLearn dynamic-depth, which is run for the whole dataset and infers the latent knowledge depth. The results also show very similar or improved performance when using $5$ topics, which is why we use it for the dataset containing all learners (18,933 users). For F1, TrueLearn-based models beat the baselines in most cases and achieve very promising performance, with TrueLearn Novelty achieving the most competitive performance. We thus validate the necessity of considering novelty, matching the knowledge state of learners and resources. Note that in this case, TrueLearn can make use of negative engagement, given our assumption in \figurename{ \ref{fig:hypotheses}}. Finally, TrueLearn Novelty is seen to achieve similar performance to Vanilla TrueSkill, which considers only one skill for each learner and resource fragment. More specifically, TrueLearn Novelty is better for the 20 most active users and Vanilla TrueSkill for the complete dataset (which includes users with very few events). We believe this might be because: i) Vanilla TrueSkill can be thought as addressing how engaging resources are by only modelling one skill, rather than learner's knowledge and ii) the sparsity of the representation in TrueLearn might play a role in its low performance for users with few sessions. By analysing the results closely, we validated that Vanilla TrueSkill has better performance at the beginning of the user session, when very few user data has been collected. We thus propose to use Vanilla TrueSkill to solve the commonly found cold-start problem. However, when more data is given, TrueLearn achieves better performance. To validate this, we compared the mean F1 performance for the test set of the 20 most active users at two different stages: i) the average performance over the first 100 events of a user session and ii) the average performance over the last 100 events of a user session. For i), Vanilla TrueSkill achieved 0.855 whereas TrueLearn Novelty 0.853, Vanilla TrueSkill showing slightly better performance at the beginning of the user session. For ii), Vanilla TrueSkill achieved 0.783 whereas TrueLearn Novelty 0.796, i.e. TrueLearn obtained similar or better performance while providing interpretable information about the knowledge state of the learner and being a more scalable solution that is run per learner.

%Mean F1 score on test set users of the 20 most active users. Vanilla TrueSkill first 100 events : 0.854869, last 100 events  0.782609. TrueLearn first 100 events: 0.853478, last 100 events: 0.796275



%\paragraph{Second experiment: Novelty}

%After analysing the baselines for the dataset with the 20 most active learners, we evaluate now the performance using the entire dataset . The results can be seen in Table \ref{tab:truelearn_performance}.


% \begin{table*}
%   \caption{Baseline mean test performance for the 20 most active learners and baseline methods. Models labelled with ($\bigtriangleup$) are trained both with positive and negative engagement labels. }
%   \label{tab:baseline_performance}
%   \centering
%   \begin{tabular}{l rrrr rrrr}
%     \toprule
%      & \multicolumn{4}{c}{20 learners-5 topics} & \multicolumn{4}{c}{20 learners-10 topics}
%                      \\
%     \cmidrule(r){2-5} \cmidrule(r){6-9}\\
%      Algorithm    & Acc. & Prec. & Rec. & F1  & Acc. & Prec. & Rec. & F1  \\
%     \midrule
%     Na\"ive persistence & \textbf{0.834} & \textbf{0.755} & \textit{0.755} & \textbf{0.755} & \textbf{0.834} & \textbf{0.755} & \textit{0.755} & \textbf{0.755} \\
%     Na\"ive majority & \textit{0.823} & 0.617 & 0.681 & 0.637 & \textit{0.823} & 0.617 & 0.681 & 0.637 \\
%     Vanilla TrueSkill ($\bigtriangleup$) & 0.695 & 0.641 & 0.726 & 0.669 & 0.703 & 0.638 & 0.698 & 0.658 \\

%     Multi skill KT ($\bigtriangleup$) &0.709 & 0.659 & 0.619 & 0.629 & 0.684 & 0.642 & 0.542 & 0.573 \\
%     Multi skill KT & 0.703 & 0.654 & 0.642 & 0.636 & 0.682 & 0.640 & 0.553 & 0.579 \\
%     Fixed depth TrueSkill ($\bigtriangleup$) & 0.808 & \textit{0.704} & 0.660 & 0.673 & 0.818 & \textit{0.728} & 0.669 & 0.679 \\
%     Fixed depth TrueSkill & 0.720 & 0.639 & \textbf{0.858} &\textit{0.705} & 0.709 & 0.634 & \textbf{0.887} & \textit{0.707} \\
%     TrueLearn ($\bigtriangleup$) & XX & XX & \textbf{XX} &\textit{XX} & XX & XX & \textbf{XX} & \textit{XX} \\
%     \bottomrule
%   \end{tabular}
% \end{table*}

% \begin{table*}
%   \caption{Baseline mean test performance for the 20 most active learners and baseline methods. Models labelled with ($\bigtriangleup$) are trained both with positive and negative engagement labels. }
%   \label{tab:baseline_performance}
%   \centering
%   \begin{tabular}{l rrrr rrrr rrrr}
%     \toprule
%      & \multicolumn{4}{c}{20 learners-5 topics} & \multicolumn{4}{c}{20 learners-10 topics}  & \multicolumn{4}{c}{All learners-5 topics} \\
%     \cmidrule(r){2-5} \cmidrule(r){6-9} \cmidrule(r){10-13}\\
%      Algorithm    & Acc. & Prec. & Rec. & F1  & Acc. & Prec. & Rec. & F1   & Acc. & Prec. & Rec. & F1\\
%     \midrule
%     Na\"ive persistence & \textbf{0.834} & \textbf{0.755} & \textit{0.755} & \textbf{0.755} & \textbf{0.834} & \textbf{0.755} & \textit{0.755} & \textbf{0.755} & \textit{0.769} & \textbf{0.631} & 0.629 & 0.629\\
%     Na\"ive majority & \textit{0.823} & 0.617 & 0.681 & 0.637 & \textit{0.823} & 0.617 & 0.681 & 0.637
%      & \textbf{0.774} & 0.561 & \textit{0.640} & \textit{0.640}\\
%     Vanilla TrueSkill ($\bigtriangleup$) & 0.695 & 0.641 & 0.726 & 0.669 & 0.703 & 0.638 & 0.698 & 0.658
%     & 0.444 & 0.522 & 0.406 & 0.400 \\
%     Multi skill KT ($\bigtriangleup$) &0.709 & 0.659 & 0.619 & 0.629 & 0.684 & 0.642 & 0.542 & 0.573
%      & 0.501 & 0.491 & 0.194 & 0.257 \\
%     Multi skill KT & 0.703 & 0.654 & 0.642 & 0.636 & 0.682 & 0.640 & 0.553 & 0.579
%     & 0.500 & 0.490 & 0.197 & 0.259\\
%     Fixed depth TrueSkill ($\bigtriangleup$) & 0.808 & \textit{0.704} & 0.660 & 0.673 & 0.818 & \textit{0.728} & 0.669 & 0.679 & 0.657 & 0.581 & 0.401 & 0.459 \\
%     Fixed depth TrueSkill & 0.720 & 0.639 & \textbf{0.858} &\textit{0.705} & 0.709 & 0.634 & \textbf{0.887} & \textit{0.707} & 0.656 & 0.591 & 0.498 & 0.518 \\
%     TrueLearn ($\bigtriangleup$) & XX & XX & \textbf{XX} &\textit{XX} & XX & XX & \textbf{XX} & \textit{XX} & 0.672 & \textit{0.608} & \textbf{0.821} & \textbf{0.677}  \\
%     \bottomrule
%   \end{tabular}
% \end{table*}




% \begin{table}
%   \caption{Mean test performance with the full dataset including all learners and models. Models labelled with ($\bigtriangleup$) are trained both with positive and negative engagement labels.}
%   \label{tab:truelearn_performance}
%   \centering
%   \begin{tabular}{l rrrr}
%     \toprule
%     Algorithm & Acc. & Prec. & Rec. & F1 \\
%     \midrule
%     Na\"ive persistence & \textit{0.769} & \textbf{0.631} & 0.629 & 0.629 \\
%     Na\"ive majority & \textbf{0.774} & 0.561 & \textit{0.640} & \textit{0.640} \\
%     Vanilla TrueSkill ($\bigtriangleup$) & 0.444 & 0.522 & 0.406 & 0.400 \\

%     Multi skill KT ($\bigtriangleup$) & 0.501 & 0.491 & 0.194 & 0.257 \\
%     Multi skill KT & 0.500 & 0.490 & 0.197 & 0.259 \\
%     Fixed depth TrueSkill ($\bigtriangleup$) & 0.657 & 0.581 & 0.401 & 0.459 \\
%     Fixed depth TrueSkill & 0.656 & 0.591 & 0.498 & 0.518 \\
%     TrueLearn ($\bigtriangleup$) & 0.672 & \textit{0.608} & \textbf{0.821} & \textbf{0.677} \\
%     \bottomrule
%   \end{tabular}
% \end{table}



% \begin{table}
%   \caption{Mean test performance with the full dataset including all learners and models. Models labelled with ($\bigtriangleup$) are trained both with positive and negative engagement labels.}
%   \label{tab:truelearn_performance}
%   \centering
%   \begin{tabular}{l rrrr}
%     \toprule
%     Algorithm & Acc. & Prec. & Rec. & F1 \\
%     \midrule
%     Na\"ive persistence & \textit{0.769} & \textbf{0.631} & 0.629 & 0.629 \\
%     Na\"ive majority & \textbf{0.774} & 0.561 & \textit{0.640} & \textit{0.640} \\
%     Vanilla TrueSkill ($\bigtriangleup$) & 0.444 & 0.522 & 0.406 & 0.400 \\

%     Multi skill KT ($\bigtriangleup$) & 0.501 & 0.491 & 0.194 & 0.257 \\
%     Multi skill KT & 0.500 & 0.490 & 0.197 & 0.259 \\
%     Fixed depth TrueSkill ($\bigtriangleup$) & 0.657 & 0.581 & 0.401 & 0.459 \\
%     Fixed depth TrueSkill & 0.656 & 0.591 & 0.498 & 0.518 \\
%     TrueLearn ($\bigtriangleup$) & 0.672 & \textit{0.608} & \textbf{0.821} & \textbf{0.677} \\
%     \bottomrule
%   \end{tabular}
% \end{table}

% \begin{figure}[!tbp]
% %   \centering
% %   \begin{minipage}[b]{0.495\columnwidth}
% %     \includegraphics[width=\textwidth]{AuthorKit20/LaTeX/kt.pdf}
% %   \end{minipage}
% %   \hfill
% %   \begin{minipage}[b]{0.495\columnwidth}
% %     \includegraphics[width=\textwidth]{AuthorKit20/LaTeX/truelearn.pdf}
% %   \end{minipage}
% %   \begin{minipage}[b]{0.495\columnwidth}
% %     \includegraphics[width=\textwidth]{AuthorKit20/LaTeX/kt.pdf}
% %   \end{minipage}
% %   \hfill
% %   \begin{minipage}[b]{0.495\columnwidth}
% %     \includegraphics[width=\textwidth]{AuthorKit20/LaTeX/truelearn.pdf}
% %   \end{minipage}
%  \centering
%  \includegraphics[width=\columnwidth]{AuthorKit20/LaTeX/KTvsTL.pdf}
%  \caption{F1 score of each learner with their associated topic sparsity (x-axis) and number of events (y-axis). Each data point represents a learner. Colours represent F1-Score.}
% % \caption{Representation of average F1 for users with different associated topic sparsity and number of events. Each data point represents a learner. Colours represent average F1. }
%  \label{tab:sparsity}
% \end{figure}


% % \paragraph{Video evaluation}

% % We now analyse results for complete videos prediction, using a selection of the methods in Table... All the models were developed to predict the probability of engagement with a partition of the video. In order to predict engagement with whole videos we test two different hypotheses (independent and dependent engagement with partitions).

% \figurename{ \ref{tab:sparsity}} compares how F1 score changes for individual learners with respect to number of events and topic sparsity. It is evident that KT model struggles with learners that have high topic sparsity (with F1 score of 0 for users with topic sparsity $>$ 4). However, this is not the case for TrueLearn (similar results are obtained for other TrueLearn versions).

% % \figurename{ \ref{tab:sparsity}} shows a representation of average F1 against topic sparsity and number of events, where each data point represents a learner. The performance of KT is influenced by topic sparsity. However, this is not the case for TrueLearn (similar results are obtained for other TrueLearn versions).

% \paragraph{Discussion on desired features}
% Regarding the desired features outlined in the introduction, we have proposed i) a transparent learner representation, that represents knowledge as a human interpretable multi-dimensional Gaussian random variable in Wikipedia topic space, key to promote self-reflection in learners \cite{Bull2016}; ii) a scalable online model that is run per user; iii) the use of an automatic content analytics toolbox that allows for cross-modality and cross-linguality features and iv) a learning strategy to make use of implicit signals in the form of learner's engagement for video lectures. In summary, TrueLearn Novelty presents superior results to the rest of models, beating Vanilla TrueSkill in the long run while maintaining a richer learner representation and being more scalable.


% %\textcolor{red}{I think we need to strongly argue the following facts to make sure that the reader is convinced that this is not a sub optimal result. (i) TrueLearn novelty is the most Superior result in all the algorithms that model individual Wikipedia topics. (ii) Modelling individual Wiki Topics is important to build a humanly interpretable learner model that can trigger self-reflection \cite{Bull2016}. TrueLearn Novely beats all the topic modelling algorithms KT, TrueLearn dynamic and fixed depth. (iii) The naive baselines are competitive in predicting the outcome GIVEN next event. But they cannot be used to rank multiple items. (iv) Vanilla TrueSkill is better in the initial stage due to several reasons:  1) there is only one Gaussian being learned and it gets updated more frequently (from every event). 2) the TrueSkill scheme updates the content engageability as well making two updates in one event opposed to TrueLearn fixed depth and Novelty. 3) As the lectures are all about CS, the topics are highly correlated. Hence, in this specific scenario, learning one topic parameter is sufficient for predicting engagement. This may not hold if the lectures came from highly diverse subject areas such as Physics, Phylosopy etc. 4) TrueSkill also learns the context-agnostic engageability of materials, whereas the truelearn algorithms attempt to estimate background knowledge. (v) But TrueLearn Novelty achieves superior performance in the long run while maintaining a richer, more actionable learner representation.}


% %\textcolor{orange}{Transparency, we can argue that the representation is a multi-dimentional Gaussian in Wikipedia topic space, which is highly human interpretable. And experiment: We can try to compare the highest valued Gaussians with the Word histograms of the user or sth .., About scalability, we can report that it took this much time to run on a 12-core machine with these resources for 200K users, And the code is massively pararalisable. Which also makes running it on already existent learning platforms highly feasible.}

% \section{Conclusions}

% This work sets the foundations towards building a lifelong learning recommendation system for education. We present three different approaches, inspired by Item Response Theory and Knowledge Tracing. Our proposed model (TrueLearn) introduces the concept of novelty as a function of learner engagement.
% % {Novelty} of the recommended learning material is particularly important in the context of recommendation of OERs.
% In this framework, recommendation algorithms need to focus on making recommendations for which i) the learner has enough background knowledge so they are able to understand and learn from the recommended material, and ii) the material has enough novelty that would help the learner to improve their knowledge about the subject.
% Our results using a very large dataset show the potential of such an approach. TrueLearn also embeds scalability, transparency and data efficiency in the core of its design showing clear promise towards building an effective lifelong learning recommendation system.
% % The fact that the design of TrueLearn also has features such as scalability, transparency and data efficiency shows clear promise towards building a light online algorithm that can leverage lifelong learning at scale.
% While there has been vast amount of work in context of recommendation, recommendation in education has unique challenges, due to which most existing recommendation algorithms tend not to be directly applicable.
% Because of this, the list of future work remains extensive. Concerning the model:
% i) We believe that the use of a hierarchical approach, that takes into account Wikipedia link graph and category tree (i.e. dependency between KCs), could significantly improve the results by alleviating the sparsity of the KCs selected by Wikifier. This might also allow for more refined definitions of novelty. ii) The model could also be extended to consider explicit learner's feedback of the type "too difficult" or "too easy". iii) The model could be combined with a form of collaborative filtering to tackle learners with limited number of sessions.
% Concerning the data and the validation:
% i) We would like to validate our strategy for processing resources in a cross-modal and cross-lingual environment.
% ii) We plan to set a user study to validate the recommendations of the system and design a visualisation of the learner's knowledge.

Distinctio quo dolorem quaerat perspiciatis fuga nihil similique ipsa, qui voluptas similique sint quam laboriosam unde doloremque eos odio, quibusdam quae atque veniam cum illo asperiores consectetur dolorem itaque modi, illo rem nostrum.Perferendis ea ipsam repellat vero consequatur eum culpa nemo
\bibliography{aaai}
\bibliographystyle{aaai}
\end{document}


% \noindent Congratulations on having a paper selected for inclusion in an AAAI Press proceedings or technical report! This document details the requirements necessary to get your accepted paper published using PDF\LaTeX{}. If you are using Microsoft Word, instructions are provided in a different document. AAAI Press does not support any other formatting software.

% The instructions herein are provided as a general guide for experienced \LaTeX{} users. If you do not know how to use \LaTeX{}, please obtain assistance locally. AAAI cannot provide you with support and the accompanying style files are \textbf{not} guaranteed to work. If the results you obtain are not in accordance with the specifications you received, you must correct your source file to achieve the correct result.

% These instructions are generic. Consequently, they do not include specific dates, page charges, and so forth. Please consult your specific written conference instructions for details regarding your submission. Please review the entire document for specific instructions that might apply to your particular situation. All authors must comply with the following:

% \begin{itemize}
% \item You must use the 2020 AAAI Press \LaTeX{} style file and the aaai.bst bibliography style file, which are located in the 2020 AAAI Author Kit (aaai20.sty and aaai.bst).
% \item You must complete, sign, and return by the deadline the AAAI copyright form (unless directed by AAAI Press to use the AAAI Distribution License instead).
% \item You must read and format your paper source and PDF according to the formatting instructions for authors.
% \item You must submit your electronic files and abstract using our electronic submission form \textbf{on time.}
% \item You must pay any required page or formatting charges to AAAI Press so that they are received by the deadline.
% \item You must check your paper before submitting it, ensuring that it compiles without error, and complies with the guidelines found in the AAAI Author Kit.
% \end{itemize}

% \section{Copyright}
% All papers submitted for publication by AAAI Press must be accompanied by a valid signed copyright form. There are no exceptions to this requirement. You must send us the original version of this form. However, to meet the deadline, you may fax (1-650-321-4457) or scan and e-mail the form (pubforms20@aaai.org) to AAAI by the submission deadline, and then mail the original via postal mail to the AAAI office. If you fail to send in a signed copyright or permission form, we will be unable to publish your paper. There are \textbf{no exceptions} to this policy.You will find PDF versions of the AAAI copyright and permission to distribute forms in the AAAI AuthorKit.

% \section{Formatting Requirements in Brief}
% We need source and PDF files that can be used in a variety of ways and can be output on a variety of devices. The design and appearance of the paper is strictly governed by the aaai style file (aaai20.sty).
% \textbf{You must not make any changes to the aaai style file, nor use any commands, packages, style files, or macros within your own paper that alter that design, including, but not limited to spacing, floats, margins, fonts, font size, and appearance.} AAAI imposes requirements on your source and PDF files that must be followed. Most of these requirements are based on our efforts to standardize conference manuscript properties and layout. All papers submitted to AAAI for publication will be recompiled for standardization purposes. Consequently, every paper submission must comply with the following requirements:

% \begin{quote}
% \begin{itemize}
% \item Your .tex file must compile in PDF\LaTeX{} --- ( you may not include .ps or .eps figure files.)
% \item All fonts must be embedded in the PDF file --- including includes your figures.
% \item Modifications to the style file, whether directly or via commands in your document may not ever be made, most especially when made in an effort to avoid extra page charges or make your paper fit in a specific number of pages.
% \item No type 3 fonts may be used (even in illustrations).
% \item You may not alter the spacing above and below captions, figures, headings, and subheadings.
% \item You may not alter the font sizes of text elements, footnotes, heading elements, captions, or title information (for references and tables and mathematics, please see the the limited exceptions provided herein).
% \item You may not alter the line spacing of text.
% \item Your title must follow Title Case capitalization rules (not sentence case).
% \item Your .tex file must include completed metadata to pass-through to the PDF (see PDFINFO below)
% \item \LaTeX{} documents must use the Times or Nimbus font package (you may not use Computer Modern for the text of your paper).
% \item No \LaTeX{} 209 documents may be used or submitted.
% \item Your source must not require use of fonts for non-Roman alphabets within the text itself. If your paper includes symbols in other languages (such as, but not limited to, Arabic, Chinese, Hebrew, Japanese, Thai, Russian and other Cyrillic languages), you must restrict their use to bit-mapped figures. Fonts that require non-English language support (CID and Identity-H) must be converted to outlines or 300 dpi bitmap or removed from the document (even if they are in a graphics file embedded in the document).
% \item Two-column format in AAAI style is required for all papers.
% \item The paper size for final submission must be US letter without exception.
% \item The source file must exactly match the PDF.
% \item The document margins may not be exceeded (no overfull boxes).
% \item The number of pages and the file size must be as specified for your event.
% \item No document may be password protected.
% \item Neither the PDFs nor the source may contain any embedded links or bookmarks (no hyperref or navigator packages).
% \item Your source and PDF must not have any page numbers, footers, or headers (no pagestyle commands).
% \item Your PDF must be compatible with Acrobat 5 or higher.
% \item Your \LaTeX{} source file (excluding references) must consist of a \textbf{single} file (use of the ``input" command is not allowed.
% \item Your graphics must be sized appropriately outside of \LaTeX{} (do not use the ``clip" or ``trim'' command) .
% \end{itemize}
% \end{quote}

% If you do not follow these requirements, you will be required to correct the deficiencies and resubmit the paper. A resubmission fee will apply.

% \section{What Files to Submit}
% You must submit the following items to ensure that your paper is published:
% \begin{itemize}
% \item A fully-compliant PDF file that includes PDF metadata.
% \item Your \LaTeX{} source file submitted as a \textbf{single} .tex file (do not use the ``input" command to include sections of your paper --- every section must be in the single source file). (The only allowable exception is .bib file, which should be included separately).
% \item The bibliography (.bib) file(s).
% \item Your source must compile on our system, which includes only standard \LaTeX{} 2018-2019 TeXLive support files.
% \item Only the graphics files used in compiling paper.
% \item The \LaTeX{}-generated files (e.g. .aux,  .bbl file, PDF, etc.).
% \end{itemize}

% Your \LaTeX{} source will be reviewed and recompiled on our system (if it does not compile, you will be required to resubmit, which will incur fees). \textbf{Do not submit your source in multiple text files.} Your single \LaTeX{} source file must include all your text, your bibliography (formatted using aaai.bst), and any custom macros.

% Your files should work without any supporting files (other than the program itself) on any computer with a standard \LaTeX{} distribution.

% \textbf{Do not send files that are not actually used in the paper.} We don't want you to send us any files not needed for compiling your paper, including, for example, this instructions file, unused graphics files, style files, additional material sent for the purpose of the paper review, and so forth.

% \textbf{Do not send supporting files that are not actually used in the paper.} We don't want you to send us any files not needed for compiling your paper, including, for example, this instructions file, unused graphics files, style files, additional material sent for the purpose of the paper review, and so forth.

% \textbf{Obsolete style files.} The commands for some common packages (such as some used for algorithms), may have changed. Please be certain that you are not compiling your paper using old or obsolete style files.
% \textbf{Final Archive.} Place your PDF and source files in a single archive which should be compressed using .zip. The final file size may not exceed 10 MB.
% Name your source file with the last (family) name of the first author, even if that is not you.


% \section{Using \LaTeX{} to Format Your Paper}

% The latest version of the AAAI style file is available on AAAI's website. Download this file and place it in the \TeX\ search path. Placing it in the same directory as the paper should also work. You must download the latest version of the complete AAAI Author Kit so that you will have the latest instruction set and style file.

% \subsection{Document Preamble}

% In the \LaTeX{} source for your paper, you \textbf{must} place the following lines as shown in the example in this subsection. This command set-up is for three authors. Add or subtract author and address lines as necessary, and uncomment the portions that apply to you. In most instances, this is all you need to do to format your paper in the Times font. The helvet package will cause Helvetica to be used for sans serif. These files are part of the PSNFSS2e package, which is freely available from many Internet sites (and is often part of a standard installation).

% Leave the setcounter for section number depth commented out and set at 0 unless you want to add section numbers to your paper. If you do add section numbers, you must uncomment this line and change the number to 1 (for section numbers), or 2 (for section and subsection numbers). The style file will not work properly with numbering of subsubsections, so do not use a number higher than 2.

% If (and only if) your author title information will not fit within the specified height allowed, put \textbackslash setlength \textbackslash titlebox{2.5in} in your preamble. Increase the height until the height error disappears from your log. You may not use the \textbackslash setlength command elsewhere in your paper, and it may not be used to reduce the height of the author-title box.

% \subsubsection{The Following Must Appear in Your Preamble}
% \begin{quote}
% \begin{scriptsize}\begin{verbatim}
% \documentclass[letterpaper]{article}
% \usepackage{aaai20}
% \usepackage{times}
% \usepackage{helvet}
% \usepackage{courier}
% \usepackage[hyphens]{url}
% \usepackage{graphicx}
% \urlstyle{rm}
% \def\UrlFont{\rm}
% \usepackage{graphicx}
% \frenchspacing
% \setlength{\pdfpagewidth}{8.5in}
% \setlength{\pdfpageheight}{11in}
% % Add additional packages here, but check
% % the list of disallowed packages
% % (including, but not limited to
% % authblk, caption, CJK, float, fullpage, geometry,
% % hyperref, layout, nameref, natbib, savetrees,
% % setspace, titlesec, tocbibind, ulem)
% % and illegal commands provided in the
% % common formatting errors document
% % included in the  Author Kit before doing so.
% %
% % PDFINFO
% % You are required to complete the following
% % for pass-through to the PDF.
% % No LaTeX commands of any kind may be
% % entered. The parentheses and spaces
% % are an integral part of the
% % pdfinfo script and must not be removed.
% %
% %
% % Section Numbers
% % Uncomment if you want to use section numbers
% % and change the 0 to a 1 or 2
% % \setcounter{secnumdepth}{0}

% % Title and Author Information Must Immediately Follow
% % the pdfinfo within the preamble
% %
% \title{Title}\\
% \author\{Author 1 \ and Author 2\\
% Address line\\
% Address line\\
% \ And\\
% Author 3\\
% Address line\\
% Address line
% }\\
% \end{verbatim}\end{scriptsize}
% \end{quote}

% \subsection{Preparing Your Paper}

% After the preamble above, you should prepare your paper as follows:
% \begin{quote}
% \begin{scriptsize}\begin{verbatim}
% %
% \begin{document}
% \maketitle
% \begin{abstract}
% %...
% \end{abstract}\end{verbatim}\end{scriptsize}
% \end{quote}

% \subsubsection{The Following Must Conclude Your Document}
% \begin{quote}
% \begin{scriptsize}\begin{verbatim}
% % References and End of Paper
% % These lines must be placed at the end of your paper
% \bibliography{Bibliography-File}
% \bibliographystyle{aaai}
% \end{document}
% \end{verbatim}\end{scriptsize}
% \end{quote}

% \subsection{Inserting Document Metadata with \LaTeX{}}
% PDF files contain document summary information that enables us to create an Acrobat index (pdx) file, and also allows search engines to locate and present your paper more accurately. \textit{Document metadata for author and title are REQUIRED.} You may not apply any script or macro to implementation of the title, author, and metadata information in your paper.

% \textit{Important:} Do not include \textit{any} \LaTeX{} code or nonascii characters (including accented characters) in the metadata. The data in the metadata must be completely plain ascii. It may not include slashes, accents, linebreaks, unicode, or any \LaTeX{} commands. Type the title exactly as it appears on the paper (minus all formatting). Input the author names in the order in which they appear on the paper (minus all accents), separating each author by a comma. You may also include keywords in the optional Keywords field.

% \begin{quote}
% \begin{scriptsize}\begin{verbatim}
% \begin{document}\\
% \maketitle\\
% ...\\
% \bibliography{Bibliography-File}\\
% \bibliographystyle{aaai}\\
% \end{document}\\
% \end{verbatim}\end{scriptsize}
% \end{quote}

% \subsection{Commands and Packages That May Not Be Used}
% \begin{table*}[t]
% \centering
% \caption{Commands that must not be used.}\smallskip
% %\resizebox{0.95\textwidth}{!}{ % If your table exceeds the column or page width, use this command to reduce it slightly
% \begin{tabular}{l|l|l|l}
% \textbackslash abovecaption &
% \textbackslash abovedisplay &
% \textbackslash addevensidemargin &
% \textbackslash addsidemargin \\
% \textbackslash addtolength &
% \textbackslash baselinestretch &
% \textbackslash belowcaption &
% \textbackslash belowdisplay \\
% \textbackslash break &
% \textbackslash clearpage &
% \textbackslash clip &
% \textbackslash columnsep \\
% \textbackslash float &
% \textbackslash input &
% \textbackslash input &
% \textbackslash linespread \\
% \textbackslash newpage &
% \textbackslash pagebreak &
% \textbackslash renewcommand &
% \textbackslash setlength \\
% \textbackslash text height &
% \textbackslash tiny &
% \textbackslash top margin &
% \textbackslash trim \\
% \textbackslash vskip\{- &
% \textbackslash vspace\{- \\
% \end{tabular}
% %}
% \label{table1}
% \end{table*}

% \begin{table}[t]
% \caption{LaTeX style packages that must not be used.}\smallskip
% \centering
% \resizebox{.95\columnwidth}{!}{
% \smallskip\begin{tabular}{l|l|l|l}
% authblk & babel & caption & cjk\\
% dvips & epsf & epsfig & euler\\
% float & fullpage & geometry & graphics\\
% hyperref & layout & linespread & lmodern\\
% maltepaper & natbib & navigator & pdfcomment\\
% psfig & pstricks & t1enc & titlesec\\
% tocbind & ulem\\
% \end{tabular}
% }
% \label{table2}
% \end{table}

% There are a number of packages, commands, scripts, and macros that are incompatable with aaai20.sty. The common ones are listed in tables \ref{table1} and \ref{table2}. Generally, if a command, package, script, or macro alters floats, margins, fonts, sizing, linespacing, or the presentation of the references and citations, it is unacceptable. Note that negative vskip and vspace may not be used except in certain rare occurances, and may never be used around tables, figures, captions, sections, subsections, subsections, or references.


% \subsection{Page Breaks}
% For your final camera ready copy, you must not use any page break commands. References must flow directly after the text without breaks. Note that some conferences require references to be on a separate page during the review process. AAAI Press, however, does not require this condition for the final paper.


% \subsection{Paper Size, Margins, and Column Width}
% Papers must be formatted to print in two-column format on 8.5 x 11 inch US letter-sized paper. The margins must be exactly as follows:
% \begin{itemize}
% \item Top margin: .75 inches
% \item Left margin: .75 inches
% \item Right margin: .75 inches
% \item Bottom margin: 1.25 inches
% \end{itemize}


% The default paper size in most installations of \LaTeX{} is A4. However, because we require that your electronic paper be formatted in US letter size, the preamble we have provided includes commands that alter the default to US letter size. Please note that using any other package to alter page size (such as, but not limited to the Geometry package) will result in your final paper being returned to you for correction and payment of a resubmission fee.


% \subsubsection{Column Width and Margins.}
% To ensure maximum readability, your paper must include two columns. Each column should be 3.3 inches wide (slightly more than 3.25 inches), with a .375 inch (.952 cm) gutter of white space between the two columns. The aaai20.sty file will automatically create these columns for you.

% \subsection{Overlength Papers}
% If your paper is too long, turn on \textbackslash frenchspacing, which will reduce the space after periods. Next, shrink the size of your graphics. Use \textbackslash centering instead of \textbackslash begin\{center\} in your figure environment. For mathematical environments, you may reduce fontsize {\bf but not below 6.5 point}. You may also alter the size of your bibliography by inserting \textbackslash fontsize\{9.5pt\}\{10.5pt\} \textbackslash selectfont
% right before the bibliography (the minimum size is \textbackslash fontsize\{9.0pt\}\{10.0pt\}.

% Commands that alter page layout are forbidden. These include \textbackslash columnsep, \textbackslash topmargin, \textbackslash topskip, \textbackslash textheight, \textbackslash textwidth, \textbackslash oddsidemargin, and \textbackslash evensizemargin (this list is not exhaustive). If you alter page layout, you will be required to pay the page fee \textit{plus} a reformatting fee. Other commands that are questionable and may cause your paper to be rejected include \textbackslash parindent, and \textbackslash parskip. Commands that alter the space between sections are forbidden. The title sec package is not allowed. Regardless of the above, if your paper is obviously ``squeezed" it is not going to to be accepted. Options for reducing the length of a paper include reducing the size of your graphics, cutting text, or paying the extra page charge (if it is offered).

% \subsection{Figures}
% Your paper must compile in PDF\LaTeX{}. Consequently, all your figures must be .jpg, .png, or .pdf. You may not use the .gif (the resolution is too low), .ps, or .eps file format for your figures.

% When you include your figures, you must crop them \textbf{outside} of \LaTeX{}. The command \textbackslash includegraphics*[clip=true, viewport 0 0 10 10]{...} might result in a PDF that looks great, but the image is \textbf{not really cropped.} The full image can reappear (and obscure whatever it is overlapping) when page numbers are applied or color space is standardized. Figures \ref{fig1}, and \ref{fig2} display some unwanted results that often occur.

% Do not use minipage to group figures. Additionally, the font and size of figure captions must be 10 point roman. Do not make them smaller, bold, or italic. (Individual words may be italicized if the context requires differentiation.)

% \begin{figure}[t]
% \centering
% \includegraphics[width=0.9\columnwidth]{figure1} % Reduce the figure size so that it is slightly narrower than the column. Don't use precise values for figure width.This setup will avoid overfull boxes.
% \caption{Using the trim and clip commands produces fragile layers that can result in disasters (like this one from an actual paper) when the color space is corrected or the PDF combined with others for the final proceedings. Crop your figures properly in a graphics program -- not in LaTeX}
% \label{fig1}
% \end{figure}

% \begin{figure*}[t]
% \centering
% \includegraphics[width=0.8\textwidth]{figure2} % Reduce the figure size so that it is slightly narrower than the column.
% \caption{Adjusting the bounding box instead of actually removing the unwanted data resulted multiple layers in this paper. It also needlessly increased the PDF size. In this case, the size of the unwanted layer doubled the paper's size, and produced the following surprising results in final production. Crop your figures properly in a graphics program. Don't just alter the bounding box.}
% \label{fig2}
% \end{figure*}

% % Using the \centering command instead of \begin{center} ... \end{center} will save space
% % Positioning your figure at the top of the page will save space and make the paper more readable
% % Using 0.95\columnwidth in conjunction with the

% \subsection{Type Font and Size}
% Your paper must be formatted in Times Roman or Nimbus. We will not accept papers formatted using Computer Modern or Palatino or some other font as the text or heading typeface. Sans serif, when used, should be Courier. Use Symbol or Lucida or Computer Modern for \textit{mathematics only. }

% Do not use type 3 fonts for any portion of your paper, including graphics. Type 3 bitmapped fonts are designed for fixed resolution printers. Most print at 300 dpi even if the printer resolution is 1200 dpi or higher. They also often cause high resolution imagesetter devices and our PDF indexing software to crash. Consequently, AAAI will not accept electronic files containing obsolete type 3 fonts. Files containing those fonts (even in graphics) will be rejected.

% Fortunately, there are effective workarounds that will prevent your file from embedding type 3 bitmapped fonts. The easiest workaround is to use the required times, helvet, and courier packages with \LaTeX{}2e. (Note that papers formatted in this way will still use Computer Modern for the mathematics. To make the math look good, you'll either have to use Symbol or Lucida, or you will need to install type 1 Computer Modern fonts --- for more on these fonts, see the section ``Obtaining Type 1 Computer Modern.")

% If you are unsure if your paper contains type 3 fonts, view the PDF in Acrobat Reader. The Properties/Fonts window will display the font name, font type, and encoding properties of all the fonts in the document. If you are unsure if your graphics contain type 3 fonts (and they are PostScript or encapsulated PostScript documents), create PDF versions of them, and consult the properties window in Acrobat Reader.

% The default size for your type must be ten-point with twelve-point leading (line spacing). Start all pages (except the first) directly under the top margin. (See the next section for instructions on formatting the title page.) Indent ten points when beginning a new paragraph, unless the paragraph begins directly below a heading or subheading.


% \subsubsection{Obtaining Type 1 Computer Modern for \LaTeX{}.}

% If you use Computer Modern for the mathematics in your paper (you cannot use it for the text) you may need to download type 1 Computer fonts. They are available without charge from the American Mathematical Society:
% http://www.ams.org/tex/type1-fonts.html.

% \subsubsection{Nonroman Fonts}
% If your paper includes symbols in other languages (such as, but not limited to, Arabic, Chinese, Hebrew, Japanese, Thai, Russian and other Cyrillic languages), you must restrict their use to bit-mapped figures.

% \subsection{Title and Authors}
% Your title must appear in mixed case (nouns, pronouns, and verbs are capitalized) near the top of the first page, centered over both columns in sixteen-point bold type (twenty-four point leading). This style is called ``mixed case," which means that means all verbs (including short verbs like be, is, using,and go), nouns, adverbs, adjectives, and pronouns should be capitalized, (including both words in hyphenated terms), while articles, conjunctions, and prepositions are lower case unless they directly follow a colon or long dash. Author's names should appear below the title of the paper, centered in twelve-point type (with fifteen point leading), along with affiliation(s) and complete address(es) (including electronic mail address if available) in nine-point roman type (the twelve point leading). (If the title is long, or you have many authors, you may reduce the specified point sizes by up to two points.) You should begin the two-column format when you come to the abstract.

% \subsubsection{Formatting Author Information}
% Author information can be set in a number of different styles, depending on the number of authors and the number of affiliations you need to display. In formatting your author information, however, you may not use a table nor may you employ the \textbackslash authorblk.sty package. For several authors from the same institution, please just separate with commas:

% \begin{quote}\begin{scriptsize}\begin{verbatim}
% \author{Author 1, ... Author n\\
% Address line \\ ... \\ Address line}
% \end{verbatim}\end{scriptsize}\end{quote}

% \noindent If the names do not fit well on one line use:

% \begin{quote}\begin{scriptsize}\begin{verbatim}
% \author{Author 1} ... \\
% {\bf \Large Author ... Author}\\
% Address line \\ ... \\ Address line
% }
% \end{verbatim}\end{scriptsize}\end{quote}

% \noindent For two (or three) authors from different institutions, use \textbackslash And:

% \begin{quote}\begin{scriptsize}\begin{verbatim}
% \author{Author 1\\ Address line \\ ... \\ Address line
% \And ... \And Author n\\
% Address line\\ ... \\ Address line}
% \end{verbatim}\end{scriptsize}\end{quote}

% \noindent To start a separate ``row" of authors, use \textbackslash AND:

% If the title and author information does not fit in the area allocated, place
% \textbackslash setlength\textbackslash titlebox\{\textit{height}\}
% after the \textbackslash documentclass line where \{\textit{height}\} is 2.5in or greater. (This one of the only allowable uses of the setlength command. Check with AAAI Press before using it elsewhere.)

% \subsubsection{Formatting Author Information --- Alternative Method}
% If your paper has a large number of authors from different institutions, you may use the following alternative method for displaying the author information.

% \begin{quote}\begin{scriptsize}\begin{verbatim}
% \author{AuthorOne},\textsuperscript{\rm 1}
% AuthorTwo,\textsuperscript{\rm 2}
% AuthorThree,\textsuperscript{\rm 3}
% \\bf \Large AuthorFour,\textsuperscript{\rm 4}
% AuthorFive, \textsuperscript{\rm 5}\\
% \textsuperscript{\rm 1}AffiliationOne,
% \textsuperscript{\rm 2}AffiliationTwo,
% \textsuperscript{\rm 3}AffiliationThree\\
% \textsuperscript{\rm 4}AffiliationFour,
% \textsuperscript{\rm 5}AffiliationFive
% \{email, email\}@affiliation.com,
% email@affiliation.com,
% email@affiliation.com,
% email@affiliation.com
% \end{verbatim}\end{scriptsize}\end{quote}

% Note that you should break the author list before it extends into the right column margin. Put a line break, followed by   \textbackslash bf  \textbackslash Large to put the second line of authors in the same font and size as the first line (you may not make authors names smaller to save space.) Affiliations can be broken with a simple line break (\textbackslash  \textbackslash).
% \subsection{\LaTeX{} Copyright Notice}
% The copyright notice automatically appears if you use aaai20.sty. It has been hardcoded and may not be disabled.

% \subsection{Credits}
% Any credits to a sponsoring agency should appear in the acknowledgments section, unless the agency requires different placement. If it is necessary to include this information on the front page, use
% \textbackslash thanks in either the \textbackslash author or \textbackslash title commands.
% For example:
% \begin{quote}
% \begin{small}
% \textbackslash title\{Very Important Results in AI\textbackslash thanks\{This work is
%  supported by everybody.\}\}
% \end{small}
% \end{quote}
% Multiple \textbackslash thanks commands can be given. Each will result in a separate footnote indication in the author or title with the corresponding text at the botton of the first column of the document. Note that the \textbackslash thanks command is fragile. You will need to use \textbackslash protect.

% Please do not include \textbackslash pubnote commands in your document.

% \subsection{Abstract}
% Follow the example commands in this document for creation of your abstract. The command \textbackslash begin\{abstract\} will automatically indent the text block. Please do not indent it further. {Do not include references in your abstract!}

% \subsection{Page Numbers}

% Do not \textbf{ever} print any page numbers on your paper. The use of \textbackslash pagestyle is forbidden.

% \subsection{Text }
% The main body of the paper must be formatted in black, ten-point Times Roman with twelve-point leading (line spacing). You may not reduce font size or the linespacing. Commands that alter font size or line spacing (including, but not limited to baselinestretch, baselineshift, linespread, and others) are expressly forbidden. In addition, you may not use color in the text.

% \subsection{Citations}
% Citations within the text should include the author's last name and year, for example (Newell 1980). Append lower-case letters to the year in cases of ambiguity. Multiple authors should be treated as follows: (Feigenbaum and Engelmore 1988) or (Ford, Hayes, and Glymour 1992). In the case of four or more authors, list only the first author, followed by et al. (Ford et al. 1997).

% \subsection{Extracts}
% Long quotations and extracts should be indented ten points from the left and right margins.

% \begin{quote}
% This is an example of an extract or quotation. Note the indent on both sides. Quotation marks are not necessary if you offset the text in a block like this, and properly identify and cite the quotation in the text.

% \end{quote}

% \subsection{Footnotes}
% Avoid footnotes as much as possible; they interrupt the reading of the text. When essential, they should be consecutively numbered throughout with superscript Arabic numbers. Footnotes should appear at the bottom of the page, separated from the text by a blank line space and a thin, half-point rule.

% \subsection{Headings and Sections}
% When necessary, headings should be used to separate major sections of your paper. Remember, you are writing a short paper, not a lengthy book! An overabundance of headings will tend to make your paper look more like an outline than a paper. The aaai.sty package will create headings for you. Do not alter their size nor their spacing above or below.

% \subsubsection{Section Numbers}
% The use of section numbers in AAAI Press papers is optional. To use section numbers in \LaTeX{}, uncomment the setcounter line in your document preamble and change the 0 to a 1 or 2. Section numbers should not be used in short poster papers.

% \subsubsection{Section Headings.}
% Sections should be arranged and headed as follows:

% \subsubsection{Acknowledgments.}
% The acknowledgments section, if included, appears after the main body of text and is headed ``Acknowledgments." This section includes acknowledgments of help from associates and colleagues, credits to sponsoring agencies, financial support, and permission to publish. Please acknowledge other contributors, grant support, and so forth, in this section. Do not put acknowledgments in a footnote on the first page. If your grant agency requires acknowledgment of the grant on page 1, limit the footnote to the required statement, and put the remaining acknowledgments at the back. Please try to limit acknowledgments to no more than three sentences.

% \subsubsection{Appendices.}
% Any appendices follow the acknowledgments, if included, or after the main body of text if no acknowledgments appear.

% \subsubsection{References}
% The references section should be labeled ``References" and should appear at the very end of the paper (don't end the paper with references, and then put a figure by itself on the last page). A sample list of references is given later on in these instructions. Please use a consistent format for references. Poorly prepared or sloppy references reflect badly on the quality of your paper and your research. Please prepare complete and accurate citations.

% \subsection{Illustrations and Figures}
% Figures, drawings, tables, and photographs should be placed throughout the paper near the place where they are first discussed. Do not group them together at the end of the paper. If placed at the top or bottom of the paper, illustrations may run across both columns. Figures must not invade the top, bottom, or side margin areas. Figures must be inserted using the \textbackslash usepackage\{graphicx\}. Number figures sequentially, for example, figure 1, and so on.

% The illustration number and caption should appear under the illustration. Labels, and other text with the actual illustration must be at least nine-point type.

% If your paper includes illustrations that are not compatible with PDF\TeX{} (such as .eps or .ps documents), you will need to convert them. The epstopdf package will usually work for eps files. You will need to convert your ps files to PDF however.



% \subsubsection{Low-Resolution Bitmaps.}
% You may not use low-resolution (such as 72 dpi) screen-dumps and GIF files---these files contain so few pixels that they are always blurry, and illegible when printed. If they are color, they will become an indecipherable mess when converted to black and white. This is always the case with gif files, which should never be used. The resolution of screen dumps can be increased by reducing the print size of the original file while retaining the same number of pixels. You can also enlarge files by manipulating them in software such as PhotoShop. Your figures should be 300 dpi when incorporated into your document.

% \subsubsection{\LaTeX{} Overflow.}
% \LaTeX{} users please beware: \LaTeX{} will sometimes put portions of the figure or table or an equation in the margin. If this happens, you need to scale the figure or table down, or reformat the equation.{ \bf Check your log file!} You must fix any overflow into the margin (that means no overfull boxes in \LaTeX{}). \textbf{Nothing is permitted to intrude into the margin or gutter.}

% The most efficient and trouble-free way to fix overfull boxes in graphics is with the following command:

% \begin{quote}
% \begin{small}
% \textbackslash resizebox\{.9\textbackslash columnwidth\}{!}\{
% \}
% \end{small}\end{quote}

% \subsubsection{Using Color.}
% Use of color is restricted to figures only. It must be WACG 2.0 compliant. (That is, the contrast ratio must be greater than 4.5:1 no matter the font size.) It must be CMYK, NOT RGB. It may never be used for any portion of the text of your paper. The archival version of your paper will be printed in black and white and grayscale.The web version must be readable by persons with disabilities. Consequently, because conversion to grayscale can cause undesirable effects (red changes to black, yellow can disappear, and so forth), we strongly suggest you avoid placing color figures in your document. If you do include color figures, you must (1) use the CMYK (not RGB) colorspace and (2) be mindful of readers who may happen to have trouble distinguishing colors. Your paper must be decipherable without using color for distinction.

% \subsubsection{Drawings.}
% We suggest you use computer drawing software (such as Adobe Illustrator or, (if unavoidable), the drawing tools in Microsoft Word) to create your illustrations. Do not use Microsoft Publisher. These illustrations will look best if all line widths are uniform (half- to two-point in size), and you do not create labels over shaded areas. Shading should be 133 lines per inch if possible. Use Times Roman or Helvetica for all figure call-outs. \textbf{Do not use hairline width lines} --- be sure that the stroke width of all lines is at least .5 pt. Zero point lines will print on a laser printer, but will completely disappear on the high-resolution devices used by our printers.

% \subsubsection{Photographs and Images.}
% Photographs and other images should be in grayscale (color photographs will not reproduce well; for example, red tones will reproduce as black, yellow may turn to white, and so forth) and set to a minimum of 300 dpi. Do not prescreen images.

% \subsubsection{Resizing Graphics.}
% Resize your graphics \textbf{before} you include them with LaTeX. You may \textbf{not} use trim or clip options as part of your \textbackslash includegraphics command. Resize the media box of your PDF using a graphics program instead.

% \subsubsection{Fonts in Your Illustrations}
% You must embed all fonts in your graphics before including them in your LaTeX document.

% \subsection{References}
% The AAAI style includes a set of definitions for use in formatting references with BibTeX. These definitions make the bibliography style fairly close to the one specified below. To use these definitions, you also need the BibTeX style file ``aaai.bst," available in the AAAI Author Kit on the AAAI web site. Then, at the end of your paper but before \textbackslash end{document}, you need to put the following lines:

% \begin{quote}
% \begin{small}
% \textbackslash bibliographystyle\{aaai\}
% \textbackslash bibliography\{bibfile1,bibfile2,...\}
% \end{small}
% \end{quote}

% Please note that you are required to use \textbackslash bibliographystyle\{aaai\} for your references. You may not use named, plain, apalike, acm, ieeetr, siam, chicago, or any other style. Use of natbib is also not acceptable. (In addition to natbib, the aaai20.sty file is also incompatible with the hyperref and navigator packages. If you use either, your references will be garbled and your paper will be returned to you.) If you used natbib commands, an imprecise workaround is available (although it does not always work). You may put the following in your preamble (after removing \textbackslash usepackage\{natbib\}

% \begin{quote}\small
% \textbackslash newcommand\{\textbackslash citet\}[1]\{\textbackslash citeauthor\{\#1\}~\textbackslash shortcite\{\#1\}\}
% \textbackslash newcommand\{\textbackslash citep\}\{\textbackslash cite\}
% \textbackslash newcommand\{\textbackslash citealp\}[1]\{\textbackslash citeauthor\{\#1\}~\textbackslash citeyear\{\#1\}\}
% \end{quote}


% References may be the same size as surrounding text. However, in this section (only), you may reduce the size to \textbackslash small if your paper exceeds the allowable number of pages. Making it any smaller than 9 point with 10 point linespacing, however, is not allowed. A more precise and exact method of reducing the size of your references minimally is by means of the following command: \begin{quote}
% \textbackslash fontsize\{9.8pt\}\{10.8pt\}
% \textbackslash selectfont\end{quote}

% \noindent You must reduce the size equally for both font size and line spacing, and may not reduce the size beyond \{9.0pt\}\{10.0pt\}.

% The list of files in the \textbackslash bibliography command should be the names of your BibTeX source files (that is, the .bib files referenced in your paper).

% The following commands are available for your use in citing references:
% \begin{quote}
% {\em \textbackslash cite:} Cites the given reference(s) with a full citation. This appears as ``(Author Year)'' for one reference, or ``(Author Year; Author Year)'' for multiple references.\smallskip\\
% {\em \textbackslash shortcite:} Cites the given reference(s) with just the year. This appears as ``(Year)'' for one reference, or ``(Year; Year)'' for multiple references.\smallskip\\
% {\em \textbackslash citeauthor:} Cites the given reference(s) with just the author name(s) and no parentheses.\smallskip\\
% {\em \textbackslash citeyear:} Cites the given reference(s) with just the date(s) and no parentheses.
% \end{quote}



% Formatted bibliographies should look like the following examples.

% \smallskip \noindent \textit{Book with Multiple Authors}\\
% Engelmore, R., and Morgan, A. eds. 1986. \textit{Blackboard Systems.} Reading, Mass.: Addison-Wesley.

% \smallskip \noindent \textit{Journal Article}\\
% Robinson, A. L. 1980a. New Ways to Make Microcircuits Smaller. \textit{Science} 208: 1019--1026.

% \smallskip \noindent \textit{Magazine Article}\\
% Hasling, D. W.; Clancey, W. J.; and Rennels, G. R. 1983. Strategic Explanations in Consultation. \textit{The International Journal of Man-Machine Studies} 20(1): 3--19.

% \smallskip \noindent \textit{Proceedings Paper Published by a Society}\\
% Clancey, W. J. 1983. Communication, Simulation, and Intelligent Agents: Implications of Personal Intelligent Machines for Medical Education. In \textit{Proceedings of the Eighth International Joint Conference on Artificial Intelligence,} 556--560. Menlo Park, Calif.: International Joint Conferences on Artificial Intelligence, Inc.

% \smallskip \noindent \textit{Proceedings Paper Published by a Press or Publisher}\\
% Clancey, W. J. 1984. Classification Problem Solving. In \textit{Proceedings of the Fourth National Conference on Artificial Intelligence,} 49--54. Menlo Park, Calif.: AAAI Press.

% \smallskip \noindent \textit{University Technical Report}\\
% Rice, J. 1986. Poligon: A System for Parallel Problem Solving, Technical Report, KSL-86-19, Dept. of Computer Science, Stanford Univ.

% \smallskip \noindent \textit{Dissertation or Thesis}\\
% Clancey, W. J. 1979. Transfer of Rule-Based Expertise through a Tutorial Dialogue. Ph.D. diss., Dept. of Computer Science, Stanford Univ., Stanford, Calif.

% \smallskip \noindent \textit{Forthcoming Publication}\\
% Clancey, W. J. 2021. The Engineering of Qualitative Models. Forthcoming.

% For the most up to date version of the AAAI reference style, please consult the \textit{AI Magazine} Author Guidelines at \url{https://aaai.org/ojs/index.php/aimagazine/about/submissions#authorGuidelines}



% \section{Proofreading Your PDF}
% Please check all the pages of your PDF file. The most commonly forgotten element is the acknowledgements --- especially the correct grant number. Authors also commonly forget to add the metadata to the source, use the wrong reference style file, or don't follow the capitalization rules or comma placement for their author-title information properly. A final common problem is text (expecially equations) that runs into the margin. You will need to fix these common errors before submitting your file.

% \section{Improperly Formatted Files }
% In the past, AAAI has corrected improperly formatted files submitted by the authors. Unfortunately, this has become an increasingly burdensome expense that we can no longer absorb (we are charged double for papers that require reformatting). Consequently, if your file is improperly formatted, it will probably be returned to you by the outside Production agency. If that happens, you will be required to fix your file and pay a resubmission fee.

% \subsection{\LaTeX{} 209 Warning}
% If you use \LaTeX{} 209 your paper will be returned to you unpublished. Convert your paper to \LaTeX{}2e.

% \section{Naming Your Electronic File}
% We require that you name your \LaTeX{} source file with the last name (family name) of the first author so that it can easily be differentiated from other submissions. Complete file-naming instructions will be provided to you in the submission instructions.

% \section{Submitting Your Electronic Files to AAAI}
% Instructions on paper submittal will be provided to you in your acceptance letter.

% \section{Inquiries}
% If you have any questions about the preparation or submission of your paper as instructed in this document, please contact AAAI Press at the address given below. If you have technical questions about implementation of the aaai style file, please contact an expert at your site. We do not provide technical support for \LaTeX{} or any other software package. To avoid problems, please keep your paper simple, and do not incorporate complicated macros and style files.

% \begin{quote}
% \noindent AAAI Press\\
% 2275 East Bayshore Road, Suite 160\\
% Palo Alto, California 94303\\
% \textit{Telephone:} (650) 328-3123\\
% \textit{E-mail:} See the submission instructions for your particular conference or event.
% \end{quote}

% \section{Additional Resources}
% \LaTeX{} is a difficult program to master. If you've used that software, and this document didn't help or some items were not explained clearly, we recommend you read Michael Shell's excellent document (testflow doc.txt V1.0a 2002/08/13) about obtaining correct PS/PDF output on \LaTeX{} systems. (It was written for another purpose, but it has general application as well). It is available at www.ctan.org in the tex-archive.

% \section{ Acknowledgments}
% AAAI is especially grateful to Peter Patel Schneider for his work in implementing the aaai.sty file, liberally using the ideas of other style hackers, including Barbara Beeton. We also acknowledge with thanks the work of George Ferguson for his guide to using the style and BibTeX files --- which has been incorporated into this document --- and Hans Guesgen, who provided several timely modifications, as well as the many others who have, from time to time, sent in suggestions on improvements to the AAAI style.

% The preparation of the \LaTeX{} and Bib\TeX{} files that implement these instructions was supported by Schlumberger Palo Alto Research, AT\&T Bell Laboratories, Morgan Kaufmann Publishers, The Live Oak Press, LLC, and AAAI Press. Bibliography style changes were added by Sunil Issar. \verb+\+pubnote was added by J. Scott Penberthy. George Ferguson added support for printing the AAAI copyright slug. Additional changes to aaai.sty and aaai.bst have been made by the AAAI staff.

% \bigskip
% \noindent Thank you for reading these instructions carefully. We look forward to receiving your electronic files!