\def\year{2022}\relax
%File: formatting-instructions-latex-2022.tex
%release 2022.1
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai22}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{xcolor}
\usepackage{listings}
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
%\nocopyright
%
\copyrighttext{Presented at the AI-HRI Symposium at AAAI Fall Symposium Series (FSS) 2022}
% PDF Info Is REQUIRED.
% For /Title, write your title in Mixed Case.
% Don't use accents or commands. Retain the parentheses.
% For /Author, add all authors within the parentheses,
% separated by commas. No accents, special characters
% or commands are allowed.
% Keep the /TemplateVersion tag as is

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
%  -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
%  -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai22.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash

%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{Towards Cognitive Robots That People Accept in Their Home}

\author {
    % Authors
    Nina Moorman, %\textsuperscript{\rm 1}
    Erin Hedlund-Botti, %\textsuperscript{\rm 2}
    Matthew Gombolay %\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    %\textsuperscript{\rm 1} Affiliation 1\\
    %\textsuperscript{\rm 2} Affiliation 2\\
    Georgia Institute of Technology \\
    School of Interactive Computing \\
    Atlanta, Georgia, USA \\
   ninamoorman@gatech.edu, erin.botti@gatech.edu, matthew.gombolay@cc.gatech.edu
}


\begin{document}
\maketitle

\begin{abstract}
It is intractable for assistive robots to have all functionalities pre-programmed prior to deployment. Rather, it is more realistic for robots to perform supplemental, on-site learning about user's needs and preferences, and  particularities of the environment. This additional learning is especially helpful for care robots that assist with individualized caregiver activities in residential or assisted living facilities. As each care receiver has unique needs and those needs may change over time, robots require the ability to adapt and learn on-site. In this work, we propose the study design to investigate the impacts on end-users of observing robot learning. We will assess user attitudes towards robots that conduct some learning in the home as compared to a baseline condition where the robot is delivered fully capable. We will additionally compare different modes of learning to determine whether some are more likely to instill trust.
\end{abstract}

%%% unclear how to include the following keywords %%%
% trust, robotics, robot adoption, human-robot interaction, human-robot trust, trust repair, explainable artificial intelligence, learning from demonstration, reinforcement learning

\section{Introduction}
\label{sec:introduction}
Care robots perform a wide variety of assistive tasks that could benefit from some degree of in situ learning. This supplemental learning would enable the robot to adapt to its environment and users. It would additionally offer caregivers and care receivers the option of being directly involved in the robot's learning, enabling end-users to specify preferences or teach the robot new tasks directly. This customization is important for ensuring effective, individualized care. Though at-home learning is already in use for some care robots, we lack an understanding of how observing this learning affects user trust \cite{irobot_irobot_nodate, moxi, paro}. This work aims to develop a better understanding of how users will respond to observable robot learning.

We propose a series of human-subjects experiments that evaluate user perceptions of learning robots using both surveys and behavioral metrics. %, we aim to determine the effect of various forms of robot learning on user trust, usability, and adoptability.
We choose four learning methods to understand how user perception of a learning robot may vary depending on the degree of user involvement in the learning process. We capture low involvement learning with a reinforcement learning (RL) condition, and high involvement learning with an learning from demonstration (LfD) condition using kinesthetic demonstrations. Our control baseline is a download condition where the robot downloads tasks from the cloud. Finally, we include the Training an Agent Manually via Evaluative Reinforcement (TAMER) \cite{knox2009interactively} condition which is a middle ground between RL an LfD. %Some of these tasks require observation-based learning. For instance, robotic agents such as Roomba \cite{irobot_irobot_nodate} and Moxi \cite{moxi} learn the layout of their environment through observation and exploration. Other robots observe users to classify and track user behavior. Robotic agents such as PHAROS use this functionality to help monitor user well-being and daily exercise \cite{martinez-martin_pharos_2019}. Finally, robots such as PARO perform interaction-based learning of user preferences via physical interactions and feedback \cite{paro}.
We will compare robot perception in each of the learning conditions for in person and remote participants, and for both the caregiver and general population.

\begin{figure}[t]
    \centering
    \includegraphics[scale=0.45]{Figures/four_agents.png}
  \caption{This figure shows the four learning conditions.}
    \label{fig:agent_types}
\end{figure}

Informed by the findings we then wish to determine the techniques that are most effective in repairing trust in a learning robot. As learning agents may not learn quickly and may fail often, it is important to evaluate the best method of trust repair for embodied, learning agents \cite{3374839}. Finally, we aim to develop guidelines to inform the design of care robotic systems that learn and operate in residential or nursing-home environments. In our work we propose the following:

\begin{enumerate}
    \item Study the difference between user perceptions of a fully pre-engineered robot compared to a learning robot.
    \item Investigate how to best perform trust repair with respect to embodied robots that learn in the home.
    \item Develop guidelines to inform the design of assistive robotic systems deployed in residential environments.
\end{enumerate}

\section{Related Works}
\label{sec:relatedworks}
% We now describe relevant prior work in care robots, acceptability, and trust.

\subsubsection{Care Robots -}
Care robots are defined by their function to support caregivers and/or care receivers \cite{van_wynsberghe_designing_2013}. These robots can operate in residential environments where they perform a variety of assistive tasks and promote extended independent living \cite{johnson_socially_2014,sabanovic_robot_2015, fiorini_assistive_2021, lee_reframing_2018}. Care robot roles generally fall under physical assistance or medical assistance. Physical assistance includes tasks such as navigation, fall-prevention, object manipulation, and household chores \cite{moxi, fischinger_hobbit_2016, swisslog_healthcare_autonomous_nodate, kittmann_let_2015, kostavelis_ramcip_2016, miseikis_lio-personal_2020}. Medical assistance includes tasks such as health monitoring, medicine delivery, and the exertion of a social presence for coaching or social interaction \cite{vitanza_assistive_2019, coradeschi_giraffplus_2013, umbrico_holistic_2020, nao, pepper, martinez-martin_pharos_2019}.

On-site learning affords the robot an opportunity to observe and adapt to individual user needs and preferences, which may be beneficial for both physical and medical assistance tasks. In this work, we seek to understand how observing various forms of robot learning may impact user perceptions of care robots.

\subsubsection{Acceptance and Trust -}
Robot acceptance depends not only on the benefits the robot can bestow upon the user, but also on the user's perception of and attitudes towards the robot \cite{cesta_psychological_2007}. One of the most important attitudes with respect to acceptability is user trust \cite{yagoda_you_2012, langer_trust_2019}. Trust is defined as a users attitude that the agent will help them achieve a goal, specifically in a situation of uncertainty, or vulnerability \cite{kohn_measurement_2021, ullman_what_2018}.

Prior work in human-automation (HA) trust has categorized trust based on the extent of interaction with the user into dispositional, situational, and learned trust \cite{hoff_trust_2015}. These represent baseline trust in automation \cite{merritt_i_2013}, trust with respect to a particular interaction \cite{jian_foundations_2000}, and trust developed though a series of interactions \cite{de_visser_towards_2020}.

Another approach for investigating HR trust is to study trust dependent on robot-specific factors, such as performance \cite{hedlund_effects_2021}. In our work, we keep performance consistent between conditions to isolate the impact of observing the learning process. However, there may still be differences in perceived robot ability due to the observation of different forms of learning; as such, we will evaluate performance-based trust.

In human robot interactions, anthropomorphism (i.e., the degree to which a robotic agent demonstrates human-like characteristics) has been shown to affect trust \cite{3374839}. Thus, we will hold the robot's embodiment constant throughout the study and subjectively measure subjects' perception of the robot's anthropomorphism to control for this effect. The robot we employ is the Movo Beta robot. Finally, in our work, we conduct both in-person and remote studies to account for the impact of the robot's physical presence on user trust.

% Thus, we will hold the robot's embodiment constant throughout the study and subjectively measure subjects' perception of the robot's anthropomorphism to control for this effect. The robot we employ is the Movo Beta robot. Another approach for investigating HR trust is to study trust dependent on robot-specific factors, such as performance. A robot's performance has been shown to impact trust \cite{hedlund_effects_2021}, so we choose to keep performance consistent between conditions to isolate the impact of observing the learning process. However, there may still be differences in perceived robot ability due to the observation of different forms of learning; as such, we will evaluate performance-based trust. % This performance-based trust encompasses robot performance and user's awareness of the robot's abilities.

% A second lens through which to examine trust is based on interaction-specific factors (i.e., relation-based) \cite{law_chapter_2021}. Relation-based trust looks at social factors between the robot and society including robot appearance, adherence to social norms, and morality. We will employ recent work to independently measure these types of HR trust \cite{malle_multidimensional_2021}.

 %The influence of embodiment on trust is especially potent when the human and robot are working together\cite{khavas_review_2021}.

\section{Methodology}
\label{sec:methods}
This section details the domain, experimental populations, learning conditions, hypotheses, metrics, and study design. % In our experiment, participants will watch videos of a robot learning to complete a training task. Then, participants will observe the robot's performance on a related, riskier test task. We will measure their trust in the robot and their perceived risk of the task.

\subsection{Domain}
\label{sec:domain}
The plate-making domain we choose is depicted in Figure \ref{fig:study_setup}. This task involves picking up a knife, cutting a banana that has already been placed on a plate in half, then picking the correct medicine, and pouring it on to the plate. We choose this task as it is a combination of both a cognitive preparation task (recipe-following) and the manipulation task (cutting). We isolate participant perceptions of the robot reported in each of these sub-tasks.

In the training phase the knife used will be a small plastic knife, and the medicine dispensed will be composed of different types of vitamins. We make the testing phase riskier by changing the knife to a large, sharp, metal knife, and changing the medicine to prescription grade medications labeled as morphine, aspirin, and antibiotics. Recall from our definition of trust that we must evaluate trust in a situation of uncertainty, or vulnerability \cite{kohn_measurement_2021, ullman_what_2018}. As a result, we raise the stakes in the test task to ensure that participants consider their risk tolerance when evaluating the robot.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\columnwidth]{Figures/testing_setup.png}
  \caption{This figure shows the testing phase study design.}
    \label{fig:study_setup}
\end{figure}

\subsection{Experiment Populations} \label{sec:humanexperiment}
Virtual studies may not fully represent the impact of the robot's physical presence on trust. However, conducting our study in person would impose a high health risk and a potentially impractical transportation burden on our target population of caregivers. As such, we propose to conduct three human-subjects experiments.

\indent \textit{Study 1: Remote, General Population} We invite members accessible to us at a metropolitan university campus to take our study virtually.

\indent \textit{Study 2: In Person, General Population} We invite members of the local population to take our study in the laboratory. In Study 2, the test phase will be conducted live, in person.

\indent \textit{Study 3: Remote, Caregivers} We invite our target population of caregivers and elder care nurses in our state to take our study virtually.

By comparing the results of Study 1 and Study 2, we determine the influence of embodied robots on user trust. Additionally, by comparing the results of Study 1 and Study 3, we determine the difference in trust between caregivers and the general population.

\subsection{Learning Conditions}
\label{sec:conditions}
In this section, we describe the training video for each of the four learning conditions. For consistency, the training in all studies (virtual and in person) is recorded and viewed in a video format. The method by which the robot learns depends upon the learning condition. We aim to investigate how people may feel differently about the robot depending on the level of user-involvement in the robot learning. Thus, the learning conditions reflect different levels of user involvement.

\textit{Download: }In the download condition, the participant observes the robot download the task knowledge from ``the cloud.'' This serves as the control condition, as no learning is observed by the user.

\textit{RL: }In the RL condition, the robot demonstrates trial-and-error learning, iteratively learning sub-tasks of the overall task until the task is completed. No explicit reward function will be explained to the participant, and we intentionally describe stages of the learning vaguely, using terms such as start, middle, and end of training rather than providing training duration or iteration count.

\textit{LfD: }In the LfD condition, the same trial-and-error learning is observed; however, we intersperse videos of a human teaching the robot the sub-tasks prior to improvement in performance on these sub-tasks.

\textit{TAMER: }The TAMER condition is a middle ground between LfD and RL, where the robot attempts the task on its own and the user provides binary feedback throughout the learning process to shape the robot's behavior. This feedback will be shown through a graphic of a remote control with green and red buttons pressed during training to convey positive and negative feedback.

\subsection{Hypotheses}
\label{sec:hypotheses}

\textbf{Hypothesis 1} \textit{We hypothesize that participants will trust and adopt robots whose learning they have observed more than robots whose learning was not observable.} We postulate that participants will feel that they understand and can relate more to a robot that learns visibly (RL, LfD, TAMER conditions) than a robot whose learning is not observed (download condition), leading to differences in trust.

\textbf{Hypothesis 2} \textit{We hypothesize that participants will trust and adopt a robot that learns via LfD more than the other learning conditions.} LfD has been shown to be the most intuitive method of interacting with robotic agents, thus, we hypothesize that participants will demonstrate higher trust in and adoption of robots that employ this form of robot learning \cite{7451754, Akgun2011RobotLF}.

\textbf{Hypothesis 3} \textit{We hypothesize that participants will trust a robots less if it is physically present as compared to a remote robot.} Given that in-person participants (Study 2) experience the risk of embodied learning in person, we posit that these participants will trust the robot less than participants for which the task's risk is virtual (Study 1).

\textbf{Hypothesis 4} \textit{We hypothesize that the caregiver population will report lower trust in the robot than the general population.} We posit that the caregiver population (Study 3) will find the risk of robot error on physical manipulation and medicine dispensing tasks performed for care receivers to be more tangible and severe than the general population (Study 2), resulting in lower robot trust.

\subsection{Metrics}
\label{sec:metrics}
We will evaluate a user's dispositional trust, situational trust, and performance-based trust through surveys \cite{merritt_i_2013, jian_foundations_2000, malle_multidimensional_2021}. We will also study user trust using behavioral measures (i.e., in terms of reliance on and compliance with the robot) by determining the average intervention rate of participants while observing the robot's behavior on the test task.

\textit{Pre-Study Questionnaire -} In the pre-study questionnaire, we will collect demographic information including participants' education \cite{raub_correlates_nodate}, computer science and robotics prior experience \cite{raub_correlates_nodate}, personality \cite{donnellan_mini-ipip_2006}, field of occupation \cite{noauthor_college_nodate}, and dispositional trust \cite{merritt_i_2013}. We additionally collect users' perception of the robot's anthropomorphism \cite{bartneck_measurement_2009}, usability, and acceptability \cite{belanche_integrating_2012}.

\textit{Post-Trial Questionnaire -}
After each testing trial we will ask participants to rate the degree to which they feel the robot accomplished the task, as well as the degree to which they feel the robot behaves safely \cite{bartneck_measurement_2009}.

\textit{Post-Study Questionnaire -}
In the post-survey questionnaire, we will collect participants' perceived situational trust \cite{jian_foundations_2000}, performance-based trust \cite{malle_multidimensional_2021}, and how risky they perceived the task to be \cite{fischhoff_how_1978}. We will also ask two ad hoc questions. First, we will ask what tasks -- from a list of hand-crafted tasks both in and outside of the distribution of tasks observed in the study -- participants would trust the robot to do. This question measures the extent of user adoption. Secondly, we will ask an open-ended question about the participants understanding of the robots learning and perception of robot competence. This second question is to collect qualitative information about user assumptions regarding the robot's learning and competence.

\subsection{Procedure}
\label{sec:procedure}
Participants first read and sign the consent form, after which they are assigned a unique and random user ID. Next, participants will watch the unboxing video in which the robotic agent introduces itself and demonstrates its range of mobility and degrees of freedom. After watching the unboxing video, participants will fill out the pre-study questionnaire.

Then, participants will go through the training phase where they will observe the robot learning to perform the training task, as seen in Figure \ref{fig:training_flow}. Ours will be a between-subjects experiment where participants experience one of the four learning conditions. Therefore, in the training phase, participants will watch their condition's unique training video. The only difference between learning conditions will be the type of robot learning observed. After this training phase all participants will observe the same final performance video, and final performance will be held constant between learning conditions.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\columnwidth]{Figures/training_flow.png}
  \caption{This figure shows a sample training trajectory for the cutting task.}
    \label{fig:training_flow}
\end{figure}

Next is the testing phase, where participants will observe nine testing trials where the robot states its goal and attempts to accomplish this goal, with an overall success rate of 80\%. During each testing trial, the participant will be instructed to interrupt the robot by clicking a red stop button if they feel that the robot might be acting in an unsafe manner or if they feel unsafe or uncomfortable, or if they feel that the robot will fail, or will not accomplish the goal of that trial. The interruption data collected here serves to assess reliance. This binary interruption metric, along with the duration of time observing the agent prior to interruption, help to support our findings on trust. After each testing trial, participants will fill out the post-trial questionnaire where we will ask them to rate the degree to which they trust the robot to act safely and the degree to which they believe the robot will accomplish the task. The testing iterations will be shown in person for Study 2 and shown as recorded videos for Study 1 and 3. After the testing phase, the participants will complete the post-study questionnaire.

\subsection{Proposed Analysis}
For the data collected in the Post-Study Questionnaire that passes parametric assumptions of normality and homoscedasticity, we will compare each metric across conditions/populations using ANOVAs with Tukey post-hoc corrections. If the data does not pass these assumptions, we will use non-parametric tests such as the Kruskal-Wallis test with Wilcoxon pairwise tests and Bonferonni post-hoc correction. We will additionally analyze each of the metrics in the Post-Trial Questionnaire using a repeated measures analysis to distinguish between user perception of the robot in the knife and medicine sub-tasks. The information collected from the Pre-Study Questionnaire will be used to determine any potential confounds in the analysis. For Study 1, we plan to run 15 participants in each learning condition, 60 total, with a power of $.8$ and $\alpha=.05$; a power analysis on these values yields a large effect size of $.44$. If we run 60 participants for both in person and remote conditions (Study 1 and Study 2), with a power of $.8$ and $\alpha=.05$, the power analysis yields a medium effect size of $.26$. We aim to recruit at least 12 caregiver participants for Study 3. Given the smaller sample size of the target population, we propose to analyze trends between the general population and caregiver population.

\section{Limitations}
\label{sec:limitations}
One limitation of our work is that in Study 1 and 3 the robot is not physically present with the participant. We are thus investigating user perception of the robot based upon the users' experience watching videos and imagining the robot learning in their home. We aim to quantify the impact of this limitation with Study 2.

Another limitation of our work is that we constrain our definition of caregiver to nurses employed in assisted living facilities for ease of recruitment in our first investigation. In future work, we plan to increase the breadth of caregiver recruitment to include caregivers who are not nurses (e.g., adult children of parents receiving care). %\textcolor{green}{Add briefly why this matters.}

% A final limitation of our work is that when recruiting from the general population, the majority of participants will come from our university campus.

\section{Future Work}
\label{sec:futurework}
In future work we will conduct the studies proposed in this paper. Based on these results, we will design a new study (i.e., Study 4) in which we compare various trust repair techniques, applied to a robot that employs the highest effect learning method from Studies 1-3. In Study 4, we propose to evaluate the following three forms of trust repair established in prior work \cite{de_visser_towards_2020, baker_toward_2018, robinette_timing_2015, kim_repairing_2013}.
% \cite{de_visser_towards_2020, baker_toward_2018, robinette_timing_2015, kim_repairing_2013} Robinette looks at when to perform trust repair, de Visser has a good list of what the options are for trust repair, and proposes some new ones, Kim looks at what types work for individuals vs teams, and Baker looks at how to do trust repair in H-H, H-A, and H-R interactions

\begin{enumerate}
    \item An apology provided directly after the trust violation.
    \item Transparency of robot learning, provided as a high-level narration of what is learned.
    \item An explanation of what caused the error, without acknowledging fault, provided after the trust violation.
\end{enumerate}

\section{Conclusion}
\label{sec:conclusion}
We propose a series of human-subject experiments to assess user attitudes towards the concept of embodied care robots that learn in the home, as compared to robots that are delivered fully capable. We investigate the impact of the robot's physical presence on a user's perception of the robot, as well as the differences in robot perception between the general population and caregivers. Based on the findings of our work, we propose to develop guidelines that inform the design of care robots deployed in the home. Finally, we propose to investigate how we can best calibrate trust in embodied learning robots.

\section{Acknowledgments}
This work was supported by NSF IIS-2112633.

% 
Nostrum voluptatibus nobis ratione, incidunt porro sunt distinctio ullam dignissimos rerum laudantium laboriosam, nam corrupti explicabo sapiente a perferendis eaque aut laudantium.Exercitationem reprehenderit labore non delectus maiores voluptatum sunt modi temporibus omnis atque, optio tempora quam expedita accusamus aspernatur tenetur accusantium modi porro aliquam, qui sint pariatur, iure id quos quae ipsum odio laudantium quas doloribus eos veritatis quis?Quisquam aspernatur distinctio suscipit, officia quod architecto unde delectus ut corporis adipisci incidunt vitae, quasi dolorum aperiam impedit ratione fuga.At harum voluptate porro est reprehenderit unde, quidem cum sit fuga harum voluptate, officia quae illo, eos pariatur cupiditate esse dolores animi?Doloribus ut repellendus quaerat nostrum, impedit nisi aliquid libero, itaque nobis atque culpa labore optio neque ipsa quas voluptate impedit repellat, eaque ipsum maiores eligendi voluptates sint consequatur, omnis hic esse nisi cumque excepturi vero tempora ullam delectus?Cumque explicabo vero adipisci quos quidem mollitia quod, delectus magnam ex aliquid dignissimos,
\bibliography{aaai22}

\end{document}