\relax 
\bibstyle{aaai24}
\citation{chapman-aij1987}
\citation{srivastava2011foundations,bonet2015policies,jimenez2019review,rivlin2020generalized}
\citation{gcrl1,gcrl2}
\citation{brown2020language,chen2021evaluating,chowdhery2022palm}
\citation{chen2021evaluating,nijkamp2023codegen,chen2023improving}
\citation{openai2023gpt4}
\citation{mcdermott-aimag2000}
\citation{wei2022chain,jiang2023self}
\citation{huang2022inner}
\citation{raman2022planning}
\citation{yang2022pg3}
\citation{sharma2022skill,ahn2022can,huang2022language,raman2022planning,lin2022grounded}
\citation{valmeekam2022large,silver2022pddl}
\citation{pallagani2022plansformer}
\citation{collins2022structured,lin2023text2motion,xie2023translating,liu2023llm}
\@LN@col{1}
\@LN@col{2}
\citation{triangletables,jimenez2019review}
\citation{levine2003learning,jimenez2015computing,segovia2018computing,segovia2021generalized}
\citation{kplanner,Srivastava2011DirectedSF,winner2008dsplanner}
\citation{genplan_representation}
\citation{yang2022pg3}
\citation{chen2021evaluating,nijkamp2023codegen}
\citation{wei2022chain,jiang2023self,zheng2023outline}
\citation{gao2022pal,imani2023mathprompter}
\citation{xia2023conversational,chen2023teaching}
\citation{chen2023improving}
\citation{liang2022code,singh2022progprompt}
\citation{alur2013syntax,gulwani2017program}
\citation{muggleton1991inductive,cropper2022inductive}
\citation{mcdermott-aimag2000}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:teaser}{{1}{2}{Overview of pipeline for generalized planning with pretrained LLMs. See text for details.}{}{}}
\@LN@col{1}
\@LN@col{2}
\citation{brown2020language,chen2021evaluating,chowdhery2022palm,openai2023gpt4}
\citation{wei2022chain}
\@LN@col{1}
\@LN@col{2}
\citation{howey2004val}
\citation{yang2022pg3}
\@LN@col{1}
\@LN@col{2}
\citation{yang2022pg3}
\citation{yang2022pg3}
\citation{yang2022pg3}
\newlabel{table:main_results}{{1}{5}{Fraction of evaluation tasks solved. All results are averaged over 10 random seeds and 30 evaluation tasks per seed.}{}{}}
\newlabel{fig:problem_size}{{2}{5}{GPT-4 synthesized program runtime compared to a state-of-the-art planner (Fast Downward). Note the log-log axes. Each point is a median over 10 newly generated tasks, over all seeds where generalized planning solved all evaluation tasks.}{}{}}
\@LN@col{1}
\newlabel{fig:automated_debugging}{{3}{5}{Fraction of evaluation tasks solved by GPT-4 versus number of debugging steps allowed, averaged over all domains and seeds. The shaded region is standard error.}{}{}}
\@LN@col{2}
\newlabel{table:error_types}{{2}{5}{Percentages of error types encountered by GPT-4 in training tasks over all domains and seeds. ``All'' is the breakdown for all training tasks; ``Success'' is the breakdown for trials where all evaluation tasks were subsequently solved; ``Failure'' is the breakdown for the non-Success trials.}{}{}}
\citation{yang2022pg3}
\citation{chowdhery2022palm}
\citation{richter2010lama}
\citation{fd}
\@LN@col{1}
\@LN@col{2}
\citation{openai2023gpt4,bubeck2023sparks}
\citation{Yato2003OnTN}
\citation{silver2023inventing}
\citation{schick2023toolformer}
\citation{liu2023llm}
\citation{sohrabi2016finding,katz2020reshaping}
\bibdata{aaai24}
\@LN@col{1}
\@LN@col{2}
\@LN@col{1}
\@LN@col{2}
\gdef \@abspage@last{8}
